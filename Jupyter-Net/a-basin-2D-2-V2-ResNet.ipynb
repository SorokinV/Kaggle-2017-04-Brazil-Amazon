{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "##\n",
    "## ResNet analog from Keras resnet50\n",
    "##\n",
    "## maximum on LB => ????\n",
    "##\n",
    "## 2017-05-20\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import formFH, paths_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D, Conv2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Data/test-jpg-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, teDirJPG, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def formImExt (nf, resize=(32,32), printOK=False) :\n",
    "    nx = None\n",
    "    try : \n",
    "        ni = cv.imread(nf,-1); \n",
    "        if (ni is not None) :\n",
    "            #ni = cv.normalize\n",
    "            if not ((ni.shape[2]==3) or (ni.shape[2]==4)) and printOK : print('----- error ---- shape:',ni.shape,nf)\n",
    "            if (ni.shape[2]==3) :\n",
    "                nx = cv.resize(ni,resize)\n",
    "            if (ni.shape[2]==4) :\n",
    "                #r,g,b,n = ni[:,:,2],ni[:,:,1],ni[:,:,0],ni[:,:,3]\n",
    "                r,g,b,n = cv.resize(ni[:,:,2],resize),cv.resize(ni[:,:,1],resize),cv.resize(ni[:,:,0],resize),cv.resize(ni[:,:,3],resize)\n",
    "                dv,dw   = np.divide((r-n),(r+n+0.01)), np.divide((g-n),(g+n+0.01))\n",
    "                nx      = np.array([r,g,b,n,dv,dw]).T; \n",
    "    except BaseException as e :\n",
    "        print(nf,e); nx = None;\n",
    "    \n",
    "    if nx is None and printOK : \n",
    "        print('------ None:',nf); nx = None\n",
    "        \n",
    "    return(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-18 16:09:51.030338 40479 40479\n",
      "2017-05-18 16:12:30.271675 \t 5000 \t train_4999\n",
      "2017-05-18 16:14:32.662155 \t 10000 \t train_9999\n",
      "2017-05-18 16:16:21.170086 \t 15000 \t train_14999\n",
      "2017-05-18 16:17:57.485082 \t 20000 \t train_19999\n",
      "2017-05-18 16:19:17.573212 \t 25000 \t train_24999\n",
      "2017-05-18 16:20:26.649529 \t 30000 \t train_29999\n",
      "2017-05-18 16:21:34.931734 \t 35000 \t train_34999\n",
      "2017-05-18 16:22:38.544159 \t 40000 \t train_39999\n",
      "2017-05-18 16:22:44.600525\n",
      "40479 (40479, 64, 64, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "trX, trY, i, size = [],[], 0, len(nameList)\n",
    "print(datetime.datetime.now(),len(nameList),size)\n",
    "for nn in nameList[0:size] :\n",
    "    #nf = os.path.join(trDirTIF,nn+\".tif\");\n",
    "    nf = os.path.join(trDirJPG,nn+\".jpg\");\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        #rr=np.save(os.path.join(trWork,nn+\".npy\"),nx);\n",
    "        #trX.append(nn+\".npy\")\n",
    "        trX.append(nx)\n",
    "        trY.append(True)\n",
    "    else : \n",
    "        trY.append(False)\n",
    "    i += 1\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",i,\"\\t\",nn)\n",
    "    #print(nn.shape)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "trX = np.array(trX);\n",
    "trY = labelList[trY];\n",
    "print(len(nameList),trX.shape,trY.shape)\n",
    "#trXY=pd.DataFrame(trY); trXY['name']=trX; trXY.head()\n",
    "#trXY.to_pickle(os.path.join(trWork,\"listFiles.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#np.save('../Data-Keras/train-model-2D-64x64x6-v2-XX.npy',trX)\n",
    "#np.save('../Data-Keras/train-model-2D-64x64x6-v2-YY.npy',trY)\n",
    "np.save('../Data-Keras/train-model-2D-64x64x3-v2-XX.npy',trX)\n",
    "np.save('../Data-Keras/train-model-2D-64x64x3-v2-YY.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "#trX = np.load('../Data-Keras/train-model-2D-64x64x6-v2-XX.npy')\n",
    "#trY = np.load('../Data-Keras/train-model-2D-64x64x6-v2-YY.npy')\n",
    "trX = np.load('../Data-Keras/train-model-2D-64x64x3-v2-XX.npy')\n",
    "trY = np.load('../Data-Keras/train-model-2D-64x64x3-v2-YY.npy')\n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trX=trX/255.0\n",
    "#trX = cv.normalize(trX, trX, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "#trX=trX/65535.0\n",
    "#trX[0,:,:]\n",
    "#trX[:,:,:,5].max(),trX.min(),trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fbeta_loss(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    #yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# for ResNet 18,34 filter=(filter1,filter2)\n",
    "#\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2= filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = ZeroPadding2D((1,1))(input_tensor)\n",
    "    \n",
    "    x = Conv2D(filters1, kernel_size, strides=strides,\n",
    "               name=conv_name_base + '2a')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    \n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "\n",
    "    shortcut = Conv2D(filters2, (1,1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ResNetXX(input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "    '''\n",
    "    # Arguments\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    '''\n",
    "    \n",
    "    \"\"\"\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "    \"\"\"\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    '''\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    '''\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    \n",
    "    x = conv_block(x, 3, [64, 64], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64], stage=2, block='b')\n",
    "    #x = identity_block(x, 3, [64, 64], stage=2, block='c')\n",
    "    \n",
    "    x = conv_block(x, 3, [128, 128], stage=3, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [128, 128], stage=3, block='b')\n",
    "    #x = identity_block(x, 3, [128, 128], stage=3, block='c')\n",
    "\n",
    "    \n",
    "    x = conv_block(x, 3, [256, 256], stage=4, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [256, 256], stage=4, block='b')\n",
    "    \n",
    "    \n",
    "    #x = conv_block(x, 3, [512, 512], stage=5, block='a', strides=(1, 1))\n",
    "    #x = identity_block(x, 3, [512, 512], stage=5, block='b')\n",
    "    \n",
    "    #x = conv_block(x, 3, [1024, 1024], stage=5, block='a', strides=(1, 1))\n",
    "    #x = identity_block(x, 3, [1024, 1024], stage=5, block='b')\n",
    "    \n",
    "    \n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    #x = AveragePooling2D((2, 2), name='avg_pool')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    #x = Dense(256,activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    x = Dense(classes, activation='sigmoid', name='fc1000')(x)\n",
    "        \n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnetXX')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "#WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "#WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "model = ResNetXX(input_shape=(64,64,3),classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_71 (InputLayer)            (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_268 (ZeroPadding2 (None, 70, 70, 3)     0           input_71[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 32, 32, 64)    9472        zero_padding2d_268[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 32, 32, 64)    256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1141 (Activation)     (None, 32, 32, 64)    0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling2D)  (None, 15, 15, 64)    0           activation_1141[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_269 (ZeroPadding2 (None, 17, 17, 64)    0           max_pooling2d_66[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 15, 15, 64)    36928       zero_padding2d_269[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1142 (Activation)     (None, 15, 15, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_1142[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 15, 15, 64)    4160        max_pooling2d_66[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_1143 (Activation)     (None, 15, 15, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 15, 15, 64)    256         res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_358 (Add)                    (None, 15, 15, 64)    0           activation_1143[0][0]            \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1144 (Activation)     (None, 15, 15, 64)    0           add_358[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 15, 15, 64)    4160        activation_1144[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1145 (Activation)     (None, 15, 15, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_1145[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1146 (Activation)     (None, 15, 15, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_359 (Add)                    (None, 15, 15, 64)    0           activation_1146[0][0]            \n",
      "                                                                   activation_1144[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1147 (Activation)     (None, 15, 15, 64)    0           add_359[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_270 (ZeroPadding2 (None, 17, 17, 64)    0           activation_1147[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 15, 15, 128)   73856       zero_padding2d_270[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 15, 15, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1148 (Activation)     (None, 15, 15, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 15, 15, 128)   147584      activation_1148[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 15, 15, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 15, 15, 128)   8320        activation_1147[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1149 (Activation)     (None, 15, 15, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 15, 15, 128)   512         res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_360 (Add)                    (None, 15, 15, 128)   0           activation_1149[0][0]            \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1150 (Activation)     (None, 15, 15, 128)   0           add_360[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 15, 15, 128)   16512       activation_1150[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 15, 15, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1151 (Activation)     (None, 15, 15, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 15, 15, 128)   147584      activation_1151[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 15, 15, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1152 (Activation)     (None, 15, 15, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_361 (Add)                    (None, 15, 15, 128)   0           activation_1152[0][0]            \n",
      "                                                                   activation_1150[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1153 (Activation)     (None, 15, 15, 128)   0           add_361[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_271 (ZeroPadding2 (None, 17, 17, 128)   0           activation_1153[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 15, 15, 256)   295168      zero_padding2d_271[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 15, 15, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1154 (Activation)     (None, 15, 15, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 15, 15, 256)   590080      activation_1154[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 15, 15, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 15, 15, 256)   33024       activation_1153[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1155 (Activation)     (None, 15, 15, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 15, 15, 256)   1024        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_362 (Add)                    (None, 15, 15, 256)   0           activation_1155[0][0]            \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1156 (Activation)     (None, 15, 15, 256)   0           add_362[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 15, 15, 256)   65792       activation_1156[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 15, 15, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1157 (Activation)     (None, 15, 15, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 15, 15, 256)   590080      activation_1157[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 15, 15, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1158 (Activation)     (None, 15, 15, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_363 (Add)                    (None, 15, 15, 256)   0           activation_1158[0][0]            \n",
      "                                                                   activation_1156[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1159 (Activation)     (None, 15, 15, 256)   0           add_363[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 2, 2, 256)     0           activation_1159[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)             (None, 1024)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "fc1000 (Dense)                   (None, 17)            17425       flatten_70[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 2,123,217\n",
      "Trainable params: 2,118,609\n",
      "Non-trainable params: 4,608\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _fbeta_loss(y_true, y_pred):\n",
    "    beta2 = 4.\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.))))\n",
    "    precision, recall = tp/K.clip(tp_fp,K.epsilon(),tp_fp), tp/K.clip(tp+fn,K.epsilon(),tp+fn) \n",
    "    fbeta = 1.-(1.+beta2)*(precision*recall)/K.clip(beta2*precision+recall,K.epsilon())\n",
    "    return(1.-(1.+beta2)*(precision*recall)/K.clip(beta2*precision+recall,K.epsilon(),beta2*precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildModel (iSize,rSize) :\n",
    "    model = ResNetXX(input_shape=iSize,classes=rSize)\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"nadam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred]) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trY_small = trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 10, 0, 9], (40479, 4))"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr = [labels.index(i) for i in weather_labels]; trY_small = trY[:,wr]; \n",
    "wr,trY_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3) 4 2109892\n"
     ]
    }
   ],
   "source": [
    "iSize, rSize, result = (trX.shape[1],trX.shape[2],trX.shape[3]), trY_small.shape[1], []\n",
    "\n",
    "model1 = buildModel(iSize,rSize)\n",
    "\n",
    "tr1=np.sum([K.count_params(p) for p in set(model1.trainable_weights)])\n",
    "tr2=np.sum([K.count_params(p) for p in set(model1.non_trainable_weights)])\n",
    "\n",
    "print(iSize,rSize,tr1+tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_padding2d_296\n",
      "conv1\n",
      "bn_conv1\n",
      "activation_1274\n",
      "max_pooling2d_73\n",
      "zero_padding2d_297\n",
      "res2a_branch2a\n",
      "bn2a_branch2a\n",
      "activation_1275\n",
      "res2a_branch2b\n",
      "bn2a_branch2b\n",
      "res2a_branch1\n",
      "activation_1276\n",
      "bn2a_branch1\n",
      "add_400\n",
      "activation_1277\n",
      "res2b_branch2a\n",
      "bn2b_branch2a\n",
      "activation_1278\n",
      "res2b_branch2b\n",
      "bn2b_branch2b\n",
      "activation_1279\n",
      "add_401\n",
      "activation_1280\n",
      "zero_padding2d_298\n",
      "res3a_branch2a\n",
      "bn3a_branch2a\n",
      "activation_1281\n",
      "res3a_branch2b\n",
      "bn3a_branch2b\n",
      "res3a_branch1\n",
      "activation_1282\n",
      "bn3a_branch1\n",
      "add_402\n",
      "activation_1283\n",
      "res3b_branch2a\n",
      "bn3b_branch2a\n",
      "activation_1284\n",
      "res3b_branch2b\n",
      "bn3b_branch2b\n",
      "activation_1285\n",
      "add_403\n",
      "activation_1286\n",
      "zero_padding2d_299\n",
      "res4a_branch2a\n",
      "bn4a_branch2a\n",
      "activation_1287\n",
      "res4a_branch2b\n",
      "bn4a_branch2b\n",
      "res4a_branch1\n",
      "activation_1288\n",
      "bn4a_branch1\n",
      "add_404\n",
      "activation_1289\n",
      "res4b_branch2a\n",
      "bn4b_branch2a\n",
      "activation_1290\n",
      "res4b_branch2b\n",
      "bn4b_branch2b\n",
      "activation_1291\n",
      "add_405\n",
      "activation_1292\n",
      "avg_pool\n",
      "fc1000 flatten_76\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to create file (Unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-512-0b9e81c00459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#len(model1.layers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data-Keras/weights_initial_resnet_sigmoid_17.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   2500\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2502\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2503\u001b[0m         \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-4rPeHA-build/h5py/_objects.c:2684)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-4rPeHA-build/h5py/_objects.c:2642)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create (/tmp/pip-4rPeHA-build/h5py/h5f.c:2097)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to create file (Unable to truncate a file which is already open)"
     ]
    }
   ],
   "source": [
    "if False :\n",
    "    \n",
    "    #model.load_weights('../Data-Keras/weights_of_best_model_sigmoid_nadam_4.hdf5') ## best weight\n",
    "    model1 = buildModel(iSize,17) #rSize)\n",
    "    model2 = buildModel(iSize,4) #rSize)\n",
    "    model2.load_weights('../Data-Keras/weights_of_best_model_sigmoid_nadam_4.hdf5') ## best weight\n",
    "    \n",
    "    i=0\n",
    "    for ii in model2.layers :\n",
    "        #print(ii.name);\n",
    "        if (i>0) and (i<(len(model2.layers)-2)) :\n",
    "            print(i,ii.name);\n",
    "            model1.layers[i].set_weights(ii.get_weights())\n",
    "        i = i+1\n",
    "    print(model1.layers[len(model1.layers)-1].name,model1.layers[len(model1.layers)-2].name)\n",
    "    #len(model1.layers)\n",
    "    #model1.save_weights('../Data-Keras/weights_initial_resnet_sigmoid_17.h5') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40479, 17)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trY_small.shape\n",
    "#model1.load_weights('../Data-Keras/weights_initial_resnet_sigmoid_17.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-22 11:04:24.335693 nodes= 2109892\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_fbeta_pred improved from -inf to 0.84590, saving model to ../Data-Keras/weights_of_best_model_sigmoid_nadam_17.hdf5\n",
      "114s - loss: 0.0745 - fbeta_pred: 0.8410 - val_loss: 0.0739 - val_fbeta_pred: 0.8459\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0704 - fbeta_pred: 0.8532 - val_loss: 0.0728 - val_fbeta_pred: 0.8456\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0705 - fbeta_pred: 0.8530 - val_loss: 0.0745 - val_fbeta_pred: 0.8333\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0702 - fbeta_pred: 0.8545 - val_loss: 0.0846 - val_fbeta_pred: 0.7901\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0702 - fbeta_pred: 0.8547 - val_loss: 0.0757 - val_fbeta_pred: 0.8273\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0703 - fbeta_pred: 0.8541 - val_loss: 0.0746 - val_fbeta_pred: 0.8348\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0701 - fbeta_pred: 0.8554 - val_loss: 0.0834 - val_fbeta_pred: 0.7970\n",
      "Epoch 8/100\n",
      "Epoch 00007: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0702 - fbeta_pred: 0.8548 - val_loss: 0.0787 - val_fbeta_pred: 0.8192\n",
      "Epoch 9/100\n",
      "Epoch 00008: val_fbeta_pred improved from 0.84590 to 0.85659, saving model to ../Data-Keras/weights_of_best_model_sigmoid_nadam_17.hdf5\n",
      "101s - loss: 0.0700 - fbeta_pred: 0.8557 - val_loss: 0.0713 - val_fbeta_pred: 0.8566\n",
      "Epoch 10/100\n",
      "Epoch 00009: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0700 - fbeta_pred: 0.8556 - val_loss: 0.0794 - val_fbeta_pred: 0.8208\n",
      "Epoch 11/100\n",
      "Epoch 00010: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0702 - fbeta_pred: 0.8538 - val_loss: 0.0931 - val_fbeta_pred: 0.7739\n",
      "Epoch 12/100\n",
      "Epoch 00011: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0699 - fbeta_pred: 0.8575 - val_loss: 0.0701 - val_fbeta_pred: 0.8500\n",
      "Epoch 13/100\n",
      "Epoch 00012: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8556 - val_loss: 0.0849 - val_fbeta_pred: 0.8174\n",
      "Epoch 14/100\n",
      "Epoch 00013: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0701 - fbeta_pred: 0.8559 - val_loss: 0.0713 - val_fbeta_pred: 0.8548\n",
      "Epoch 15/100\n",
      "Epoch 00014: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0704 - fbeta_pred: 0.8540 - val_loss: 0.0727 - val_fbeta_pred: 0.8402\n",
      "Epoch 16/100\n",
      "Epoch 00015: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0700 - fbeta_pred: 0.8556 - val_loss: 0.0712 - val_fbeta_pred: 0.8519\n",
      "Epoch 17/100\n",
      "Epoch 00016: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0700 - fbeta_pred: 0.8554 - val_loss: 0.0756 - val_fbeta_pred: 0.8404\n",
      "Epoch 18/100\n",
      "Epoch 00017: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0696 - fbeta_pred: 0.8580 - val_loss: 0.0943 - val_fbeta_pred: 0.7792\n",
      "Epoch 19/100\n",
      "Epoch 00018: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0697 - fbeta_pred: 0.8576 - val_loss: 0.0723 - val_fbeta_pred: 0.8492\n",
      "Epoch 20/100\n",
      "Epoch 00019: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0699 - fbeta_pred: 0.8561 - val_loss: 0.0805 - val_fbeta_pred: 0.8083\n",
      "Epoch 21/100\n",
      "Epoch 00020: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0702 - fbeta_pred: 0.8539 - val_loss: 0.0827 - val_fbeta_pred: 0.8004\n",
      "Epoch 22/100\n",
      "Epoch 00021: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8553 - val_loss: 0.0889 - val_fbeta_pred: 0.7740\n",
      "Epoch 23/100\n",
      "Epoch 00022: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0699 - fbeta_pred: 0.8566 - val_loss: 0.0918 - val_fbeta_pred: 0.7619\n",
      "Epoch 24/100\n",
      "Epoch 00023: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0697 - fbeta_pred: 0.8568 - val_loss: 0.0709 - val_fbeta_pred: 0.8524\n",
      "Epoch 25/100\n",
      "Epoch 00024: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8575 - val_loss: 0.0721 - val_fbeta_pred: 0.8457\n",
      "Epoch 26/100\n",
      "Epoch 00025: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0699 - fbeta_pred: 0.8567 - val_loss: 0.0712 - val_fbeta_pred: 0.8553\n",
      "Epoch 27/100\n",
      "Epoch 00026: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8558 - val_loss: 0.0905 - val_fbeta_pred: 0.7669\n",
      "Epoch 28/100\n",
      "Epoch 00027: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8564 - val_loss: 0.0757 - val_fbeta_pred: 0.8349\n",
      "Epoch 29/100\n",
      "Epoch 00028: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8567 - val_loss: 0.0845 - val_fbeta_pred: 0.8122\n",
      "Epoch 30/100\n",
      "Epoch 00029: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8557 - val_loss: 0.0812 - val_fbeta_pred: 0.8037\n",
      "Epoch 31/100\n",
      "Epoch 00030: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0697 - fbeta_pred: 0.8571 - val_loss: 0.0719 - val_fbeta_pred: 0.8434\n",
      "Epoch 32/100\n",
      "Epoch 00031: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0698 - fbeta_pred: 0.8557 - val_loss: 0.0873 - val_fbeta_pred: 0.7854\n",
      "Epoch 33/100\n",
      "Epoch 00032: val_fbeta_pred did not improve\n",
      "100s - loss: 0.0697 - fbeta_pred: 0.8561 - val_loss: 0.0744 - val_fbeta_pred: 0.8412\n",
      "Epoch 00032: early stopping\n",
      "2017-05-22 12:01:10.250043 fbeta2s= 0.690694745722 0.841162835233\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "epochs  = 100\n",
    "verbose = 2\n",
    "batch_size = 64\n",
    "initial = 0\n",
    "\n",
    "if (tr1+tr2)>14500000 : \n",
    "    print(datetime.datetime.now(),pp,tr1+tr2,'(badly)')\n",
    "else :        \n",
    "        \n",
    "    filepath=\"../Data-Keras/weights.{epoch:02d}-{fbeta_pred:.2f}-{val_fbeta_pred:.2f}.hdf5\"\n",
    "    filepath=\"../Data-Keras/weights_of_best_model_softmax.hdf5\"\n",
    "    filepath=\"../Data-Keras/weights_of_best_model_sigmoid_nadam_4.hdf5\"\n",
    "    filepath=\"../Data-Keras/weights_of_best_model_sigmoid_nadam_17.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_fbeta_pred', verbose=1, save_best_only=True, mode='max')\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_binary_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    print(datetime.datetime.now(),'nodes=',tr1+tr2)\n",
    "    hist_softmax  = model1.fit(trX,trY_small,\n",
    "                        initial_epoch=initial,\n",
    "                        epochs=epochs+initial, batch_size=batch_size, validation_split=0.2, \n",
    "                        #callbacks=[early_stopping,reduce_lr,checkpoint],\n",
    "                        callbacks=[checkpoint,early_stopping],\n",
    "                        verbose=verbose)\n",
    "    \n",
    "    trP = model1.predict(trX, batch_size=batch_size)\n",
    "    \n",
    "    fbeta2score=fbeta_score(trY_small, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "    fbeta2pred =K.get_value(fbeta_pred(trY_small.astype(np.float64),trP.astype(np.float64)))\n",
    "    #print(datetime.datetime.now(),pp,hist1.history['fbeta_pred'][-1],hist1.history['val_fbeta_pred'][-1],'fbeta2s=',fbeta2score,fbeta2pred)\n",
    "    print(datetime.datetime.now(),'fbeta2s=',fbeta2score,fbeta2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04438319368251431, 0.91760892008141293]\n",
      "(40479, 4)\n",
      "(40479, 4)\n",
      "fbeta_score= 0.89923993511\n",
      "fbeta_pred = 0.9176300733\n"
     ]
    }
   ],
   "source": [
    "#model1.load_weights('../Data-Keras/weights.07-0.86-0.83.hdf5') ##\n",
    "#model1.load_weights('../Data-Keras/weights_of_best_model_softmax.hdf5') ## best weights\n",
    "#model1.load_weights('../Data-Keras/weights_of_best_model_sigmoid_nadam_4.hdf5') ## best weights\n",
    "model1.load_weights('../Data-Keras/weights_of_best_model_sigmoid_nadam_17.hdf5') ## best weights\n",
    "print(model1.evaluate(trX,trY_small,verbose=2,batch_size=batch_size))\n",
    "trP = model1.predict(trX, batch_size=batch_size)\n",
    "print(trY_small.shape)\n",
    "print(trP.shape)\n",
    "print('fbeta_score=',fbeta_score(trY_small, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY_small.astype(np.float64),trP.astype(np.float64),OK1=0.2)))\n",
    "#plt.hist(trP.flatten()); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model1.load_weights('../Data-Keras/weights_of_best_model_softmax.hdf5') ## best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33942034220962897, 0.85421489789736316]\n",
      "(40479, 17)\n",
      "(40479, 17)\n",
      "fbeta_score= 0.668507353332\n",
      "fbeta_pred = 0.775708254265\n"
     ]
    }
   ],
   "source": [
    "print(model1.evaluate(trX,trY,verbose=2,batch_size=batch_size))\n",
    "trP = model1.predict(trX, batch_size=batch_size)\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64),OK1=0.2)))\n",
    "#plt.hist(trP.flatten()); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta_score1= 0.424836601307\n",
      "fbeta_score2= 0.424836601307\n",
      "ten true  [[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "ten roun  [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      " pre= 0.333333277778  recall= 0.9999995  tp= 2.0  fn= 0.0  tp+fp= 6.0\n",
      "fbeta_pred  = 0.714285153061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8),\n",
       " 0.66138786)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trPP = trP[0:2]\n",
    "trYY = trY[0:2]\n",
    "print('fbeta_score1=',fbeta_score(trYY, np.array(trPP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_score2=',fbeta_score(trYY, np.round(trPP+(0.5-0.2)).astype(np.uint8), beta=2, average='samples'))\n",
    "print('fbeta_pred  =',K.get_value(fbeta_pred(trYY.astype(np.float64),trPP.astype(np.float64),printOK=True,OK1=0.2)))\n",
    "trYY,np.round(trPP+(0.5-0.2)).astype(np.uint8),trPP.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112068965517241"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*0.33*1.0/(4*0.33+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_model(model,'../Data-Keras/train-model-2D-2-v2-all.h5')\n",
    "model.save_weights('../Data-Keras/train-model-2D-2-v2-weights-resnet.h5')  # save weights after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-21 04:33:29.868062 0 --> 12 0.701061456789 [0.69027836079096705, 0.70106145678882503, 0.70097333966554642]\n",
      "2017-05-21 04:34:46.820765 1 --> 18 0.970360673025 [0.97028825116911765, 0.97036067302471052, 0.96925310898663897]\n",
      "2017-05-21 04:36:09.395277 2 --> 14 0.787397912978 [0.78418708954033389, 0.78739791297818562, 0.78739256385420475]\n",
      "2017-05-21 04:37:37.568402 3 --> 14 0.960480052616 [0.96047590680428074, 0.96048005261587177, 0.95978748962279092]\n",
      "2017-05-21 04:39:11.964028 4 --> 20 0.660986706165 [0.65612739214963112, 0.66098670616463051, 0.66098097939318778]\n",
      "2017-05-21 04:40:52.131403 5 --> 7 0.598958064523 [0.58823505932796361, 0.59895806452306344, 0.58685894275107442]\n",
      "2017-05-21 04:42:37.846685 6 --> 6 0.713505952554 [0.70583410290540627, 0.71350595255370186, 0.70250832497474558]\n",
      "2017-05-21 04:44:29.077766 7 --> 9 0.585068476993 [0.58490668135597612, 0.58506847699323372, 0.56409315329175058]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-c420cc24f3c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtrPP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrPY\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#x = fbeta_score(trY[:,0], np.array(trP[:,0] > 0.1*ii), beta=2, average='samples')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbeta_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrYY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrPP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2088\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m     \"\"\"\n\u001b[0;32m-> 2090\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \"\"\"\n\u001b[0;32m--> 569\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3739\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3740\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3741\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 run_metadata):\n\u001b[1;32m   1016\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1066\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rr, rrx = [], []; trP = model.predict(trX, batch_size=128)\n",
    "for i in range(trP.shape[1]) :\n",
    "    xx = [];\n",
    "    trYY = trY[:,i].astype(np.float64)\n",
    "    trPY = trP[:,i]\n",
    "    for ii in range(100) :\n",
    "        trPP = (trPY>0.01*ii).astype(np.float64)\n",
    "        #x = fbeta_score(trY[:,0], np.array(trP[:,0] > 0.1*ii), beta=2, average='samples')\n",
    "        x = K.get_value(fbeta_pred(trYY,trPP))\n",
    "        xx.append(x)\n",
    "    rrr = np.array(xx).argmax();\n",
    "    rr.append(rrr)\n",
    "    rrx.append(xx[rrr])\n",
    "    print(datetime.datetime.now(),i,'-->',rrr,xx[rrr],xx[(rrr-1):(rrr+2)])\n",
    "    #print(xx);\n",
    "    #plt.plot(np.array(xx)); plt.show()\n",
    "trM = np.array(rr)/100.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fbeta_pred = 0.852262799278\n",
      "11 fbeta_pred = 0.85860954729\n",
      "12 fbeta_pred = 0.863598218022\n",
      "13 fbeta_pred = 0.867415899366\n",
      "14 fbeta_pred = 0.870350360537\n",
      "15 fbeta_pred = 0.872115891222\n",
      "16 fbeta_pred = 0.873628123981\n",
      "17 fbeta_pred = 0.873875118136\n",
      "18 fbeta_pred = 0.872978397105\n",
      "19 fbeta_pred = 0.87111173067\n",
      "20 fbeta_pred = 0.868017511052\n",
      "21 fbeta_pred = 0.863709761266\n",
      "22 fbeta_pred = 0.857957813086\n",
      "23 fbeta_pred = 0.849860113255\n",
      "24 fbeta_pred = 0.841126318708\n",
      "25 fbeta_pred = 0.831194119535\n",
      "26 fbeta_pred = 0.820387882662\n",
      "27 fbeta_pred = 0.809047783749\n",
      "28 fbeta_pred = 0.797786636371\n",
      "29 fbeta_pred = 0.787032754149\n"
     ]
    }
   ],
   "source": [
    "for iii in range(10,30) :\n",
    "    print(iii,'fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64),OK1=iii/100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights-resnet.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191\n",
      "2017-05-21 04:51:36.884908 61191 61191\n",
      "2017-05-21 04:51:44.366410 \t 0 \t 5000 \t test_14523.jpg \t \n",
      "2017-05-21 04:51:57.129539 \t 1 \t 10000 \t test_19029.jpg \t (10000, 17)\n",
      "2017-05-21 04:52:04.310439 \t 1 \t 15000 \t test_23524.jpg \t (10000, 17)\n",
      "2017-05-21 04:52:16.162226 \t 2 \t 20000 \t test_28015.jpg \t (20000, 17)\n",
      "2017-05-21 04:52:22.850290 \t 2 \t 25000 \t test_32520.jpg \t (20000, 17)\n",
      "2017-05-21 04:52:34.361601 \t 3 \t 30000 \t test_37026.jpg \t (30000, 17)\n",
      "2017-05-21 04:52:41.050391 \t 3 \t 35000 \t test_4908.jpg \t (30000, 17)\n",
      "2017-05-21 04:52:52.574351 \t 4 \t 40000 \t test_9402.jpg \t (40000, 17)\n",
      "2017-05-21 04:52:59.475271 \t 4 \t 45000 \t file_13913.jpg \t (40000, 17)\n",
      "2017-05-21 04:53:10.554489 \t 5 \t 50000 \t file_18419.jpg \t (50000, 17)\n",
      "2017-05-21 04:53:31.752280 \t 5 \t 55000 \t file_4564.jpg \t (50000, 17)\n",
      "2017-05-21 04:53:47.705018 \t 6 \t 60000 \t file_892.jpg \t (60000, 17)\n",
      "2017-05-21 04:53:50.410902\n"
     ]
    }
   ],
   "source": [
    "#nameAsk = os.listdir(teDirI); print(len(nameAsk))\n",
    "nameAsk = os.listdir(teDirJPG); print(len(nameAsk))\n",
    "trOX, trOY, i, ii, size = [], [], 0, 0, len(nameAsk)\n",
    "print(datetime.datetime.now(),len(nameAsk),size)\n",
    "for nn in nameAsk[0:size] :\n",
    "    #nf = os.path.join(teDirTIF,nn);\n",
    "    nf = os.path.join(teDirJPG,nn);\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        trOX.append(nx)\n",
    "        trOY.append(nn)\n",
    "    i += 1\n",
    "    if (i%10000==0) and (i>1) :\n",
    "        if (ii==0) :\n",
    "            trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "            trP = model.predict(trOX, batch_size=512); \n",
    "        else :\n",
    "            trOX = np.array(trOX);  trOX = trOX / 255.0\n",
    "            trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "        trOX,ii = [],ii+1;\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",ii,'\\t',i,\"\\t\",nn,'\\t',(trP.shape if ii>0 else \"\"))\n",
    "\n",
    "if (len(trOX)>0) :\n",
    "    if (ii==0) :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = model.predict(trOX, batch_size=512); \n",
    "    else :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "    trOX,ii = [],ii+1;\n",
    "    \n",
    "print(datetime.datetime.now())\n",
    "\n",
    "#assert (size!=len(trOY)), \"Wrong files {} != {}\".format(size,len(trOY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191 (61191, 17) (61191,)\n"
     ]
    }
   ],
   "source": [
    "#trOX = np.array(trOX);\n",
    "trOY = np.array([os.path.splitext(x)[0] for x in trOY]);\n",
    "print(len(nameAsk),trP.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy',trOX)\n",
    "np.save('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 32, 32, 6) (61191,)\n"
     ]
    }
   ],
   "source": [
    "trOX = np.load('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy')\n",
    "trOY = np.load('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy')\n",
    "print(trOX.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.75841929007857778,\n",
       " 1: 0.98263848366246676,\n",
       " 2: 0.84722629763157453,\n",
       " 3: 0.97604678247993626,\n",
       " 4: 0.78729476795032916,\n",
       " 5: 0.78956810256787635,\n",
       " 6: 0.83083164404299403,\n",
       " 7: 0.73801616416924898,\n",
       " 8: 0.6761901702314258,\n",
       " 9: 0.86068787363532673,\n",
       " 10: 0.96403428373772715,\n",
       " 11: 0.90053737661152566,\n",
       " 12: 0.6528441526860862,\n",
       " 13: 0.86359942524081812,\n",
       " 14: 0.37037005520335736,\n",
       " 15: 0.68382329252278806,\n",
       " 16: 0.58917169677281178}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrx\n",
    "rrd=dict()\n",
    "for i in range(len(rrx)) :\n",
    "    rrd[i]=rrx[i]\n",
    "rrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Forming result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61191, 17), array([  1.51678212e-02,   2.47970134e-01,   4.04648930e-02,\n",
       "          1.49414241e-01,   4.00180258e-02,   3.28476608e-01,\n",
       "          1.54203057e-01,   1.21361157e-03,   2.60228753e-05,\n",
       "          3.93420953e-04,   2.10836772e-02,   1.34721558e-04,\n",
       "          1.17336481e-03,   4.00833051e-05,   8.84044348e-05,\n",
       "          1.29057618e-04,   2.91726406e-06], dtype=float32))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trP = model.predict(trOX, batch_size=512); \n",
    "trP.shape, trP[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "[3, 10, 0, 9] \n",
      " ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down'] \n",
      " [2.0, 0.5, 0.5, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "trM=np.array([0.0]*len(labels)); print(trM.shape)\n",
    "wr = [labels.index(i) for i in weather_labels];\n",
    "trM[:]=0.5 ### 0.17 ################ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "trM[np.array(wr)] = 2.0\n",
    "print(wr,'\\n',labels,'\\n',trM.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHfKHpZVgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe06c679d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(res), len(trOY), trOY[0:3]\n",
    "plt.hist(trP.flatten()); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'clear'] \n",
      " ['file_20521', 'clear primary'] \n",
      " [ 2.   0.5  0.5  2.   0.5  0.5  0.5  0.5  0.5  2.   2.   0.5  0.5  0.5  0.5\n",
      "  0.5  0.5] [  5.69364019e-02   1.46626368e-01   5.61825596e-02   3.07105750e-01\n",
      "   2.11413950e-01   5.84495859e-03   8.64350051e-03   1.33131153e-03\n",
      "   3.46140841e-05   1.83510408e-01   1.28348945e-02   5.12083773e-07\n",
      "   9.52941086e-03   6.62975083e-07   2.47126104e-06   7.83156437e-08\n",
      "   2.20744641e-06]\n"
     ]
    }
   ],
   "source": [
    "#trP = model.predict(trX, batch_size=512); trP=K.get_value(trP)\n",
    "res = []\n",
    "\n",
    "for i in range(trP.shape[0]) :\n",
    "    trPP = [weather_labels[trP[i,wr].argmax()]] + [labels[ii] for ii in range(len(labels)) if (trP[i,ii]>trM[ii])];\n",
    "    pp   = ' '.join(trPP)\n",
    "    ##if (pp==\"\") : print(trY[i])\n",
    "    res.append([trOY[i],pp])\n",
    "\n",
    "res.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n",
    "#print(res[4:8],'\\n',res[-4:])\n",
    "print(res[0],'\\n',res[-1],'\\n',trM,trP[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "#print(trM.tolist())\n",
    "#np.round(trP[4:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-21-05-08-35\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(res,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ResNet50(include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "    \"\"\"Instantiates the ResNet50 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    '''\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "    '''\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    '''\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "    '''\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "        \n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "        else:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1000')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
