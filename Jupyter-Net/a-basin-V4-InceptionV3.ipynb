{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## InceptionV3 проверка результативности (реализации взяты с github keras/application):\n",
    "##                  https://github.com/fchollet/keras/tree/master/keras/applications\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import paths_input, formImExt, formImHist\n",
    "from estimate import confusion_matrix, getConfusion, getRocAUC, getProb01, getProbX01, getTh, estimateResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model, Model, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Data/test-jpg-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, teDirJPG, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trOX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d1d26fa2a73c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrOX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrOY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trOX' is not defined"
     ]
    }
   ],
   "source": [
    "del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy',trX)\n",
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 128, 128, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "if False :\n",
    "    ###trXX = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-XX.npy')\n",
    "    ###trYY = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    trXX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "    trYY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "\n",
    "    trX, trY = trXX[trYY[:,9]==0], trYY[trYY[:,9]==0] # not cloudy == 9 feature\n",
    "    trY=trY[:,range(0,9)+range(10,17)] # --cloudy <> 9\n",
    "    del trXX,trYY\n",
    "    #print(trXX.shape,trYY.shape)\n",
    "    print(trX.shape,trY.shape)\n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX-short.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY-short.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-XX-tif.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    \n",
    "if False : # VGG16-19\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "    \n",
    "    \n",
    "if False :\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    trX0 = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-tif.npy')\n",
    "    trX1 = np.load('../Data-Keras/Datas/train-model-2D-128x128x8-XX-tif.npy')\n",
    "    #trX1 = trX1[:,:,:,3:]\n",
    "    trX  = np.zeros((trX0.shape[0],trX0.shape[1],trX0.shape[2],trX0.shape[3]+trX1.shape[3]),dtype=np.uint8)\n",
    "    print (trX0.shape,trX1.shape,trX.shape)\n",
    "    trX[:,:,:,0:3] = trX0; del trX0\n",
    "    trX[:,:,:,3:]  = trX1; del trX1\n",
    "    \n",
    "if False :\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    trX0 = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX-tif.npy')\n",
    "    trX1 = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-XX-tif.npy')\n",
    "    #trX1 = trX1[:,:,:,3:]\n",
    "    trX  = np.zeros((trX0.shape[0],trX0.shape[1],trX0.shape[2],trX0.shape[3]+trX1.shape[3]),dtype=np.uint8)\n",
    "    print (trX0.shape,trX1.shape,trX.shape)\n",
    "    trX[:,:,:,0:3] = trX0\n",
    "    trX[:,:,:,3:]  = trX1\n",
    "    #del trX0,trX1\n",
    "    \n",
    "if True :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-tif.npy').astype(np.float32)\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY-tif.npy')\n",
    "    \n",
    "    # Xception pre-processing\n",
    "    \n",
    "    trX  /= 255.\n",
    "    trX  -= 0.5\n",
    "    trX  *= 2.\n",
    "    \n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del trX0,trX1,trX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Для совместной обработки tif\n",
    "if False :\n",
    "    trX00 = trX0.copy()\n",
    "    for i in range(trX00.shape[1]) :\n",
    "        for j in range(trX00.shape[2]) :\n",
    "            trX00[:,i,j,:] = trX0[:,j,i,:]\n",
    "    trX[:,:,:,0:3] = trX00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : # построение CCCI\n",
    "    trX.shape\n",
    "    ndvi_min, ndvi_max = np.zeros(trX.shape[0],dtype=np.float16), np.zeros(trX.shape[0],dtype=np.float16)\n",
    "    ccci               = np.zeros((trX.shape[0],trX.shape[1],trX.shape[2]),dtype=np.uint8)\n",
    "    for ii in range(trX.shape[0]) :\n",
    "        ndvi_min[ii], ndvi_max[ii] = trX[ii,:,:,0].min(), trX[ii,:,:,0].max()\n",
    "        ccci[ii] = (trX[ii,:,:,0]-ndvi_min[ii])/(ndvi_max[ii]-ndvi_min[ii])*256.0\n",
    "    ccci.shape\n",
    "    trX[:,:,:,3]=ccci\n",
    "    \n",
    "    ii = 50\n",
    "    #plt.imshow(np.array(ccci[ii]*256.0,dtype=np.uint8),'gray'); plt.show()\n",
    "    #plt.subplot(121);plt.imshow(ccci[ii],'gray'); plt.subplot(122);plt.hist(ccci[ii].ravel(),bins=50); \n",
    "    #plt.show()\n",
    "    plt.subplot(121);plt.imshow(trX[ii,:,:,0],'gray'); plt.subplot(122);plt.hist(trX[ii,:,:,0].ravel(),bins=30); \n",
    "    plt.show()\n",
    "    plt.subplot(121);plt.imshow(trX[ii,:,:,1],'gray'); plt.subplot(122);plt.hist(trX[ii,:,:,1].ravel(),bins=30); \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 128, 128, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape,trY.shape)\n",
    "###del trX, trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : # Берем все\n",
    "    # Берем из признаков только 4,5,6,7 - проблемные\n",
    "    trY_old = trY\n",
    "    trY=trY[:,4:8]\n",
    "    print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fbeta_pred(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def VGG19XX(include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG19 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "    \"\"\"\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        #x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        #x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        #x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "        \n",
    "        x = Dense(4096, activation='relu', name='fc1')(x) ##\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x) ## \n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg19xx')\n",
    "\n",
    "    \"\"\"\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    \"\"\"\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model11 = VGG16XX(input_shape=(128,128,12),classes=4)\n",
    "#model11.summary()\n",
    "#del model11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) 17\n"
     ]
    }
   ],
   "source": [
    "input_shape, output_classes, metric = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], 'acc'\n",
    "print(input_shape,output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del model11, model10\n",
    "from keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model10 = Xception(input_shape=input_shape,classes=output_classes,include_top=False,weights=None)\n",
    "#model11.summary()\n",
    "\n",
    "if False :\n",
    "    import h5py\n",
    "    hh5  = h5py.File('../Data-Keras/gitModels/vgg19_weights_tf_dim_ordering_tf_kernels.h5','r')\n",
    "\n",
    "    for ll in model10.layers :\n",
    "        wb   = ll.get_weights()\n",
    "        if len(wb)==2 :\n",
    "            upd  = ''\n",
    "            hg1  = hh5[ll.name]\n",
    "            hg1w = hg1.get(ll.name+\"_W_1:0\")[()]\n",
    "            hg1b = hg1.get(ll.name+\"_b_1:0\")[()]\n",
    "            if wb[0].shape==hg1w.shape : wb[0] = hg1w; upd +='1'\n",
    "            if wb[1].shape==hg1b.shape : wb[1] = hg1b; upd +='2'\n",
    "            ll.set_weights(wb)\n",
    "            print (ll.name,[iwb.shape for iwb in wb],hg1w.shape,hg1b.shape,upd)\n",
    "        #ll.set_weights([fc1W,fc1B])\n",
    "    hh5.close()\n",
    "    \n",
    "sgd = keras.optimizers.SGD(nesterov=True)\n",
    "model10.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "              optimizer=sgd, #\"nadam\", #sgd, #\"adam\", #'rmsprop',\n",
    "              metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 128, 128, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, 63, 63, 32)    864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, 63, 63, 32)    128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, 63, 63, 32)    0           block1_conv1_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, 61, 61, 64)    18432       block1_conv1_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, 61, 61, 64)    256         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, 61, 61, 64)    0           block1_conv2_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, 61, 61, 128)   8768        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, 61, 61, 128)   512         block2_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, 61, 61, 128)   0           block2_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, 61, 61, 128)   17536       block2_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, 61, 61, 128)   512         block2_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 31, 31, 128)   8192        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 31, 31, 128)   0           block2_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 31, 31, 128)   512         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 31, 31, 128)   0           block2_pool[0][0]                \n",
      "                                                                   batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, 31, 31, 128)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, 31, 31, 256)   33920       block3_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, 31, 31, 256)   1024        block3_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, 31, 31, 256)   0           block3_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, 31, 31, 256)   67840       block3_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, 31, 31, 256)   1024        block3_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 16, 16, 256)   32768       add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 16, 16, 256)   0           block3_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 16, 16, 256)   1024        conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 16, 16, 256)   0           block3_pool[0][0]                \n",
      "                                                                   batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, 16, 16, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, 16, 16, 728)   188672      block4_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, 16, 16, 728)   2912        block4_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, 16, 16, 728)   0           block4_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, 16, 16, 728)   536536      block4_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, 16, 16, 728)   2912        block4_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 8, 8, 728)     186368      add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 8, 8, 728)     0           block4_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 8, 8, 728)     2912        conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 8, 8, 728)     0           block4_pool[0][0]                \n",
      "                                                                   batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, 8, 8, 728)     0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, 8, 8, 728)     536536      block5_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, 8, 8, 728)     2912        block5_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, 8, 8, 728)     0           block5_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, 8, 8, 728)     536536      block5_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, 8, 8, 728)     2912        block5_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, 8, 8, 728)     0           block5_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, 8, 8, 728)     536536      block5_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, 8, 8, 728)     2912        block5_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 8, 8, 728)     0           block5_sepconv3_bn[0][0]         \n",
      "                                                                   add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, 8, 8, 728)     0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, 8, 8, 728)     536536      block6_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, 8, 8, 728)     2912        block6_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, 8, 8, 728)     0           block6_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, 8, 8, 728)     536536      block6_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, 8, 8, 728)     2912        block6_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, 8, 8, 728)     0           block6_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, 8, 8, 728)     536536      block6_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, 8, 8, 728)     2912        block6_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 8, 8, 728)     0           block6_sepconv3_bn[0][0]         \n",
      "                                                                   add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, 8, 8, 728)     0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, 8, 8, 728)     536536      block7_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, 8, 8, 728)     2912        block7_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, 8, 8, 728)     0           block7_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, 8, 8, 728)     536536      block7_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, 8, 8, 728)     2912        block7_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, 8, 8, 728)     0           block7_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, 8, 8, 728)     536536      block7_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, 8, 8, 728)     2912        block7_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 8, 8, 728)     0           block7_sepconv3_bn[0][0]         \n",
      "                                                                   add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, 8, 8, 728)     0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, 8, 8, 728)     536536      block8_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, 8, 8, 728)     2912        block8_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, 8, 8, 728)     0           block8_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, 8, 8, 728)     536536      block8_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, 8, 8, 728)     2912        block8_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, 8, 8, 728)     0           block8_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, 8, 8, 728)     536536      block8_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, 8, 8, 728)     2912        block8_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 8, 8, 728)     0           block8_sepconv3_bn[0][0]         \n",
      "                                                                   add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, 8, 8, 728)     0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, 8, 8, 728)     536536      block9_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, 8, 8, 728)     2912        block9_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, 8, 8, 728)     0           block9_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, 8, 8, 728)     536536      block9_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, 8, 8, 728)     2912        block9_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, 8, 8, 728)     0           block9_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, 8, 8, 728)     536536      block9_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, 8, 8, 728)     2912        block9_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 8, 8, 728)     0           block9_sepconv3_bn[0][0]         \n",
      "                                                                   add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, 8, 8, 728)     0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, 8, 8, 728)     536536      block10_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, 8, 8, 728)     2912        block10_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, 8, 8, 728)     0           block10_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, 8, 8, 728)     536536      block10_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, 8, 8, 728)     2912        block10_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, 8, 8, 728)     0           block10_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, 8, 8, 728)     536536      block10_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, 8, 8, 728)     2912        block10_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 8, 8, 728)     0           block10_sepconv3_bn[0][0]        \n",
      "                                                                   add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, 8, 8, 728)     0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, 8, 8, 728)     536536      block11_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, 8, 8, 728)     2912        block11_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, 8, 8, 728)     0           block11_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, 8, 8, 728)     536536      block11_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, 8, 8, 728)     2912        block11_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation (None, 8, 8, 728)     0           block11_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, 8, 8, 728)     536536      block11_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, 8, 8, 728)     2912        block11_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 8, 8, 728)     0           block11_sepconv3_bn[0][0]        \n",
      "                                                                   add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, 8, 8, 728)     0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, 8, 8, 728)     536536      block12_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, 8, 8, 728)     2912        block12_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, 8, 8, 728)     0           block12_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, 8, 8, 728)     536536      block12_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, 8, 8, 728)     2912        block12_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, 8, 8, 728)     0           block12_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, 8, 8, 728)     536536      block12_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, 8, 8, 728)     2912        block12_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 8, 8, 728)     0           block12_sepconv3_bn[0][0]        \n",
      "                                                                   add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, 8, 8, 728)     0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, 8, 8, 728)     536536      block13_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, 8, 8, 728)     2912        block13_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, 8, 8, 728)     0           block13_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, 8, 8, 1024)    752024      block13_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, 8, 8, 1024)    4096        block13_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 4, 4, 1024)    745472      add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, 4, 4, 1024)    0           block13_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 4, 4, 1024)    4096        conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 4, 4, 1024)    0           block13_pool[0][0]               \n",
      "                                                                   batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, 4, 4, 1536)    1582080     add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, 4, 4, 1536)    6144        block14_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, 4, 4, 1536)    0           block14_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, 4, 4, 2048)    3159552     block14_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, 4, 4, 2048)    8192        block14_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, 4, 4, 2048)    0           block14_sepconv2_bn[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : model10.load_weights('../Data-Keras/Models/model-Alex-weights-128x128x3.h5', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : \n",
    "    sweight  = np.zeros(trY.shape[0],dtype=np.float32);\n",
    "    sweight[:]  = 1.0\n",
    "    sweight[trY[:,0]==1] = 0.35\n",
    "    sweight[trY[:,1]==1] = 0.25\n",
    "    sweight[trY[:,2]==1] = 0.15\n",
    "    sweight[trY[:,3]==1] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-13 00:34:42.483393 20861480\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected block14_sepconv2_act to have 4 dimensions, but got array with shape (5000, 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d0e1790b2fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;31m#initial_epoch=5,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     verbose=verbose)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m##trP = model1.predict(trX, batch_size=128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1307\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1310\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1311\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected block14_sepconv2_act to have 4 dimensions, but got array with shape (5000, 17)"
     ]
    }
   ],
   "source": [
    "epochs     = 5\n",
    "verbose    = 2\n",
    "batch_size = 128\n",
    "stopping   = 10\n",
    "\n",
    "prefixTemp = 'xc-jpg-128x128x3'     \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=stopping,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "filepath=\"../Temp/Temp/\"+prefixTemp+\"-weights.{epoch:02d}-acc={\"+metric+\":.4f}-val_acc={val_\"+metric+\":.4f}-.hdf5\"\n",
    "##checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=metric, verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "tr1    = np.sum([K.count_params(p) for p in set(model10.trainable_weights)])\n",
    "tr2    = np.sum([K.count_params(p) for p in set(model10.non_trainable_weights)])\n",
    "\n",
    "step = 5000\n",
    "low  = 0\n",
    "high = low+step\n",
    "\n",
    "xxyy = 0\n",
    "#trXX = trX #[trY[:,xxyy]==1]\n",
    "#trYY = trY #[trY[:,xxyy]==1]\n",
    "\n",
    "print(datetime.datetime.now(),tr1+tr2)\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "#hist1  = model10.fit(trX,trY,\n",
    "                    #sample_weight=sweight[low:high],\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.20, \n",
    "                    #initial_epoch=5,\n",
    "                    callbacks=[early_stopping,checkpoint, reduce_lr],\n",
    "                    verbose=verbose)\n",
    "\n",
    "##trP = model1.predict(trX, batch_size=128)\n",
    "##fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "##fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "print(datetime.datetime.now()) #,pp,'fbeta2s=',fbeta2score,fbeta2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40479, 128, 128, 3), (40479, 17))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape, trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 11.3 s, total: 33.7 s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%time trP = model10.predict(trX, batch_size=batch_size)\n",
    "trP01       = getProb01(trP)\n",
    "th, _       = getTh(trY,trP)\n",
    "trP01x      = getProbX01(trP,th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 17)\n",
      "(40479, 17)\n",
      "fbeta_score= 0.223606358247\n",
      "fbeta_pred = 0.42286061861\n",
      "fbeta_score= 0.924543623725\n",
      "fbeta_pred = 0.923238668576\n"
     ]
    }
   ],
   "source": [
    "#print(model10.evaluate(trX,trY,verbose=2,batch_size=batch_size))\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "#print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "#print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.5, beta=2, average='samples'))\n",
    "##-------------\n",
    "print('fbeta_score=',fbeta_score(trY,trP01, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP01.astype(np.float64))))\n",
    "##-------------\n",
    "if trY.shape[1]==17 :\n",
    "    print('fbeta_score=',fbeta_score(trY,trP01x, beta=2, average='samples'))\n",
    "    print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP01x.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    freeze  = ('fc1','fc2','dropout_1','dropout_2','flatten')\n",
    "    trainOK = ('input_1','predictions')\n",
    "    for layer in model10.layers :\n",
    "        #if (layer.name=='fc1') : layer.trainable = False\n",
    "        #if (layer.name=='fc2') : layer.trainable = False\n",
    "        if (layer.name in freeze) : layer.trainable = False\n",
    "        else : layer.trainable = True\n",
    "        if (layer.name in trainOK) : layer.trainable = True\n",
    "        layer.trainable = True\n",
    "        print(layer.name,layer.trainable)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True :\n",
    "    save_model(model10,'../Data-Keras/Models/model-VGG19-128x128x3-d4096xd4096.h5')\n",
    "    model10.save_weights('../Data-Keras/Models/model-VGG19-128x128x3-d4096xd4096-weights.h5')\n",
    "    if True : # best 0x90004\n",
    "        save_model(model10,'../Work/Join-XGB-NET/VGG19-LB=0x90004/model-VGG19-128x128x3-d4096xd4096.h5')\n",
    "        model10.save_weights('../Work/Join-XGB-NET/VGG19-LB=0x90004/model-VGG19-128x128x3-d4096xd4096-weights.h5')\n",
    "        np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trIP01-XX.npy',trP01)\n",
    "        np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trIP-XX.npy', trP)\n",
    "        np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trIY-YY.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 70,433,873\n",
      "Trainable params: 70,433,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.70237350e-01,   4.93190736e-01,   1.06996112e-03,\n",
       "          1.33314744e-01,   6.74560608e-04,   9.84107974e-05,\n",
       "          2.12351413e-04,   4.83186363e-04,   4.88138940e-05,\n",
       "          1.42483710e-04,   7.10203385e-05,   1.37875631e-05,\n",
       "          4.31219232e-05,   1.01183177e-05,   1.92909007e-04,\n",
       "          5.11052203e-05,   1.45314596e-04], dtype=float32),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trP[0], trY[0], trP01[0], trP01x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Результативность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.970824378073 roc=0.827535509167 not=1181 yes=1786 no=37512 true=39298 all-1-0=(0.6622-0.9929)\n",
      "1 acc=0.976555744954 roc=0.877590365212 not=949 yes=37271 no=2259 true=39530 all-1-0=(0.9935-0.7616)\n",
      "2 acc=0.917611601077 roc=0.909720294098 not=3335 yes=10955 no=26189 true=37144 all-1-0=(0.8896-0.9299)\n",
      "3 acc=0.964376590331 roc=0.949960875432 not=1442 yes=28021 no=11016 true=39037 all-1-0=(0.9856-0.9143)\n",
      "4 acc=0.937943131006 roc=0.87391779368 not=2512 yes=5728 no=32239 true=37967 all-1-0=(0.7729-0.9749)\n",
      "5 acc=0.954074952444 roc=0.807677321803 not=1859 yes=2302 no=36318 true=38620 all-1-0=(0.6290-0.9864)\n",
      "6 acc=0.942711035352 roc=0.901277662688 not=2319 yes=6718 no=31442 true=38160 all-1-0=(0.8324-0.9702)\n",
      "7 acc=0.928012055634 roc=0.768147534975 not=2914 yes=2520 no=35045 true=37565 all-1-0=(0.5629-0.9734)\n",
      "8 acc=0.994861533141 roc=0.507152201111 not=208 yes=3 no=40268 true=40271 all-1-0=(0.0144-1.0000)\n",
      "9 acc=0.990464191309 roc=0.950839323708 not=386 yes=1894 no=38199 true=40093 all-1-0=(0.9067-0.9950)\n",
      "10 acc=0.982410632674 roc=0.970772637269 not=712 yes=6917 no=32850 true=39767 all-1-0=(0.9526-0.9889)\n",
      "11 acc=0.998443637442 roc=0.759814259888 not=63 yes=52 no=40364 true=40416 all-1-0=(0.5200-0.9996)\n",
      "12 acc=0.981447170138 roc=0.627369387875 not=751 yes=222 no=39506 true=39728 all-1-0=(0.2575-0.9972)\n",
      "13 acc=0.99743076657 roc=0.910956343065 not=104 yes=279 no=40096 true=40375 all-1-0=(0.8230-0.9989)\n",
      "14 acc=0.991946441365 roc=0.543388251489 not=326 yes=29 no=40124 true=40153 all-1-0=(0.0873-0.9994)\n",
      "15 acc=0.992909903901 roc=0.647931489544 not=287 yes=101 no=40091 true=40192 all-1-0=(0.2971-0.9988)\n",
      "16 acc=0.997702512414 roc=0.545868839103 not=93 yes=9 no=40377 true=40386 all-1-0=(0.0918-0.9999)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01x,printOK=True) # 40000 jpg128 (epoch=40,features=17) VGG19 d4096+d4096 +weights+imnet LB=0.90004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trOX  = np.load('../Data-Keras/Datas/test-model-2D-128x128x3-jpg-XX.npy').astype(np.float16)\n",
    "trOY  = np.load('../Data-Keras/Datas/test-model-2D-128x128x3-jpg-YY.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Препроцессорная обработка данных\n",
    "\n",
    "trOX  = trOX[:, :, :, ::-1] # RGB --> BGR\n",
    "\n",
    "##trX  = np.array(trX,dtype=np.float16)\n",
    "trOX[:, :, :, 0] -= 103.939\n",
    "trOX[:, :, :, 1] -= 116.779\n",
    "trOX[:, :, :, 2] -= 123.68\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  Построение решения для test массива на основе уровней прохождения (эффект почему-то дают)\n",
    "#    Построенное решение 01 полное с учетом погодных критериев [0,3,9,10]\n",
    "#        и особенности критерия cloudy (посмотреть и сменить можно в getProbX01)\n",
    "#        Построение критериев прохождения в getTh\n",
    "#\n",
    "\n",
    "# test\n",
    "trOP = model10.predict(trOX, batch_size=batch_size)\n",
    "\n",
    "# Уровни прохождения & решение\n",
    "trO01   = getProbX01(trOP,th)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#trO01[0:3],np.array(th),trOP[0:3]\n",
    "if True :\n",
    "    np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trO01-OX.npy',trO01)\n",
    "    np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trOP-OX.npy', trOP)\n",
    "    np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trOY-OY.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Строим результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trZ = trO01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for i in range(trZ.shape[0]) :\n",
    "    temp = [labels[ii] for ii in range(trZ.shape[1]) if trZ[i,ii]==1];\n",
    "    temp = ' '.join(temp)\n",
    "    temp_list.append([trOY[i],temp])\n",
    "temp_list.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['test_0', 'primary clear'],\n",
       " ['test_1', 'primary clear'],\n",
       " ['test_2', 'primary partly_cloudy'],\n",
       " ['test_3', 'primary clear'],\n",
       " ['test_4', 'cloudy']]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12-15-25-40\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(temp_list,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                   tags\n",
       "0     test_0          primary clear\n",
       "1     test_1          primary clear\n",
       "2     test_2  primary partly_cloudy\n",
       "3     test_3          primary clear\n",
       "4     test_4                 cloudy"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Склад барахла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Skip to content\n",
    "Features Business Explore Marketplace Pricing\n",
    "This repository\n",
    "Search\n",
    "Sign in or Sign up\n",
    " Watch 1,176  Star 17,415  Fork 6,223 fchollet/keras\n",
    " Code  Issues 1,167  Pull requests 36  Projects 1  Wiki Insights \n",
    "Branch: master Find file Copy pathkeras/keras/applications/vgg19.py\n",
    "bac1637  on 22 May\n",
    "@taehoonlee taehoonlee Fix typos (#6702)\n",
    "4 contributors @fchollet @taehoonlee @singlas @ozancaglayan\n",
    "RawBlameHistory     \n",
    "193 lines (167 sloc)  8.29 KB\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"VGG19 model for Keras.\n",
    "# Reference\n",
    "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "\n",
    "from ..models import Model\n",
    "from ..layers import Flatten\n",
    "from ..layers import Dense\n",
    "from ..layers import Input\n",
    "from ..layers import Conv2D\n",
    "from ..layers import MaxPooling2D\n",
    "from ..layers import GlobalAveragePooling2D\n",
    "from ..layers import GlobalMaxPooling2D\n",
    "from ..engine.topology import get_source_inputs\n",
    "from ..utils import layer_utils\n",
    "from ..utils.data_utils import get_file\n",
    "from .. import backend as K\n",
    "from .imagenet_utils import decode_predictions\n",
    "from .imagenet_utils import preprocess_input\n",
    "from .imagenet_utils import _obtain_input_shape\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG19(include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG19 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg19')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n",
    "Contact GitHub API Training Shop Blog About\n",
    "© 2017 GitHub, Inc. Terms Privacy Security Status Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def VGG16 ( include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    from keras.utils.data_utils import get_file\n",
    "    WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "    WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "    weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                        WEIGHTS_PATH,\n",
    "                        cache_subdir='models')\n",
    "weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                        WEIGHTS_PATH_NO_TOP,\n",
    "                        cache_subdir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildModel (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    if (cv2d is None) and (dense is None) and not (params is None) : cv2d, dense = params[:-2], params[-2:]\n",
    "    model = Kriz2012x3x3(model,iSize,rSize,cv2d=cv2d,dense=dense,pp=params)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "def buildModelKriz (iSize,rSize) :\n",
    "    model = Sequential()\n",
    "    \n",
    "    model = Kriz2012(model,iSize,rSize)\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    sgd = keras.optimizers.SGD(nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "                  optimizer=\"sgd\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "#from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=False)\n",
    "model10 = VGG16(weights=None,input_shape=(224,224,3),include_top=True,classes=4)\n",
    "\n",
    "#x = (Dense(512,activation='relu'))(model10)\n",
    "#model10.add(Dropout(0.25))\n",
    "#model10.add(Dense(4,activation='sigmoid'))\n",
    "\n",
    "#img_path = 'elephant.jpg'\n",
    "#img = image.load_img(img_path, target_size=(224, 224))\n",
    "#x = image.img_to_array(img)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "\n",
    "#features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
