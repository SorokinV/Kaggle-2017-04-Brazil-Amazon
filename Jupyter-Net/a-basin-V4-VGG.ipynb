{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## VGG16 и VGG19 проверка результативности (реализации взяты с github keras/application):\n",
    "##                  https://github.com/fchollet/keras/tree/master/keras/applications\n",
    "##\n",
    "## 2017-05-20\n",
    "## maximum on LB => 0.84500\n",
    "##\n",
    "## TIF - (,,6) (,,3)\n",
    "##\n",
    "## 2017-07-06\n",
    "##  TIF (64,64,6) - полная схема без выемки 09(cloudy) - то есть 17 признаков\n",
    "##  \n",
    "## 2017-07-09\n",
    "##  TIF (64,64,6) - полная схема по признакам 4,5,6,7\n",
    "##\n",
    "## 2017-07-12\n",
    "##  JPG+TIF (64x64x)==(128x128x) по результатам\n",
    "##  BatchNarmalizstion не  поднимает результат\n",
    "##  Наиболее быстрый и адекватный вариант классификационной части dense1024+dense1024\n",
    "##  Ввод новых вегетационных признаков типа CCCI не приводит к улучшению. Либо также либо чуть хуже\n",
    "##\n",
    "## 2017-07-12\n",
    "##  Проверяю полный прогон на VGG19 (для очистки совести и перехожу на другое)\n",
    "##\n",
    "## 2017-07-12\n",
    "##  Проверил! LB=0.90004. Вставил VGG19 на наборе jpg128 + подставил насильственно веса от imagenet. Работает на train 9 часов.\n",
    "##  Необходима специализированная препроцессорная обработка для imagenet (RGB-->BGR; минус спец среднее из изображений)\n",
    "##\n",
    "## 2017-07-15\n",
    "##  Вернулся после неудач с другим сетями\n",
    "##\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import paths_input, formImExt, formImHist\n",
    "from estimate import confusion_matrix, getConfusion, getRocAUC, getProb01, getProbX01, getTh, estimateResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model, Model, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Data/test-jpg-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, teDirJPG, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trOX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d1d26fa2a73c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrOX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrOY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trOX' is not defined"
     ]
    }
   ],
   "source": [
    "del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy',trX)\n",
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 128, 128, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "if False :\n",
    "    ###trXX = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-XX.npy')\n",
    "    ###trYY = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    trXX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "    trYY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "\n",
    "    trX, trY = trXX[trYY[:,9]==0], trYY[trYY[:,9]==0] # not cloudy == 9 feature\n",
    "    trY=trY[:,range(0,9)+range(10,17)] # --cloudy <> 9\n",
    "    del trXX,trYY\n",
    "    #print(trXX.shape,trYY.shape)\n",
    "    print(trX.shape,trY.shape)\n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX-short.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY-short.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-XX-tif.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    \n",
    "if False : # VGG16-19\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "    \n",
    "    \n",
    "if False :\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    trX0 = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-tif.npy')\n",
    "    trX1 = np.load('../Data-Keras/Datas/train-model-2D-128x128x8-XX-tif.npy')\n",
    "    #trX1 = trX1[:,:,:,3:]\n",
    "    trX  = np.zeros((trX0.shape[0],trX0.shape[1],trX0.shape[2],trX0.shape[3]+trX1.shape[3]),dtype=np.uint8)\n",
    "    print (trX0.shape,trX1.shape,trX.shape)\n",
    "    trX[:,:,:,0:3] = trX0; del trX0\n",
    "    trX[:,:,:,3:]  = trX1; del trX1\n",
    "    \n",
    "if False :\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    trX0 = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX-tif.npy')\n",
    "    trX1 = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-XX-tif.npy')\n",
    "    #trX1 = trX1[:,:,:,3:]\n",
    "    trX  = np.zeros((trX0.shape[0],trX0.shape[1],trX0.shape[2],trX0.shape[3]+trX1.shape[3]),dtype=np.uint8)\n",
    "    print (trX0.shape,trX1.shape,trX.shape)\n",
    "    trX[:,:,:,0:3] = trX0\n",
    "    trX[:,:,:,3:]  = trX1\n",
    "    #del trX0,trX1\n",
    "    \n",
    "if True :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-tif.npy').astype(np.float32)\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY-tif.npy')\n",
    "    \n",
    "    trX  = preprocess_input(trX) # по умному\n",
    "    \n",
    "    ##trX  = trX[:, :, :, ::-1] # RGB --> BGR\n",
    "    \n",
    "    ##trX  = np.array(trX,dtype=np.float16)\n",
    "    ##trX[:, :, :, 0] -= 103.939\n",
    "    ##trX[:, :, :, 1] -= 116.779\n",
    "    ##trX[:, :, :, 2] -= 123.68\n",
    "    \n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del trX0,trX1,trX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : #переворот по диагонали для GIF для совмещения с JPG\n",
    "    trX00 = trX0.copy()\n",
    "    for i in range(trX00.shape[1]) :\n",
    "        for j in range(trX00.shape[2]) :\n",
    "            trX00[:,i,j,:] = trX0[:,j,i,:]\n",
    "    trX[:,:,:,0:3] = trX00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : # построение CCCI\n",
    "    trX.shape\n",
    "    ndvi_min, ndvi_max = np.zeros(trX.shape[0],dtype=np.float16), np.zeros(trX.shape[0],dtype=np.float16)\n",
    "    ccci               = np.zeros((trX.shape[0],trX.shape[1],trX.shape[2]),dtype=np.uint8)\n",
    "    for ii in range(trX.shape[0]) :\n",
    "        ndvi_min[ii], ndvi_max[ii] = trX[ii,:,:,0].min(), trX[ii,:,:,0].max()\n",
    "        ccci[ii] = (trX[ii,:,:,0]-ndvi_min[ii])/(ndvi_max[ii]-ndvi_min[ii])*256.0\n",
    "    ccci.shape\n",
    "    trX[:,:,:,3]=ccci\n",
    "    \n",
    "    ii = 50\n",
    "    #plt.imshow(np.array(ccci[ii]*256.0,dtype=np.uint8),'gray'); plt.show()\n",
    "    #plt.subplot(121);plt.imshow(ccci[ii],'gray'); plt.subplot(122);plt.hist(ccci[ii].ravel(),bins=50); \n",
    "    #plt.show()\n",
    "    plt.subplot(121);plt.imshow(trX[ii,:,:,0],'gray'); plt.subplot(122);plt.hist(trX[ii,:,:,0].ravel(),bins=30); \n",
    "    plt.show()\n",
    "    plt.subplot(121);plt.imshow(trX[ii,:,:,1],'gray'); plt.subplot(122);plt.hist(trX[ii,:,:,1].ravel(),bins=30); \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 128, 128, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape,trY.shape)\n",
    "###del trX, trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fbeta_pred(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) 17\n"
     ]
    }
   ],
   "source": [
    "input_shape, output_classes, metric = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], 'acc'\n",
    "print(input_shape,output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model00 = VGG19(weights='imagenet', include_top=True)\n",
    "for layer in model00.layers :\n",
    "    if layer.name=='fc1' : fc1 = layer.get_weights()\n",
    "    if layer.name=='fc2' : fc2 = layer.get_weights()\n",
    "model00.summary()\n",
    "del model00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(25088, 4096), (4096,)], [(4096, 4096), (4096,)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in fc1], [x.shape for x in fc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc1 [(8192, 4096), (4096,)]\n",
      " fc1 fc1-1 fc2 fc2-0 fc2-1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "ffcc1 (Dense)                (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "ffcc2 (Dense)                (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 70,433,873\n",
      "Trainable params: 70,433,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "base_model = VGG19(weights='imagenet', include_top=False, pooling=None, input_shape=input_shape)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "##print(base_model.summary())\n",
    "\n",
    "##x = GlobalMaxPooling2D()(x) \n",
    "x = Flatten()(x)\n",
    "initiaze = 'he_normal'\n",
    "x = Dense(4096, activation='relu',kernel_initializer=initiaze, name='ffcc1')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(4096, activation='relu',kernel_initializer=initiaze, name='ffcc2')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(output_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model10 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "##for layer in base_model.layers : layer.Tranable = False\n",
    "\n",
    "flag = ''\n",
    "for layer in model10.layers :\n",
    "    if layer.name=='ffcc1' : \n",
    "        ffcc = layer.get_weights(); flag+=' fc1'; print(flag,[x.shape for x in ffcc])\n",
    "        if (ffcc[0].shape==fc1[0].shape) : ffcc[0]+=fc1[0]; flag+=' fc1-0'\n",
    "        if (ffcc[1].shape==fc1[1].shape) : ffcc[1]+=fc1[1]; flag+=' fc1-1'\n",
    "        layer.set_weights(ffcc)\n",
    "    if layer.name=='ffcc2' :\n",
    "        ffcc = layer.get_weights(); flag+=' fc2'\n",
    "        if (ffcc[0].shape==fc2[0].shape) : ffcc[0]+=fc2[0]; flag+=' fc2-0'\n",
    "        if (ffcc[1].shape==fc2[1].shape) : ffcc[1]+=fc2[1]; flag+=' fc2-1'\n",
    "        layer.set_weights(ffcc)\n",
    "        \n",
    "print(flag)\n",
    "\n",
    "sgd = keras.optimizers.SGD(nesterov=True)\n",
    "model10.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "              optimizer=sgd, #\"nadam\", #sgd, #\"adam\", #'rmsprop',\n",
    "              metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del model11, model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 [(3, 3, 3, 64), (64,)] (3, 3, 3, 64) (64,) 12\n",
      "block1_conv2 [(3, 3, 64, 64), (64,)] (3, 3, 64, 64) (64,) 12\n",
      "block2_conv1 [(3, 3, 64, 128), (128,)] (3, 3, 64, 128) (128,) 12\n",
      "block2_conv2 [(3, 3, 128, 128), (128,)] (3, 3, 128, 128) (128,) 12\n",
      "block3_conv1 [(3, 3, 128, 256), (256,)] (3, 3, 128, 256) (256,) 12\n",
      "block3_conv2 [(3, 3, 256, 256), (256,)] (3, 3, 256, 256) (256,) 12\n",
      "block3_conv3 [(3, 3, 256, 256), (256,)] (3, 3, 256, 256) (256,) 12\n",
      "block3_conv4 [(3, 3, 256, 256), (256,)] (3, 3, 256, 256) (256,) 12\n",
      "block4_conv1 [(3, 3, 256, 512), (512,)] (3, 3, 256, 512) (512,) 12\n",
      "block4_conv2 [(3, 3, 512, 512), (512,)] (3, 3, 512, 512) (512,) 12\n",
      "block4_conv3 [(3, 3, 512, 512), (512,)] (3, 3, 512, 512) (512,) 12\n",
      "block4_conv4 [(3, 3, 512, 512), (512,)] (3, 3, 512, 512) (512,) 12\n",
      "block5_conv1 [(3, 3, 512, 512), (512,)] (3, 3, 512, 512) (512,) 12\n",
      "block5_conv2 [(3, 3, 512, 512), (512,)] (3, 3, 512, 512) (512,) 12\n",
      "block5_conv3 [(3, 3, 512, 512), (512,)] (3, 3, 512, 512) (512,) 12\n",
      "block5_conv4 [(3, 3, 512, 512), (512,)] (3, 3, 512, 512) (512,) 12\n",
      "fc1 [(8192, 4096), (4096,)] (25088, 4096) (4096,) 2\n",
      "fc2 [(4096, 4096), (4096,)] (4096, 4096) (4096,) 12\n",
      "predictions [(4096, 17), (17,)] (4096, 1000) (1000,) \n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model10 = VGG19XX(input_shape=input_shape,classes=output_classes)\n",
    "#model11.summary()\n",
    "\n",
    "import h5py\n",
    "hh5  = h5py.File('../Data-Keras/gitModels/vgg19_weights_tf_dim_ordering_tf_kernels.h5','r')\n",
    "\n",
    "for ll in model10.layers :\n",
    "    wb   = ll.get_weights()\n",
    "    if len(wb)==2 :\n",
    "        upd  = ''\n",
    "        hg1  = hh5[ll.name]\n",
    "        hg1w = hg1.get(ll.name+\"_W_1:0\")[()]\n",
    "        hg1b = hg1.get(ll.name+\"_b_1:0\")[()]\n",
    "        if wb[0].shape==hg1w.shape : wb[0] = hg1w; upd +='1'\n",
    "        if wb[1].shape==hg1b.shape : wb[1] = hg1b; upd +='2'\n",
    "        ll.set_weights(wb)\n",
    "        print (ll.name,[iwb.shape for iwb in wb],hg1w.shape,hg1b.shape,upd)\n",
    "    #ll.set_weights([fc1W,fc1B])\n",
    "hh5.close()\n",
    "sgd = keras.optimizers.SGD(nesterov=True)\n",
    "model10.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "              optimizer=sgd, #\"nadam\", #sgd, #\"adam\", #'rmsprop',\n",
    "              metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(nesterov=True)\n",
    "model10.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "              optimizer=sgd, #\"nadam\", #sgd, #\"adam\", #'rmsprop',\n",
    "              metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : model10.load_weights('../Data-Keras/Models/model-Alex-weights-128x128x3.h5', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : \n",
    "    sweight  = np.zeros(trY.shape[0],dtype=np.float32);\n",
    "    sweight[:]  = 1.0\n",
    "    sweight[trY[:,0]==1] = 0.35\n",
    "    sweight[trY[:,1]==1] = 0.25\n",
    "    sweight[trY[:,2]==1] = 0.15\n",
    "    sweight[trY[:,3]==1] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-15 18:52:57.396255\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/12\n",
      "Epoch 00000: acc improved from -inf to 0.85771, saving model to ../Temp/Temp/vgg19-jpg-tif-128x128x3-weights.00-acc=0.8577-val_acc=0.8563-.hdf5\n",
      "774s - loss: 0.2422 - acc: 0.8577 - val_loss: 0.2547 - val_acc: 0.8563\n",
      "Epoch 2/12\n",
      "Epoch 00001: acc improved from 0.85771 to 0.85796, saving model to ../Temp/Temp/vgg19-jpg-tif-128x128x3-weights.01-acc=0.8580-val_acc=0.8501-.hdf5\n",
      "776s - loss: 0.2410 - acc: 0.8580 - val_loss: 0.2544 - val_acc: 0.8501\n",
      "Epoch 3/12\n",
      "Epoch 00002: acc improved from 0.85796 to 0.85809, saving model to ../Temp/Temp/vgg19-jpg-tif-128x128x3-weights.02-acc=0.8581-val_acc=0.8538-.hdf5\n",
      "776s - loss: 0.2398 - acc: 0.8581 - val_loss: 0.2555 - val_acc: 0.8538\n",
      "Epoch 4/12\n",
      "Epoch 00003: acc improved from 0.85809 to 0.85813, saving model to ../Temp/Temp/vgg19-jpg-tif-128x128x3-weights.03-acc=0.8581-val_acc=0.8502-.hdf5\n",
      "777s - loss: 0.2387 - acc: 0.8581 - val_loss: 0.2563 - val_acc: 0.8502\n",
      "Epoch 5/12\n",
      "Epoch 00004: acc improved from 0.85813 to 0.85824, saving model to ../Temp/Temp/vgg19-jpg-tif-128x128x3-weights.04-acc=0.8582-val_acc=0.8542-.hdf5\n",
      "777s - loss: 0.2376 - acc: 0.8582 - val_loss: 0.2554 - val_acc: 0.8542\n",
      "Epoch 6/12\n",
      "Epoch 00005: acc improved from 0.85824 to 0.85851, saving model to ../Temp/Temp/vgg19-jpg-tif-128x128x3-weights.05-acc=0.8585-val_acc=0.8535-.hdf5\n",
      "776s - loss: 0.2364 - acc: 0.8585 - val_loss: 0.2572 - val_acc: 0.8535\n",
      "Epoch 7/12\n",
      "Epoch 00006: acc improved from 0.85851 to 0.85854, saving model to ../Temp/Temp/vgg19-jpg-tif-128x128x3-weights.06-acc=0.8585-val_acc=0.8523-.hdf5\n",
      "776s - loss: 0.2353 - acc: 0.8585 - val_loss: 0.2570 - val_acc: 0.8523\n",
      "2017-07-15 20:23:33.386960\n"
     ]
    }
   ],
   "source": [
    "epochs     = 12\n",
    "verbose    = 2\n",
    "batch_size = 32\n",
    "stopping   = 4\n",
    "\n",
    "prefixTemp = 'vgg19-jpg-tif-128x128x3'     \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=stopping,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "filepath=\"../Temp/Temp/\"+prefixTemp+\"-weights.{epoch:02d}-acc={\"+metric+\":.4f}-val_acc={val_\"+metric+\":.4f}-.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=metric, verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "step = 5000\n",
    "low  = 5000\n",
    "high = low+step\n",
    "\n",
    "xxyy = 0\n",
    "#trXX = trX #[trY[:,xxyy]==1]\n",
    "#trYY = trY #[trY[:,xxyy]==1]\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "hist1  = model10.fit(trX,trY,\n",
    "                    #sample_weight=sweight[low:high],\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.20, \n",
    "                    #initial_epoch=6,\n",
    "                    callbacks=[early_stopping,checkpoint, reduce_lr],\n",
    "                    verbose=verbose)\n",
    "\n",
    "##trP = model1.predict(trX, batch_size=128)\n",
    "##fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "##fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "print(datetime.datetime.now()) #,pp,'fbeta2s=',fbeta2score,fbeta2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fc1[1].shape, fc1[1][:10], fc2[0][:10], fc2[1][:10], ffcc[0][:10], ffcc[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhJQQhAREUAJQUREAkoIIiICwP8D80D4LMK3AT0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8daae3fc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8daecbdf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd.get_config(); hist1.history\n",
    "plt.plot(hist1.history['acc']); plt.plot(hist1.history['val_acc']); plt.show()\n",
    "plt.plot(hist1.history['loss']); plt.plot(hist1.history['val_loss']); plt.show()\n",
    "#hist1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40479, 128, 128, 3), (40479, 17))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape, trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.7 s, sys: 14 s, total: 54.7 s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%time trP = model10.predict(trX, batch_size=batch_size)\n",
    "trP01       = getProb01(trP)\n",
    "th, _       = getTh(trY,trP)\n",
    "trP01x      = getProbX01(trP,th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 17)\n",
      "(40479, 17)\n",
      "fbeta_score= 0.235712955756\n",
      "fbeta_pred = 0.43852996984\n",
      "fbeta_score= 0.936343915303\n",
      "fbeta_pred = 0.93375767889\n"
     ]
    }
   ],
   "source": [
    "#print(model10.evaluate(trX,trY,verbose=2,batch_size=batch_size))\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "#print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "#print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.5, beta=2, average='samples'))\n",
    "##-------------\n",
    "print('fbeta_score=',fbeta_score(trY,trP01, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP01.astype(np.float64))))\n",
    "##-------------\n",
    "if trY.shape[1]==17 :\n",
    "    print('fbeta_score=',fbeta_score(trY,trP01x, beta=2, average='samples'))\n",
    "    print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP01x.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    freeze  = ('fc1','fc2','dropout_1','dropout_2','flatten')\n",
    "    trainOK = ('input_1','predictions')\n",
    "    for layer in model10.layers :\n",
    "        #if (layer.name=='fc1') : layer.trainable = False\n",
    "        #if (layer.name=='fc2') : layer.trainable = False\n",
    "        if (layer.name in freeze) : layer.trainable = False\n",
    "        else : layer.trainable = True\n",
    "        if (layer.name in trainOK) : layer.trainable = True\n",
    "        layer.trainable = True\n",
    "        print(layer.name,layer.trainable)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True :\n",
    "    save_model(model10,'../Data-Keras/Models/model-VGG19-128x128x3-d4096xd4096.h5')\n",
    "    model10.save_weights('../Data-Keras/Models/model-VGG19-128x128x3-d4096xd4096-weights.h5')\n",
    "    if False : # best 0x90004\n",
    "        save_model(model10,'../Work/Join-XGB-NET/VGG19-LB=0x90004/model-VGG19-128x128x3-d4096xd4096.h5')\n",
    "        model10.save_weights('../Work/Join-XGB-NET/VGG19-LB=0x90004/model-VGG19-128x128x3-d4096xd4096-weights.h5')\n",
    "        np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trIP01-XX.npy',trP01)\n",
    "        np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trIP-XX.npy', trP)\n",
    "        np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trIY-YY.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "ffcc1 (Dense)                (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "ffcc2 (Dense)                (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 70,433,873\n",
      "Trainable params: 70,433,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.70237350e-01,   4.93190736e-01,   1.06996112e-03,\n",
       "          1.33314744e-01,   6.74560608e-04,   9.84107974e-05,\n",
       "          2.12351413e-04,   4.83186363e-04,   4.88138940e-05,\n",
       "          1.42483710e-04,   7.10203385e-05,   1.37875631e-05,\n",
       "          4.31219232e-05,   1.01183177e-05,   1.92909007e-04,\n",
       "          5.11052203e-05,   1.45314596e-04], dtype=float32),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trP[0], trY[0], trP01[0], trP01x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Результативность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.976679265792 roc=0.883524232955 not=944 yes=2093 no=37442 true=39535 all-1-0=(0.7760-0.9910)\n",
      "1 acc=0.977642728328 roc=0.883610525919 not=905 yes=37280 no=2294 true=39574 all-1-0=(0.9938-0.7734)\n",
      "2 acc=0.928926109835 roc=0.922535026704 not=2877 yes=11160 no=26442 true=37602 all-1-0=(0.9062-0.9389)\n",
      "3 acc=0.973467724005 roc=0.967815856268 not=1074 yes=27913 no=11492 true=39405 all-1-0=(0.9818-0.9539)\n",
      "4 acc=0.949825835618 roc=0.90710241146 not=2031 yes=6223 no=32225 true=38448 all-1-0=(0.8397-0.9745)\n",
      "5 acc=0.961436794387 roc=0.849248928854 not=1561 yes=2607 no=36311 true=38918 all-1-0=(0.7123-0.9862)\n",
      "6 acc=0.951258677339 roc=0.919828071166 not=1973 yes=7002 no=31504 true=38506 all-1-0=(0.8676-0.9721)\n",
      "7 acc=0.932434101633 roc=0.767210724538 not=2735 yes=2485 no=35259 true=37744 all-1-0=(0.5551-0.9794)\n",
      "8 acc=0.994960349811 roc=0.531001148943 not=204 yes=13 no=40262 true=40275 all-1-0=(0.0622-0.9998)\n",
      "9 acc=0.99137824551 roc=0.963542756305 not=349 yes=1948 no=38182 true=40130 all-1-0=(0.9325-0.9946)\n",
      "10 acc=0.988240816226 roc=0.984333394426 not=476 yes=7103 no=32900 true=40003 all-1-0=(0.9782-0.9904)\n",
      "11 acc=0.998369524939 roc=0.719876173258 not=66 yes=44 no=40369 true=40413 all-1-0=(0.4400-0.9998)\n",
      "12 acc=0.983201166037 roc=0.678198917044 not=680 yes=310 no=39489 true=39799 all-1-0=(0.3596-0.9968)\n",
      "13 acc=0.998023666593 roc=0.924417525387 not=80 yes=288 no=40111 true=40399 all-1-0=(0.8496-0.9993)\n",
      "14 acc=0.992391116381 roc=0.57199025509 not=308 yes=48 no=40123 true=40171 all-1-0=(0.1446-0.9994)\n",
      "15 acc=0.993502803923 roc=0.696348790893 not=263 yes=134 no=40082 true=40216 all-1-0=(0.3941-0.9986)\n",
      "16 acc=0.997702512414 roc=0.530599862837 not=93 yes=6 no=40380 true=40386 all-1-0=(0.0612-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01x,printOK=True) # 40000 jpg128 (epoch=40,features=17) VGG19 d4096+d4096 +weights+imnet LB=0.90004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.970824378073 roc=0.827535509167 not=1181 yes=1786 no=37512 true=39298 all-1-0=(0.6622-0.9929)\n",
      "1 acc=0.976555744954 roc=0.877590365212 not=949 yes=37271 no=2259 true=39530 all-1-0=(0.9935-0.7616)\n",
      "2 acc=0.917611601077 roc=0.909720294098 not=3335 yes=10955 no=26189 true=37144 all-1-0=(0.8896-0.9299)\n",
      "3 acc=0.964376590331 roc=0.949960875432 not=1442 yes=28021 no=11016 true=39037 all-1-0=(0.9856-0.9143)\n",
      "4 acc=0.937943131006 roc=0.87391779368 not=2512 yes=5728 no=32239 true=37967 all-1-0=(0.7729-0.9749)\n",
      "5 acc=0.954074952444 roc=0.807677321803 not=1859 yes=2302 no=36318 true=38620 all-1-0=(0.6290-0.9864)\n",
      "6 acc=0.942711035352 roc=0.901277662688 not=2319 yes=6718 no=31442 true=38160 all-1-0=(0.8324-0.9702)\n",
      "7 acc=0.928012055634 roc=0.768147534975 not=2914 yes=2520 no=35045 true=37565 all-1-0=(0.5629-0.9734)\n",
      "8 acc=0.994861533141 roc=0.507152201111 not=208 yes=3 no=40268 true=40271 all-1-0=(0.0144-1.0000)\n",
      "9 acc=0.990464191309 roc=0.950839323708 not=386 yes=1894 no=38199 true=40093 all-1-0=(0.9067-0.9950)\n",
      "10 acc=0.982410632674 roc=0.970772637269 not=712 yes=6917 no=32850 true=39767 all-1-0=(0.9526-0.9889)\n",
      "11 acc=0.998443637442 roc=0.759814259888 not=63 yes=52 no=40364 true=40416 all-1-0=(0.5200-0.9996)\n",
      "12 acc=0.981447170138 roc=0.627369387875 not=751 yes=222 no=39506 true=39728 all-1-0=(0.2575-0.9972)\n",
      "13 acc=0.99743076657 roc=0.910956343065 not=104 yes=279 no=40096 true=40375 all-1-0=(0.8230-0.9989)\n",
      "14 acc=0.991946441365 roc=0.543388251489 not=326 yes=29 no=40124 true=40153 all-1-0=(0.0873-0.9994)\n",
      "15 acc=0.992909903901 roc=0.647931489544 not=287 yes=101 no=40091 true=40192 all-1-0=(0.2971-0.9988)\n",
      "16 acc=0.997702512414 roc=0.545868839103 not=93 yes=9 no=40377 true=40386 all-1-0=(0.0918-0.9999)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01x,printOK=True) # 40000 jpg128 (epoch=40,features=17) VGG19 d4096+d4096 +weights+imnet LB=0.90004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trOX  = np.load('../Data-Keras/Datas/test-model-2D-128x128x3-jpg-XX.npy').astype(np.float16)\n",
    "trOY  = np.load('../Data-Keras/Datas/test-model-2D-128x128x3-jpg-YY.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Препроцессорная обработка данных\n",
    "\n",
    "trOX  = trOX[:, :, :, ::-1] # RGB --> BGR\n",
    "\n",
    "##trX  = np.array(trX,dtype=np.float16)\n",
    "trOX[:, :, :, 0] -= 103.939\n",
    "trOX[:, :, :, 1] -= 116.779\n",
    "trOX[:, :, :, 2] -= 123.68\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  Построение решения для test массива на основе уровней прохождения (эффект почему-то дают)\n",
    "#    Построенное решение 01 полное с учетом погодных критериев [0,3,9,10]\n",
    "#        и особенности критерия cloudy (посмотреть и сменить можно в getProbX01)\n",
    "#        Построение критериев прохождения в getTh\n",
    "#\n",
    "\n",
    "# test\n",
    "trOP = model10.predict(trOX, batch_size=batch_size)\n",
    "\n",
    "# Уровни прохождения & решение\n",
    "trO01   = getProbX01(trOP,th)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#trO01[0:3],np.array(th),trOP[0:3]\n",
    "if True :\n",
    "    np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trO01-OX.npy',trO01)\n",
    "    np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trOP-OX.npy', trOP)\n",
    "    np.save('../Work/Join-XGB-NET/VGG19-LB=0x90004/trOY-OY.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Строим результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trZ = trO01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for i in range(trZ.shape[0]) :\n",
    "    temp = [labels[ii] for ii in range(trZ.shape[1]) if trZ[i,ii]==1];\n",
    "    temp = ' '.join(temp)\n",
    "    temp_list.append([trOY[i],temp])\n",
    "temp_list.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['test_0', 'primary clear'],\n",
       " ['test_1', 'primary clear'],\n",
       " ['test_2', 'primary partly_cloudy'],\n",
       " ['test_3', 'primary clear'],\n",
       " ['test_4', 'cloudy']]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12-15-25-40\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(temp_list,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                   tags\n",
       "0     test_0          primary clear\n",
       "1     test_1          primary clear\n",
       "2     test_2  primary partly_cloudy\n",
       "3     test_3          primary clear\n",
       "4     test_4                 cloudy"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Склад барахла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Skip to content\n",
    "Features Business Explore Marketplace Pricing\n",
    "This repository\n",
    "Search\n",
    "Sign in or Sign up\n",
    " Watch 1,176  Star 17,415  Fork 6,223 fchollet/keras\n",
    " Code  Issues 1,167  Pull requests 36  Projects 1  Wiki Insights \n",
    "Branch: master Find file Copy pathkeras/keras/applications/vgg19.py\n",
    "bac1637  on 22 May\n",
    "@taehoonlee taehoonlee Fix typos (#6702)\n",
    "4 contributors @fchollet @taehoonlee @singlas @ozancaglayan\n",
    "RawBlameHistory     \n",
    "193 lines (167 sloc)  8.29 KB\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"VGG19 model for Keras.\n",
    "# Reference\n",
    "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "\n",
    "from ..models import Model\n",
    "from ..layers import Flatten\n",
    "from ..layers import Dense\n",
    "from ..layers import Input\n",
    "from ..layers import Conv2D\n",
    "from ..layers import MaxPooling2D\n",
    "from ..layers import GlobalAveragePooling2D\n",
    "from ..layers import GlobalMaxPooling2D\n",
    "from ..engine.topology import get_source_inputs\n",
    "from ..utils import layer_utils\n",
    "from ..utils.data_utils import get_file\n",
    "from .. import backend as K\n",
    "from .imagenet_utils import decode_predictions\n",
    "from .imagenet_utils import preprocess_input\n",
    "from .imagenet_utils import _obtain_input_shape\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG19(include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG19 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg19')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n",
    "Contact GitHub API Training Shop Blog About\n",
    "© 2017 GitHub, Inc. Terms Privacy Security Status Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def VGG16 ( include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    from keras.utils.data_utils import get_file\n",
    "    WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "    WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "    weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                        WEIGHTS_PATH,\n",
    "                        cache_subdir='models')\n",
    "weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                        WEIGHTS_PATH_NO_TOP,\n",
    "                        cache_subdir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildModel (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    if (cv2d is None) and (dense is None) and not (params is None) : cv2d, dense = params[:-2], params[-2:]\n",
    "    model = Kriz2012x3x3(model,iSize,rSize,cv2d=cv2d,dense=dense,pp=params)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "def buildModelKriz (iSize,rSize) :\n",
    "    model = Sequential()\n",
    "    \n",
    "    model = Kriz2012(model,iSize,rSize)\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    sgd = keras.optimizers.SGD(nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "                  optimizer=\"sgd\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "#from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=False)\n",
    "model10 = VGG16(weights=None,input_shape=(224,224,3),include_top=True,classes=4)\n",
    "\n",
    "#x = (Dense(512,activation='relu'))(model10)\n",
    "#model10.add(Dropout(0.25))\n",
    "#model10.add(Dense(4,activation='sigmoid'))\n",
    "\n",
    "#img_path = 'elephant.jpg'\n",
    "#img = image.load_img(img_path, target_size=(224, 224))\n",
    "#x = image.img_to_array(img)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "\n",
    "#features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
