{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## AlexNet analog (Krizhevsky 2012)\n",
    "##\n",
    "## 2017-05-20\n",
    "## maximum on LB => 0.84500\n",
    "##\n",
    "## TIF - (,,6) (,,3)\n",
    "##\n",
    "## 2017-07-06\n",
    "##  TIF (64,64,6) - полная схема без выемки 09(cloudy) - то есть 17 признаков\n",
    "##  \n",
    "## 2017-07-09\n",
    "##  TIF (64,64,6) - полная схема по признакам 4,5,6,7\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import paths_input, formImExt, formImHist\n",
    "from estimate import confusion_matrix, getConfusion, getRocAUC, getProb01, getProbX01, getTh, estimateResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Data/test-jpg-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, teDirJPG, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy',trX)\n",
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 3) (40479, 64, 64, 8) (40479, 64, 64, 11)\n",
      "(40479, 64, 64, 11) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "if False :\n",
    "    ###trXX = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-XX.npy')\n",
    "    ###trYY = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    trXX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "    trYY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "\n",
    "    trX, trY = trXX[trYY[:,9]==0], trYY[trYY[:,9]==0] # not cloudy == 9 feature\n",
    "    trY=trY[:,range(0,9)+range(10,17)] # --cloudy <> 9\n",
    "    del trXX,trYY\n",
    "    #print(trXX.shape,trYY.shape)\n",
    "    print(trX.shape,trY.shape)\n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX-short.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY-short.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-XX-tif.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    \n",
    "if False : # VGG16-19\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "    \n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    \n",
    "if True :\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-YY-tif.npy')\n",
    "    trX0 = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX-tif.npy')\n",
    "    trX1 = np.load('../Data-Keras/Datas/train-model-2D-64x64x8-XX-tif.npy')\n",
    "    #trX1 = trX1[:,:,:,3:]\n",
    "    trX  = np.zeros((trX0.shape[0],trX0.shape[1],trX0.shape[2],trX0.shape[3]+trX1.shape[3]),dtype=np.uint8)\n",
    "    print (trX0.shape,trX1.shape,trX.shape)\n",
    "    trX[:,:,:,0:3] = trX0\n",
    "    trX[:,:,:,3:]  = trX1\n",
    "    del trX0,trX1\n",
    "    \n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 11) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape,trY.shape)\n",
    "###del trX, trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 11) (40479, 4)\n"
     ]
    }
   ],
   "source": [
    "# Берем из признаков только 4,5,6,7 - проблемные\n",
    "trY_old = trY\n",
    "trY=trY[:,4:8]\n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fbeta_pred(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "def VGG16XX ( include_top=True, \n",
    "              weights='imagenet',\n",
    "              input_tensor=None, input_shape=None,\n",
    "              pooling=None,\n",
    "              classes=1000):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "    '''\n",
    "    \n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        '''\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        '''\n",
    "        \n",
    "        x = Dense(1024, activation='relu', name='fc1')(x) ##\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Dense(1024, activation='relu', name='fc2')(x) ## \n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16XX')\n",
    "    \n",
    "    \"\"\"\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    \"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model10 = VGG16XX(input_shape=(64,64,3),classes=4)\n",
    "#model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 11) 4\n"
     ]
    }
   ],
   "source": [
    "input_shape, output_classes, metric = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], 'acc'\n",
    "print(input_shape,output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 11)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        6400      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 17,871,172\n",
      "Trainable params: 17,871,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model10 = VGG16XX(input_shape=input_shape,classes=output_classes)\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(nesterov=True)\n",
    "model10.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "              optimizer=sgd, #\"nadam\", #sgd, #\"adam\", #'rmsprop',\n",
    "              metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False : model10.load_weights('../Data-Keras/Models/model-Alex-weights-128x128x3.h5', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sweight  = np.zeros(trY.shape[0],dtype=np.float32);\n",
    "sweight[:]  = 1.0\n",
    "sweight[trY[:,0]==1] = 0.35\n",
    "sweight[trY[:,1]==1] = 0.25\n",
    "sweight[trY[:,2]==1] = 0.15\n",
    "sweight[trY[:,3]==1] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-10 10:29:23.990582 17871172.0\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 32/100\n",
      "Epoch 00031: acc improved from -inf to 0.89039, saving model to ../Temp/tif-64x64x11-weights.31-acc=0.8904-val_acc=0.8888-.hdf5\n",
      "171s - loss: 0.3795 - acc: 0.8904 - val_loss: 0.3825 - val_acc: 0.8888\n",
      "Epoch 33/100\n",
      "Epoch 00032: acc improved from 0.89039 to 0.89138, saving model to ../Temp/tif-64x64x11-weights.32-acc=0.8914-val_acc=0.8863-.hdf5\n",
      "172s - loss: 0.3787 - acc: 0.8914 - val_loss: 0.3827 - val_acc: 0.8863\n",
      "Epoch 34/100\n",
      "Epoch 00033: acc did not improve\n",
      "171s - loss: 0.3785 - acc: 0.8908 - val_loss: 0.3831 - val_acc: 0.8878\n",
      "Epoch 35/100\n",
      "Epoch 00034: acc did not improve\n",
      "171s - loss: 0.3782 - acc: 0.8911 - val_loss: 0.3824 - val_acc: 0.8862\n",
      "Epoch 36/100\n",
      "Epoch 00035: acc improved from 0.89138 to 0.89159, saving model to ../Temp/tif-64x64x11-weights.35-acc=0.8916-val_acc=0.8847-.hdf5\n",
      "172s - loss: 0.3776 - acc: 0.8916 - val_loss: 0.3854 - val_acc: 0.8847\n",
      "Epoch 37/100\n",
      "Epoch 00036: acc did not improve\n",
      "171s - loss: 0.3776 - acc: 0.8909 - val_loss: 0.3841 - val_acc: 0.8865\n",
      "Epoch 38/100\n",
      "Epoch 00037: acc improved from 0.89159 to 0.89166, saving model to ../Temp/tif-64x64x11-weights.37-acc=0.8917-val_acc=0.8882-.hdf5\n",
      "172s - loss: 0.3772 - acc: 0.8917 - val_loss: 0.3823 - val_acc: 0.8882\n",
      "Epoch 39/100\n",
      "Epoch 00038: acc did not improve\n",
      "172s - loss: 0.3769 - acc: 0.8912 - val_loss: 0.3819 - val_acc: 0.8882\n",
      "Epoch 40/100\n",
      "Epoch 00039: acc improved from 0.89166 to 0.89200, saving model to ../Temp/tif-64x64x11-weights.39-acc=0.8920-val_acc=0.8871-.hdf5\n",
      "172s - loss: 0.3767 - acc: 0.8920 - val_loss: 0.3830 - val_acc: 0.8871\n",
      "Epoch 41/100\n",
      "Epoch 00040: acc improved from 0.89200 to 0.89220, saving model to ../Temp/tif-64x64x11-weights.40-acc=0.8922-val_acc=0.8889-.hdf5\n",
      "172s - loss: 0.3764 - acc: 0.8922 - val_loss: 0.3806 - val_acc: 0.8889\n",
      "Epoch 42/100\n",
      "Epoch 00041: acc did not improve\n",
      "172s - loss: 0.3758 - acc: 0.8921 - val_loss: 0.3820 - val_acc: 0.8894\n",
      "Epoch 43/100\n",
      "Epoch 00042: acc did not improve\n",
      "172s - loss: 0.3759 - acc: 0.8917 - val_loss: 0.3814 - val_acc: 0.8891\n",
      "Epoch 44/100\n",
      "Epoch 00043: acc did not improve\n",
      "172s - loss: 0.3754 - acc: 0.8921 - val_loss: 0.3840 - val_acc: 0.8845\n",
      "Epoch 45/100\n",
      "Epoch 00044: acc improved from 0.89220 to 0.89279, saving model to ../Temp/tif-64x64x11-weights.44-acc=0.8928-val_acc=0.8773-.hdf5\n",
      "172s - loss: 0.3752 - acc: 0.8928 - val_loss: 0.3874 - val_acc: 0.8773\n",
      "Epoch 46/100\n",
      "Epoch 00045: acc did not improve\n",
      "172s - loss: 0.3753 - acc: 0.8924 - val_loss: 0.3810 - val_acc: 0.8882\n",
      "Epoch 47/100\n",
      "Epoch 00046: acc did not improve\n",
      "172s - loss: 0.3746 - acc: 0.8925 - val_loss: 0.3842 - val_acc: 0.8847\n",
      "Epoch 48/100\n",
      "Epoch 00047: acc improved from 0.89279 to 0.89347, saving model to ../Temp/tif-64x64x11-weights.47-acc=0.8935-val_acc=0.8865-.hdf5\n",
      "172s - loss: 0.3734 - acc: 0.8935 - val_loss: 0.3809 - val_acc: 0.8865\n",
      "Epoch 49/100\n",
      "Epoch 00048: acc did not improve\n",
      "172s - loss: 0.3731 - acc: 0.8931 - val_loss: 0.3816 - val_acc: 0.8873\n",
      "Epoch 50/100\n",
      "Epoch 00049: acc improved from 0.89347 to 0.89380, saving model to ../Temp/tif-64x64x11-weights.49-acc=0.8938-val_acc=0.8869-.hdf5\n",
      "172s - loss: 0.3724 - acc: 0.8938 - val_loss: 0.3818 - val_acc: 0.8869\n",
      "Epoch 51/100\n",
      "Epoch 00050: acc did not improve\n",
      "172s - loss: 0.3725 - acc: 0.8930 - val_loss: 0.3829 - val_acc: 0.8861\n",
      "Epoch 52/100\n",
      "Epoch 00051: acc did not improve\n",
      "172s - loss: 0.3725 - acc: 0.8935 - val_loss: 0.3810 - val_acc: 0.8858\n",
      "2017-07-10 11:29:43.168421\n"
     ]
    }
   ],
   "source": [
    "epochs     = 100\n",
    "verbose    = 2\n",
    "batch_size = 64\n",
    "stopping   = 10\n",
    "\n",
    "prefixTemp = 'tif-64x64x11'     \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=stopping,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "filepath=\"../Temp/\"+prefixTemp+\"-weights.{epoch:02d}-acc={\"+metric+\":.4f}-val_acc={val_\"+metric+\":.4f}-.hdf5\"\n",
    "##checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=metric, verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "tr1    = np.sum([K.count_params(p) for p in set(model10.trainable_weights)])\n",
    "tr2    = np.sum([K.count_params(p) for p in set(model10.non_trainable_weights)])\n",
    "\n",
    "step = 5000\n",
    "low  = 0\n",
    "high = low+step\n",
    "\n",
    "xxyy = 0\n",
    "#trXX = trX #[trY[:,xxyy]==1]\n",
    "#trYY = trY #[trY[:,xxyy]==1]\n",
    "\n",
    "print(datetime.datetime.now(),tr1+tr2)\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "hist1  = model10.fit(trX,trY,\n",
    "                    #sample_weight=sweight[low:high],\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.20, \n",
    "                    initial_epoch=31,\n",
    "                    callbacks=[early_stopping,checkpoint, reduce_lr],\n",
    "                    verbose=verbose)\n",
    "\n",
    "##trP = model1.predict(trX, batch_size=128)\n",
    "##fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "##fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "print(datetime.datetime.now()) #,pp,'fbeta2s=',fbeta2score,fbeta2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40479, 64, 64, 11), (40479, 4))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape, trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 6.95 s, total: 25.6 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%time trP = model10.predict(trX, batch_size=batch_size)\n",
    "trP01       = getProb01(trP)\n",
    "#th, _       = getTh(trY,trP)\n",
    "#trP01x      = getProbX01(trP,th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37371786834635329, 0.88867684475721032]\n",
      "(40479, 4)\n",
      "(40479, 4)\n",
      "fbeta_score= 0.194998626987\n",
      "fbeta_pred = 0.614875077362\n"
     ]
    }
   ],
   "source": [
    "print(model10.evaluate(trX,trY,verbose=2))\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "#print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "#print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.5, beta=2, average='samples'))\n",
    "##-------------\n",
    "print('fbeta_score=',fbeta_score(trY,trP01, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP01.astype(np.float64))))\n",
    "##-------------\n",
    "#print('fbeta_score=',fbeta_score(trY,trP01x, beta=2, average='samples'))\n",
    "#print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP01x.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True :\n",
    "    save_model(model10,'../Data-Keras/Models/model-VGG16-64x64x11-d1024xd1024.h5')\n",
    "    model10.save_weights('../Data-Keras/Models/model-VGG16-weights-64x64x11-d1024xd1024.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 11)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        6400      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 17,871,172\n",
      "Trainable params: 17,871,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.13789362,  0.01323014,  0.06813941,  0.05523191], dtype=float32),\n",
       " array([0, 0, 0, 0]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trP[0], trY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Результативность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.90320907137 roc=0.782461350112 not=3918 yes=4387 no=32174 true=36561 all-1-0=(0.5920-0.9730)\n",
      "1 acc=0.915981126016 roc=0.536612834428 not=3401 yes=269 no=36809 true=37078 all-1-0=(0.0735-0.9997)\n",
      "2 acc=0.847575285951 roc=0.678757529563 not=6170 yes=3212 no=31097 true=34309 all-1-0=(0.3980-0.9595)\n",
      "3 acc=0.887941895798 roc=0.652521299136 not=4536 yes=1568 no=34375 true=35943 all-1-0=(0.3502-0.9548)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 40000 jpg64 VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.89644012945 roc=0.757222563118 not=4192 yes=3984 no=32303 true=36287 all-1-0=(0.5376-0.9769)\n",
      "1 acc=0.914918846809 roc=0.530369421258 not=3444 yes=223 no=36812 true=37035 all-1-0=(0.0609-0.9998)\n",
      "2 acc=0.850515081894 roc=0.698039209517 not=6051 yes=3587 no=30841 true=34428 all-1-0=(0.4444-0.9516)\n",
      "3 acc=0.893352108501 roc=0.529017603407 not=4317 yes=274 no=35888 true=36162 all-1-0=(0.0612-0.9968)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 40000 jpg64 VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.832209293708 roc=0.567673970869 not=6792 yes=1114 no=32573 true=33687 all-1-0=(0.1503-0.9850)\n",
      "1 acc=0.90968156328 roc=0.501407672624 not=3656 yes=11 no=36812 true=36823 all-1-0=(0.0030-0.9998)\n",
      "2 acc=0.820351293263 roc=0.590623565462 not=7272 yes=1683 no=31524 true=33207 all-1-0=(0.2085-0.9727)\n",
      "3 acc=0.889399441686 roc=0.5 not=4477 yes=0 no=36002 true=36002 all-1-0=(0.0000-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 40000 jpg64 VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.832209293708 roc=0.567673970869 not=6792 yes=1114 no=32573 true=33687 all-1-0=(0.1503-0.9850)\n",
      "1 acc=0.90968156328 roc=0.501407672624 not=3656 yes=11 no=36812 true=36823 all-1-0=(0.0030-0.9998)\n",
      "2 acc=0.820351293263 roc=0.590623565462 not=7272 yes=1683 no=31524 true=33207 all-1-0=(0.2085-0.9727)\n",
      "3 acc=0.889399441686 roc=0.5 not=4477 yes=0 no=36002 true=36002 all-1-0=(0.0000-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 40000 jpg64 VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.866350453321 roc=0.681224354661 not=5410 yes=2884 no=32185 true=35069 all-1-0=(0.3892-0.9733)\n",
      "1 acc=0.909706267447 roc=0.501052156339 not=3655 yes=8 no=36816 true=36824 all-1-0=(0.0022-0.9999)\n",
      "2 acc=0.845574248376 roc=0.696349208737 not=6251 yes=3617 no=30611 true=34228 all-1-0=(0.4481-0.9446)\n",
      "3 acc=0.889399441686 roc=0.5 not=4477 yes=0 no=36002 true=36002 all-1-0=(0.0000-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 10000 +jpg64+tif64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.825316830949 roc=0.534350503276 not=7071 yes=558 no=32850 true=33408 all-1-0=(0.0753-0.9934)\n",
      "1 acc=0.909582746609 roc=0.5 not=3660 yes=0 no=36819 true=36819 all-1-0=(0.0000-1.0000)\n",
      "2 acc=0.800612663356 roc=0.5 not=8071 yes=0 no=32408 true=32408 all-1-0=(0.0000-1.0000)\n",
      "3 acc=0.889399441686 roc=0.5 not=4477 yes=0 no=36002 true=36002 all-1-0=(0.0000-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 10000 + weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.776180241607 roc=0.731723479904 not=9060 yes=4903 no=26516 true=31419 all-1-0=(0.6616-0.8019)\n",
      "1 acc=0.909582746609 roc=0.5 not=3660 yes=0 no=36819 true=36819 all-1-0=(0.0000-1.0000)\n",
      "2 acc=0.832159885373 roc=0.624794903727 not=6794 yes=2259 no=31426 true=33685 all-1-0=(0.2799-0.9697)\n",
      "3 acc=0.889399441686 roc=0.5 not=4477 yes=0 no=36002 true=36002 all-1-0=(0.0000-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 10000 + weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.890511129228 roc=0.763120816684 not=4432 yes=4166 no=31881 true=36047 all-1-0=(0.5621-0.9641)\n",
      "1 acc=0.915289409323 roc=0.543368456414 not=3429 yes=327 no=36723 true=37050 all-1-0=(0.0893-0.9974)\n",
      "2 acc=0.858321598854 roc=0.705845428811 not=5735 yes=3650 no=31094 true=34744 all-1-0=(0.4522-0.9595)\n",
      "3 acc=0.890264087552 roc=0.511830166361 not=4442 yes=116 no=35921 true=36037 all-1-0=(0.0259-0.9978)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 40497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.882506978927 roc=0.720322650364 not=4756 yes=3442 no=32281 true=35723 all-1-0=(0.4644-0.9762)\n",
      "1 acc=0.91049680081 roc=0.564602169942 not=3623 yes=521 no=36335 true=36856 all-1-0=(0.1423-0.9869)\n",
      "2 acc=0.845104869191 roc=0.747044076636 not=6270 yes=4713 no=29496 true=34209 all-1-0=(0.5839-0.9101)\n",
      "3 acc=0.889399441686 roc=0.5 not=4477 yes=0 no=36002 true=36002 all-1-0=(0.0000-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True) # 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.958348773438 roc=0.799160605167 not=1686 yes=1660 no=37133 true=38793 all-1-0=(0.6155-0.9828)\n",
      "1 acc=0.963240198622 roc=0.80939353027 not=1488 yes=37125 no=1866 true=38991 all-1-0=(0.9897-0.6291)\n",
      "2 acc=0.873909928605 roc=0.845756934198 not=5104 yes=9530 no=25845 true=35375 all-1-0=(0.7739-0.9177)\n",
      "3 acc=0.928432026483 roc=0.903017204686 not=2897 yes=27459 no=10123 true=37582 all-1-0=(0.9658-0.8402)\n",
      "4 acc=0.892314533462 roc=0.745117976905 not=4359 yes=3801 no=32319 true=36120 all-1-0=(0.5129-0.9773)\n",
      "5 acc=0.917858642753 roc=0.600514301463 not=3325 yes=780 no=36374 true=37154 all-1-0=(0.2131-0.9879)\n",
      "6 acc=0.864250599076 roc=0.768351903302 not=5495 yes=4914 no=30070 true=34984 all-1-0=(0.6088-0.9279)\n",
      "7 acc=0.893722671015 roc=0.574700047997 not=4302 yes=739 no=35438 true=36177 all-1-0=(0.1651-0.9843)\n",
      "8 acc=0.994836828973 roc=0.5 not=209 yes=0 no=40270 true=40270 all-1-0=(0.0000-1.0000)\n",
      "9 acc=0.978532078362 roc=0.86827718369 not=869 yes=1557 no=38053 true=39610 all-1-0=(0.7453-0.9912)\n",
      "10 acc=0.945527310457 roc=0.897073753302 not=2205 yes=5965 no=32309 true=38274 all-1-0=(0.8215-0.9726)\n",
      "11 acc=0.997529583241 roc=0.5 not=100 yes=0 no=40379 true=40379 all-1-0=(0.0000-1.0000)\n",
      "12 acc=0.979050865881 roc=0.531952523135 not=848 yes=56 no=39575 true=39631 all-1-0=(0.0650-0.9989)\n",
      "13 acc=0.993823958102 roc=0.768740602581 not=250 yes=183 no=40046 true=40229 all-1-0=(0.5398-0.9977)\n",
      "14 acc=0.991798216359 roc=0.5 not=332 yes=0 no=40147 true=40147 all-1-0=(0.0000-1.0000)\n",
      "15 acc=0.991600583018 roc=0.5 not=340 yes=0 no=40139 true=40139 all-1-0=(0.0000-1.0000)\n",
      "16 acc=0.997578991576 roc=0.5 not=98 yes=0 no=40381 true=40381 all-1-0=(0.0000-1.0000)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc=0.914004792609 roc=0.791948027198 not=3481 yes=4442 no=32556 true=36998 all-1-0=(0.5994-0.9845)\n",
      "1 acc=0.933125818326 roc=0.673498547836 not=2707 yes=1305 no=36467 true=37772 all-1-0=(0.3566-0.9904)\n",
      "2 acc=0.879690703822 roc=0.767480634104 not=4870 yes=4688 no=30921 true=35609 all-1-0=(0.5808-0.9541)\n",
      "3 acc=0.901306850466 roc=0.603901122213 not=3995 yes=994 no=35490 true=36484 all-1-0=(0.2220-0.9858)\n"
     ]
    }
   ],
   "source": [
    "temp = estimateResult(trY,trP01,printOK=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 40479,     0,     0,  7411, 33068,  4442, 32556,  3481],\n",
       "       [    1, 40479,     0,     0,  3660, 36819,  1305, 36467,  2707],\n",
       "       [    2, 40479,     0,     0,  8071, 32408,  4688, 30921,  4870],\n",
       "       [    3, 40479,     0,     0,  4477, 36002,   994, 35490,  3995]], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(temp,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 5)\n",
      "0 acc=0.953556164925 roc=0.776106519169 not=1880 yes=1541 no=37058 true=38599 all-1-0=(0.5714-0.9808)\n",
      "1 acc=0.958422885941 roc=0.857560689368 not=1683 yes=36603 no=2193 true=38796 all-1-0=(0.9757-0.7394)\n",
      "2 acc=0.85733343215 roc=0.788034858816 not=5775 yes=7525 no=27179 true=34704 all-1-0=(0.6110-0.9650)\n",
      "3 acc=0.813483534672 roc=0.836660016401 not=7550 yes=22159 no=10770 true=32929 all-1-0=(0.7794-0.8939)\n",
      "4 acc=0.87848019961 roc=0.677864984878 not=4919 yes=2678 no=32882 true=35560 all-1-0=(0.3614-0.9944)\n"
     ]
    }
   ],
   "source": [
    "print(trY.shape)\n",
    "fres = []\n",
    "trP01 = getProb01(trP)\n",
    "for i in range(trY.shape[1]) :\n",
    "        cm = confusion_matrix(trY[:,i],trP01[:,i])\n",
    "        print('{} acc={} roc={} not={} yes={} no={} true={} all-1-0=({:.4f}-{:.4f})'.format(i,\n",
    "                  skm.accuracy_score(trY[:,i],trP01[:,i]),\n",
    "                  skm.roc_auc_score(trY[:,i],trP01[:,i]),\n",
    "                  cm[0,1]+cm[1,0],\n",
    "                  cm[0,0],cm[1,1],\n",
    "                  cm[0,0]+cm[1,1],\n",
    "                  float(cm[0,0])/len(trY[trY[:,i]==1,i]),\n",
    "                  float(cm[1,1])/len(trY[trY[:,i]==0,i]),\n",
    "                 ));\n",
    "        fres.append ((i,trY.shape[0],\n",
    "                skm.accuracy_score(trY[:,i],trP01[:,i]),\n",
    "                #skm.accuracy_score(trY[:,i],trP01[:,i]),\n",
    "                skm.roc_auc_score(trY[:,i],trP01[:,i]),\n",
    "                  cm[0,1]+cm[1,0]))\n",
    "fresList.append(fres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9d70b1350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9/jNtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9687b40d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x[4] for x in fresList[-1]]); \n",
    "plt.plot([x[4] for x in fresList[-2]]); \n",
    "plt.show()\n",
    "plt.plot([x[2] for x in fresList[-1]]); \n",
    "plt.plot([x[2] for x in fresList[-2]]); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20 05:22:01.009723 0 --> 70 0.758419290079 [0.75741733368803943, 0.75841929007857778, 0.75785138394714635]\n",
      "2017-05-20 05:22:23.972821 1 --> 78 0.982638483662 [0.98262473453994426, 0.98263848366246676, 0.98259679666709321]\n",
      "2017-05-20 05:22:52.632376 2 --> 58 0.847226297632 [0.8469111862002846, 0.84722629763157453, 0.84682213028656683]\n",
      "2017-05-20 05:23:27.033547 3 --> 78 0.97604678248 [0.97585536488705449, 0.97604678247993626, 0.97586138532621902]\n",
      "2017-05-20 05:24:07.288213 4 --> 39 0.78729476795 [0.78664609854346335, 0.78729476795032916, 0.78707371492899492]\n",
      "2017-05-20 05:24:52.980975 5 --> 42 0.789568102568 [0.78871126051941221, 0.78956810256787635, 0.78669767415698355]\n",
      "2017-05-20 05:25:44.022237 6 --> 47 0.830831644043 [0.8305167161398419, 0.83083164404299403, 0.83015444819651052]\n",
      "2017-05-20 05:26:40.712293 7 --> 45 0.738016164169 [0.73686966073098015, 0.73801616416924898, 0.73773213859960107]\n",
      "2017-05-20 05:27:43.679293 8 --> 26 0.676190170231 [0.6690774577597115, 0.6761901702314258, 0.65439641541326066]\n",
      "2017-05-20 05:28:52.203737 9 --> 99 0.860687873635 [0.84540789671187133, 0.86068787363532673]\n",
      "2017-05-20 05:30:06.360727 10 --> 53 0.964034283738 [0.96339687009527564, 0.96403428373772715, 0.96364205060652686]\n",
      "2017-05-20 05:31:26.352144 11 --> 30 0.900537376612 [0.89285689393748568, 0.90053737661152566, 0.90053737661152566]\n",
      "2017-05-20 05:32:51.552201 12 --> 27 0.652844152686 [0.64595635259618922, 0.6528441526860862, 0.65053736636295179]\n",
      "2017-05-20 05:34:22.405562 13 --> 24 0.863599425241 [0.86179482608466784, 0.86359942524081812, 0.85725979475579062]\n",
      "2017-05-20 05:35:59.177670 14 --> 14 0.370370055203 [0.3600540358709392, 0.37037005520335736, 0.35595995253798635]\n",
      "2017-05-20 05:37:41.803909 15 --> 22 0.683823292523 [0.67335220282476826, 0.68382329252278806, 0.67567543551442677]\n",
      "2017-05-20 05:39:29.432537 16 --> 14 0.589171696773 [0.56748439106677917, 0.58917169677281178, 0.5851060891681884]\n"
     ]
    }
   ],
   "source": [
    "rr, rrx = [], []; trP = model.predict(trX, batch_size=128)\n",
    "for i in range(trP.shape[1]) :\n",
    "    xx = [];\n",
    "    trYY = trY[:,i].astype(np.float64)\n",
    "    trPY = trP[:,i]\n",
    "    for ii in range(100) :\n",
    "        trPP = (trPY>0.01*ii).astype(np.float64)\n",
    "        #x = fbeta_score(trY[:,0], np.array(trP[:,0] > 0.1*ii), beta=2, average='samples')\n",
    "        x = K.get_value(fbeta_pred(trYY,trPP))\n",
    "        xx.append(x)\n",
    "    rrr = np.array(xx).argmax();\n",
    "    rr.append(rrr)\n",
    "    rrx.append(xx[rrr])\n",
    "    print(datetime.datetime.now(),i,'-->',rrr,xx[rrr],xx[(rrr-1):(rrr+2)])\n",
    "    #print(xx);\n",
    "    #plt.plot(np.array(xx)); plt.show()\n",
    "trM = np.array(rr)/100.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191\n",
      "2017-05-20 05:46:19.287685 61191 61191\n",
      "2017-05-20 05:46:38.218814 \t 0 \t 5000 \t test_14523.jpg \t \n",
      "2017-05-20 05:46:51.023731 \t 1 \t 10000 \t test_19029.jpg \t (10000, 17)\n",
      "2017-05-20 05:46:58.884016 \t 1 \t 15000 \t test_23524.jpg \t (10000, 17)\n",
      "2017-05-20 05:47:09.507695 \t 2 \t 20000 \t test_28015.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:16.475888 \t 2 \t 25000 \t test_32520.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:26.837760 \t 3 \t 30000 \t test_37026.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:33.858034 \t 3 \t 35000 \t test_4908.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:44.019579 \t 4 \t 40000 \t test_9402.jpg \t (40000, 17)\n",
      "2017-05-20 05:47:51.298769 \t 4 \t 45000 \t file_13913.jpg \t (40000, 17)\n",
      "2017-05-20 05:48:01.555641 \t 5 \t 50000 \t file_18419.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:24.538867 \t 5 \t 55000 \t file_4564.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:40.785101 \t 6 \t 60000 \t file_892.jpg \t (60000, 17)\n",
      "2017-05-20 05:48:43.863555\n"
     ]
    }
   ],
   "source": [
    "#nameAsk = os.listdir(teDirI); print(len(nameAsk))\n",
    "nameAsk = os.listdir(teDirJPG); print(len(nameAsk))\n",
    "trOX, trOY, i, ii, size = [], [], 0, 0, len(nameAsk)\n",
    "print(datetime.datetime.now(),len(nameAsk),size)\n",
    "for nn in nameAsk[0:size] :\n",
    "    #nf = os.path.join(teDirTIF,nn);\n",
    "    nf = os.path.join(teDirJPG,nn);\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        trOX.append(nx)\n",
    "        trOY.append(nn)\n",
    "    i += 1\n",
    "    if (i%10000==0) and (i>1) :\n",
    "        if (ii==0) :\n",
    "            trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "            trP = model.predict(trOX, batch_size=512); \n",
    "        else :\n",
    "            trOX = np.array(trOX);  trOX = trOX / 255.0\n",
    "            trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "        trOX,ii = [],ii+1;\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",ii,'\\t',i,\"\\t\",nn,'\\t',(trP.shape if ii>0 else \"\"))\n",
    "\n",
    "if (len(trOX)>0) :\n",
    "    if (ii==0) :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = model.predict(trOX, batch_size=512); \n",
    "    else :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "    trOX,ii = [],ii+1;\n",
    "    \n",
    "print(datetime.datetime.now())\n",
    "\n",
    "#assert (size!=len(trOY)), \"Wrong files {} != {}\".format(size,len(trOY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191 (61191, 17) (61191,)\n"
     ]
    }
   ],
   "source": [
    "#trOX = np.array(trOX);\n",
    "trOY = np.array([os.path.splitext(x)[0] for x in trOY]);\n",
    "print(len(nameAsk),trP.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy',trOX)\n",
    "np.save('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 32, 32, 6) (61191,)\n"
     ]
    }
   ],
   "source": [
    "trOX = np.load('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy')\n",
    "trOY = np.load('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy')\n",
    "print(trOX.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.75841929007857778,\n",
       " 1: 0.98263848366246676,\n",
       " 2: 0.84722629763157453,\n",
       " 3: 0.97604678247993626,\n",
       " 4: 0.78729476795032916,\n",
       " 5: 0.78956810256787635,\n",
       " 6: 0.83083164404299403,\n",
       " 7: 0.73801616416924898,\n",
       " 8: 0.6761901702314258,\n",
       " 9: 0.86068787363532673,\n",
       " 10: 0.96403428373772715,\n",
       " 11: 0.90053737661152566,\n",
       " 12: 0.6528441526860862,\n",
       " 13: 0.86359942524081812,\n",
       " 14: 0.37037005520335736,\n",
       " 15: 0.68382329252278806,\n",
       " 16: 0.58917169677281178}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrx\n",
    "rrd=dict()\n",
    "for i in range(len(rrx)) :\n",
    "    rrd[i]=rrx[i]\n",
    "rrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Forming result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61191, 17), array([  6.56801313e-02,   7.46541142e-01,   2.32726157e-01,\n",
       "          9.55386758e-01,   1.95543230e-01,   9.11955476e-01,\n",
       "          8.89197826e-01,   2.53069662e-02,   1.54045611e-05,\n",
       "          7.43342913e-04,   6.54759035e-02,   6.17289741e-04,\n",
       "          8.51887614e-02,   2.95602629e-04,   2.64362683e-07,\n",
       "          1.03749386e-04,   2.92145728e-07], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trP = model.predict(trOX, batch_size=512); \n",
    "trP.shape, trP[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "[3, 10, 0, 9] \n",
      " ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down'] \n",
      " [2.0, 0.5, 0.5, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "trM=np.array([0.0]*len(labels)); print(trM.shape)\n",
    "wr = [labels.index(i) for i in weather_labels];\n",
    "tt=trM; trM[:]=0.5\n",
    "trM[np.array(wr)] = 2.0\n",
    "print(wr,'\\n',labels,'\\n',trM.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'clear primary'] \n",
      " ['file_20521', 'clear primary'] \n",
      " [ 2.   0.5  0.5  2.   0.5  0.5  0.5  0.5  0.5  2.   2.   0.5  0.5  0.5  0.5\n",
      "  0.5  0.5] [  1.63650557e-01   3.91220033e-01   1.36160061e-01   9.47374701e-01\n",
      "   9.09343541e-01   1.55211976e-02   3.13203782e-02   1.42206885e-02\n",
      "   8.06170846e-08   9.10553038e-01   7.85041321e-03   4.12757437e-08\n",
      "   6.71853591e-03   1.33155788e-06   7.46736941e-06   9.65268737e-06\n",
      "   7.95199711e-08]\n"
     ]
    }
   ],
   "source": [
    "#trP = model.predict(trX, batch_size=512); trP=K.get_value(trP)\n",
    "res = []\n",
    "\n",
    "for i in range(trP.shape[0]) :\n",
    "    trPP = [weather_labels[trP[i,wr].argmax()]] + [labels[ii] for ii in range(len(labels)) if (trP[i,ii]>trM[ii])];\n",
    "    pp   = ' '.join(trPP)\n",
    "    ##if (pp==\"\") : print(trY[i])\n",
    "    res.append([trOY[i],pp])\n",
    "\n",
    "res.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n",
    "#print(res[4:8],'\\n',res[-4:])\n",
    "print(res[0],'\\n',res[-1],'\\n',trM,trP[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "#print(trM.tolist())\n",
    "#np.round(trP[4:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20-05-51-18\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(res,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Склад барахла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG16Natural ( include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildModel (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    if (cv2d is None) and (dense is None) and not (params is None) : cv2d, dense = params[:-2], params[-2:]\n",
    "    model = Kriz2012x3x3(model,iSize,rSize,cv2d=cv2d,dense=dense,pp=params)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "def buildModelKriz (iSize,rSize) :\n",
    "    model = Sequential()\n",
    "    \n",
    "    model = Kriz2012(model,iSize,rSize)\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    sgd = keras.optimizers.SGD(nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "                  optimizer=\"sgd\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=['acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "#from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=False)\n",
    "model10 = VGG16(weights=None,input_shape=(224,224,3),include_top=True,classes=4)\n",
    "\n",
    "#x = (Dense(512,activation='relu'))(model10)\n",
    "#model10.add(Dropout(0.25))\n",
    "#model10.add(Dense(4,activation='sigmoid'))\n",
    "\n",
    "#img_path = 'elephant.jpg'\n",
    "#img = image.load_img(img_path, target_size=(224, 224))\n",
    "#x = image.img_to_array(img)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "\n",
    "#features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
