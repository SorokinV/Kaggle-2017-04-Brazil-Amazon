{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## AlexNet analog (Krizhevsky 2012)\n",
    "##\n",
    "## 2017-05-20\n",
    "## maximum on LB => 0.84500\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import formFH, paths_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Data/test-jpg-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, teDirJPG, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy',trX)\n",
    "##np.save('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38390, 128, 128, 3) (38390, 16)\n"
     ]
    }
   ],
   "source": [
    "if False :\n",
    "    ###trXX = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-XX.npy')\n",
    "    ###trYY = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    trXX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "    trYY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "\n",
    "    trX, trY = trXX[trYY[:,9]==0], trYY[trYY[:,9]==0] # not cloudy == 9 feature\n",
    "    trY=trY[:,range(0,9)+range(10,17)] # --cloudy <> 9\n",
    "    del trXX,trYY\n",
    "    #print(trXX.shape,trYY.shape)\n",
    "    print(trX.shape,trY.shape)\n",
    "if False :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX-short.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY-short.npy')\n",
    "    print(trX.shape,trY.shape)\n",
    "if True :\n",
    "    trX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX-not-cloudy.npy')\n",
    "    trY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY-not-cloudy.npy')\n",
    "    print(trX.shape,trY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-42221122990d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trX' is not defined"
     ]
    }
   ],
   "source": [
    "print(trX.shape,trY.shape)\n",
    "del trX, trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#trX=trX/255.0\n",
    "##trX = cv.normalize(trX, trX, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "#trX=trX/65535.0\n",
    "#trX[0,:,:]\n",
    "#trX[:,:,:,5].max(),trX.min(),trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fbeta_pred(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "#\n",
    "def Kriz2012 ( model, iSize, rSize ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    model.add(Convolution2D(96,(11,11),strides=(4,4),activation='relu'))\n",
    "    model.add(Convolution2D(256,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(256,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)\n",
    "\n",
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "#\n",
    "def Kriz2012X ( model, iSize, rSize ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    model.add(Convolution2D(96,(11,11),strides=(4,4),activation='relu'))\n",
    "    model.add(Convolution2D(256,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    #model.add(Convolution2D(256,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(128,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    #model.add(Dense(4096,activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "# cut version\n",
    "#\n",
    "#\n",
    "def Kriz2012x3x3 ( model, iSize, rSize, cv2d, dense, pp ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(axis=3,input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    if not (cv2d is None) :\n",
    "        for cv in cv2d :\n",
    "            if (cv>0) :\n",
    "                model.add(Convolution2D(cv,(2,2)))\n",
    "                #model.add(BatchNormalization(axis=3))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if not (dense is None) :\n",
    "        for de in dense :\n",
    "            if (de>0) :\n",
    "                model.add(Dense(pp[5],activation='relu'))\n",
    "                model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildModel (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    if (cv2d is None) and (dense is None) and not (params is None) : cv2d, dense = params[:-2], params[-2:]\n",
    "    model = Kriz2012x3x3(model,iSize,rSize,cv2d=cv2d,dense=dense,pp=params)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "def buildModelKriz (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    \n",
    "    model = Kriz2012(model,iSize,rSize)\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    sgd = keras.optimizers.SGD(nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', # 'mean_absolute_error'\n",
    "                  optimizer=\"sgd\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#mm1=np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "#mm2=np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "#mm1,mm2,mm1+mm2\n",
    "#len(result),len(resAll)\n",
    "#trX.shape,trX.dtype,trX[0]\n",
    "#trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resAll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) 16\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=12,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "params = [(32,64,32,0,0,256,0),(32,64,16,0,0,256,0),(32,64,32,0,0,256,0),(32,64,64,0,0,256,0),(32,64,128,0,0,256,0),(32,64,256,0,0,256,0),(32,64,512,0,0,256,0),(32,64,1024,0,0,256,0)]\n",
    "params = params+[(32,64,8,0,0,16,0),(32,64,16,0,0,256,0),(32,64,32,0,0,64,0),(32,64,64,0,0,128,0),(32,64,128,0,0,256,0),(32,64,256,0,0,512,0),(32,64,512,0,0,1024,0),(32,64,1024,0,0,2048,0)]\n",
    "params = params+[(32,64,8,0,0,16,128),(32,64,16,0,0,32,128),(32,64,32,0,0,64,128),(32,64,64,0,0,128,128),(32,64,128,0,0,256,128),(32,64,256,0,0,512,128),(32,64,512,0,0,1024,128),(32,64,1024,0,0,2048,128)]\n",
    "params = params+[(96,256,384,384,256,4096,4096),(96,256,384,384,256,4096,2048),(96,256,384,384,256,2048,4096),(96,256,384,384,256,2048,2048),\n",
    "          (96,256,384,384,0,4096,0),(96,256,384,0,256,4096,0),(96,256,0,0,256,4096,0),\n",
    "          (96,256,0,0,0,4096,0),(96,0,0,0,0,4096,0),(96,256,0,0,256,4096,0)]\n",
    "#         (96,256,384,197,256,4096,0),  bad unchausted memory ResourceExhaustedError: OOM when allocating tensor with shape[128,8,8,384]\n",
    "#         (96,128,0,0,0,4096,0),\n",
    "#\n",
    "#        [(96,256,197,0,0,4096,0), (96,256,384,384,256,4096,0)]\n",
    "#\n",
    "#       [(96,32,0,0,0,1024,0),(96,64,0,0,0,1024,0),(96,128,0,0,0,1024,0),(96,256,0,0,0,1024,0),\n",
    "#         (256,32,0,0,0,1024,0),(256,64,0,0,0,1024,0),(256,128,0,0,0,1024,0)]\n",
    "\n",
    "params = [(96,64,0,0,0,256,0),(96,64,0,0,0,512,0),(96,64,0,0,0,1024,0),(96,64,0,0,0,2048,0),(96,64,0,0,0,8192,0)]\n",
    "params = params+[(16,64,0,0,0,256,0),(32,64,0,0,0,256,0),(64,64,0,0,0,256,0),(128,64,0,0,0,256,0),(256,64,0,0,0,256,0)]\n",
    "\n",
    "params = [(32,64,16,0,0,256,0)] \n",
    "params = [(16,32,64,256,0,512,512),(8,64,256,1024,0,512,512),(8,64,256,1024,0,0,512),(8,64,256,2048,0,0,512),(8,64,256,2048,0,512,512),\n",
    "          (8,64,256,2048,0,1024,0),(8,64,256,2048,0,1024,1024)]\n",
    "##params = [(8,64,256,1024,0,512,512),(8,64,256,1024,0,512,0)]\n",
    "params = [(8,64,256,2048,0,2048,0)] # 0.87 0.87\n",
    "params = [(8,64,256,4096,0,1024,0)] # 0.8686 0.8724\n",
    "params = [(32,64,16,0,0,256,512),(8,64,256,2048,0,1024,0),(8,64,256,2048,0,512,0),(8,64,256,4096,0,256,0)] # 0.875 0.8796\n",
    "params = [(32,64,16,0,0,256,512)]\n",
    "\n",
    "#params = [(8,64,256,4096,0,256,0)]\n",
    "\n",
    "iSize, rSize, result = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], []\n",
    "print(iSize,rSize)\n",
    "epochs  = 100\n",
    "verbose = 2\n",
    "batch_size = 64 # 64 0.8633 0.8717 (68 secs/batch) # 32 0.8545 0.8653 (87 secs/batch) # 16 0.8483 0.8623 (137 secs/batch) # 32\n",
    "for pp in [] : #params :\n",
    "    filepath=\"../Data-Keras/weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    model1 = buildModel(iSize,rSize,pp)\n",
    "    tr1=np.sum([K.count_params(p) for p in set(model1.trainable_weights)])\n",
    "    tr2=np.sum([K.count_params(p) for p in set(model1.non_trainable_weights)])\n",
    "    if (tr1+tr2)>14000000 : \n",
    "        print(datetime.datetime.now(),pp,tr1+tr2,'(badly)')\n",
    "        continue;\n",
    "    print(datetime.datetime.now(),pp,tr1+tr2)\n",
    "    hist1  = model1.fit(trX,trY,epochs=epochs, batch_size=batch_size, validation_split=0.20, \n",
    "                        callbacks=[early_stopping,reduce_lr,checkpoint],\n",
    "                        verbose=verbose)\n",
    "    \n",
    "    trP = model1.predict(trX, batch_size=128)\n",
    "    fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "    fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "    #print(datetime.datetime.now(),pp,hist1.history['fbeta_pred'][-1],hist1.history['val_fbeta_pred'][-1],'fbeta2s=',fbeta2score,fbeta2pred)\n",
    "    print(datetime.datetime.now(),pp,'fbeta2s=',fbeta2score,fbeta2pred)\n",
    "    result.append([pp,hist1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) 16\n"
     ]
    }
   ],
   "source": [
    "iSize, rSize, result = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], []\n",
    "params = (32,64,128,256,0,256,512)\n",
    "print(iSize,rSize)\n",
    "metric = 'acc'\n",
    "model10 = buildModelKriz(iSize,rSize,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    sgd = keras.optimizers.SGD(nesterov=True)\n",
    "    model10.compile(loss= 'binary_crossentropy', \n",
    "                #'mean_squared_error', #'mean_absolute_error',  #'binary_crossentropy','categorical_crossentropy',\n",
    "                  optimizer=\"rmsprop\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[metric,fbeta_pred]) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model10.load_weights('../Data-Keras/Models/model-Alex-weights-128x128x3.h5', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 12:50:07.798649 125455772\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: acc improved from -inf to 0.91825, saving model to ../Temp/weights.00-acc=0.9182-val_acc=0.9210625-val_fbeta_pred=0.8175.hdf5\n",
      "127s - loss: 0.1997 - fbeta_pred: 0.8087 - acc: 0.9182 - val_loss: 0.1899 - val_fbeta_pred: 0.8175 - val_acc: 0.9211\n",
      "Epoch 2/100\n",
      "Epoch 00001: acc improved from 0.91825 to 0.91839, saving model to ../Temp/weights.01-acc=0.9184-val_acc=0.923453125-val_fbeta_pred=0.8206.hdf5\n",
      "127s - loss: 0.1989 - fbeta_pred: 0.8088 - acc: 0.9184 - val_loss: 0.1873 - val_fbeta_pred: 0.8206 - val_acc: 0.9235\n",
      "Epoch 3/100\n",
      "Epoch 00002: acc improved from 0.91839 to 0.91872, saving model to ../Temp/weights.02-acc=0.9187-val_acc=0.9245-val_fbeta_pred=0.8246.hdf5\n",
      "127s - loss: 0.1979 - fbeta_pred: 0.8102 - acc: 0.9187 - val_loss: 0.1868 - val_fbeta_pred: 0.8246 - val_acc: 0.9245\n",
      "Epoch 4/100\n",
      "Epoch 00003: acc improved from 0.91872 to 0.91916, saving model to ../Temp/weights.03-acc=0.9192-val_acc=0.9236875-val_fbeta_pred=0.8285.hdf5\n",
      "127s - loss: 0.1974 - fbeta_pred: 0.8111 - acc: 0.9192 - val_loss: 0.1875 - val_fbeta_pred: 0.8285 - val_acc: 0.9237\n",
      "Epoch 5/100\n",
      "Epoch 00004: acc improved from 0.91916 to 0.91949, saving model to ../Temp/weights.04-acc=0.9195-val_acc=0.9200625-val_fbeta_pred=0.8014.hdf5\n",
      "127s - loss: 0.1965 - fbeta_pred: 0.8122 - acc: 0.9195 - val_loss: 0.1916 - val_fbeta_pred: 0.8014 - val_acc: 0.9201\n",
      "Epoch 6/100\n",
      "Epoch 00005: acc improved from 0.91949 to 0.92003, saving model to ../Temp/weights.05-acc=0.9200-val_acc=0.922703125-val_fbeta_pred=0.8181.hdf5\n",
      "127s - loss: 0.1958 - fbeta_pred: 0.8139 - acc: 0.9200 - val_loss: 0.1880 - val_fbeta_pred: 0.8181 - val_acc: 0.9227\n",
      "Epoch 7/100\n",
      "Epoch 00006: acc did not improve\n",
      "122s - loss: 0.1956 - fbeta_pred: 0.8123 - acc: 0.9198 - val_loss: 0.1868 - val_fbeta_pred: 0.8182 - val_acc: 0.9240\n",
      "Epoch 8/100\n",
      "Epoch 00007: acc improved from 0.92003 to 0.92034, saving model to ../Temp/weights.07-acc=0.9203-val_acc=0.9236875-val_fbeta_pred=0.8146.hdf5\n",
      "127s - loss: 0.1946 - fbeta_pred: 0.8144 - acc: 0.9203 - val_loss: 0.1868 - val_fbeta_pred: 0.8146 - val_acc: 0.9237\n",
      "Epoch 9/100\n",
      "Epoch 00008: acc improved from 0.92034 to 0.92064, saving model to ../Temp/weights.08-acc=0.9206-val_acc=0.9230625-val_fbeta_pred=0.8131.hdf5\n",
      "127s - loss: 0.1941 - fbeta_pred: 0.8155 - acc: 0.9206 - val_loss: 0.1885 - val_fbeta_pred: 0.8131 - val_acc: 0.9231\n",
      "Epoch 10/100\n",
      "Epoch 00009: acc improved from 0.92064 to 0.92187, saving model to ../Temp/weights.09-acc=0.9219-val_acc=0.925171875-val_fbeta_pred=0.8271.hdf5\n",
      "127s - loss: 0.1914 - fbeta_pred: 0.8188 - acc: 0.9219 - val_loss: 0.1848 - val_fbeta_pred: 0.8271 - val_acc: 0.9252\n",
      "Epoch 11/100\n",
      "Epoch 00010: acc did not improve\n",
      "122s - loss: 0.1913 - fbeta_pred: 0.8181 - acc: 0.9217 - val_loss: 0.1846 - val_fbeta_pred: 0.8265 - val_acc: 0.9245\n",
      "Epoch 12/100\n",
      "Epoch 00011: acc improved from 0.92187 to 0.92199, saving model to ../Temp/weights.11-acc=0.9220-val_acc=0.925-val_fbeta_pred=0.8278.hdf5\n",
      "127s - loss: 0.1909 - fbeta_pred: 0.8186 - acc: 0.9220 - val_loss: 0.1846 - val_fbeta_pred: 0.8278 - val_acc: 0.9250\n",
      "Epoch 13/100\n",
      "Epoch 00012: acc improved from 0.92199 to 0.92229, saving model to ../Temp/weights.12-acc=0.9223-val_acc=0.92471875-val_fbeta_pred=0.8237.hdf5\n",
      "127s - loss: 0.1908 - fbeta_pred: 0.8198 - acc: 0.9223 - val_loss: 0.1848 - val_fbeta_pred: 0.8237 - val_acc: 0.9247\n",
      "Epoch 14/100\n",
      "Epoch 00013: acc improved from 0.92229 to 0.92246, saving model to ../Temp/weights.13-acc=0.9225-val_acc=0.9244375-val_fbeta_pred=0.8189.hdf5\n",
      "127s - loss: 0.1907 - fbeta_pred: 0.8205 - acc: 0.9225 - val_loss: 0.1851 - val_fbeta_pred: 0.8189 - val_acc: 0.9244\n",
      "Epoch 15/100\n",
      "Epoch 00014: acc improved from 0.92246 to 0.92248, saving model to ../Temp/weights.14-acc=0.9225-val_acc=0.924453125-val_fbeta_pred=0.8212.hdf5\n",
      "127s - loss: 0.1903 - fbeta_pred: 0.8200 - acc: 0.9225 - val_loss: 0.1848 - val_fbeta_pred: 0.8212 - val_acc: 0.9245\n",
      "Epoch 16/100\n",
      "Epoch 00015: acc did not improve\n",
      "122s - loss: 0.1903 - fbeta_pred: 0.8206 - acc: 0.9225 - val_loss: 0.1849 - val_fbeta_pred: 0.8232 - val_acc: 0.9248\n",
      "Epoch 17/100\n",
      "Epoch 00016: acc improved from 0.92248 to 0.92275, saving model to ../Temp/weights.16-acc=0.9227-val_acc=0.92490625-val_fbeta_pred=0.8236.hdf5\n",
      "127s - loss: 0.1898 - fbeta_pred: 0.8207 - acc: 0.9227 - val_loss: 0.1841 - val_fbeta_pred: 0.8236 - val_acc: 0.9249\n",
      "Epoch 18/100\n",
      "Epoch 00017: acc did not improve\n",
      "122s - loss: 0.1897 - fbeta_pred: 0.8202 - acc: 0.9225 - val_loss: 0.1838 - val_fbeta_pred: 0.8264 - val_acc: 0.9252\n",
      "Epoch 19/100\n",
      "Epoch 00018: acc did not improve\n",
      "122s - loss: 0.1895 - fbeta_pred: 0.8208 - acc: 0.9226 - val_loss: 0.1838 - val_fbeta_pred: 0.8256 - val_acc: 0.9253\n",
      "Epoch 20/100\n",
      "Epoch 00019: acc improved from 0.92275 to 0.92291, saving model to ../Temp/weights.19-acc=0.9229-val_acc=0.924953125-val_fbeta_pred=0.8228.hdf5\n",
      "127s - loss: 0.1897 - fbeta_pred: 0.8213 - acc: 0.9229 - val_loss: 0.1842 - val_fbeta_pred: 0.8228 - val_acc: 0.9250\n",
      "Epoch 21/100\n",
      "Epoch 00020: acc did not improve\n",
      "122s - loss: 0.1893 - fbeta_pred: 0.8211 - acc: 0.9227 - val_loss: 0.1835 - val_fbeta_pred: 0.8273 - val_acc: 0.9251\n",
      "Epoch 22/100\n",
      "Epoch 00021: acc did not improve\n",
      "122s - loss: 0.1896 - fbeta_pred: 0.8208 - acc: 0.9227 - val_loss: 0.1834 - val_fbeta_pred: 0.8272 - val_acc: 0.9253\n",
      "Epoch 23/100\n",
      "Epoch 00022: acc improved from 0.92291 to 0.92296, saving model to ../Temp/weights.22-acc=0.9230-val_acc=0.925234375-val_fbeta_pred=0.8256.hdf5\n",
      "127s - loss: 0.1892 - fbeta_pred: 0.8214 - acc: 0.9230 - val_loss: 0.1835 - val_fbeta_pred: 0.8256 - val_acc: 0.9252\n",
      "Epoch 24/100\n",
      "Epoch 00023: acc did not improve\n",
      "122s - loss: 0.1889 - fbeta_pred: 0.8217 - acc: 0.9229 - val_loss: 0.1833 - val_fbeta_pred: 0.8290 - val_acc: 0.9255\n",
      "Epoch 25/100\n",
      "Epoch 00024: acc improved from 0.92296 to 0.92323, saving model to ../Temp/weights.24-acc=0.9232-val_acc=0.925375-val_fbeta_pred=0.8266.hdf5\n",
      "134s - loss: 0.1890 - fbeta_pred: 0.8226 - acc: 0.9232 - val_loss: 0.1834 - val_fbeta_pred: 0.8266 - val_acc: 0.9254\n",
      "Epoch 26/100\n",
      "Epoch 00025: acc did not improve\n",
      "122s - loss: 0.1886 - fbeta_pred: 0.8218 - acc: 0.9231 - val_loss: 0.1832 - val_fbeta_pred: 0.8260 - val_acc: 0.9254\n",
      "Epoch 27/100\n",
      "Epoch 00026: acc improved from 0.92323 to 0.92350, saving model to ../Temp/weights.26-acc=0.9235-val_acc=0.925171875-val_fbeta_pred=0.8241.hdf5\n",
      "127s - loss: 0.1882 - fbeta_pred: 0.8230 - acc: 0.9235 - val_loss: 0.1838 - val_fbeta_pred: 0.8241 - val_acc: 0.9252\n",
      "Epoch 28/100\n",
      "Epoch 00027: acc did not improve\n",
      "122s - loss: 0.1888 - fbeta_pred: 0.8215 - acc: 0.9230 - val_loss: 0.1831 - val_fbeta_pred: 0.8298 - val_acc: 0.9257\n",
      "Epoch 29/100\n",
      "Epoch 00028: acc did not improve\n",
      "122s - loss: 0.1880 - fbeta_pred: 0.8222 - acc: 0.9231 - val_loss: 0.1829 - val_fbeta_pred: 0.8306 - val_acc: 0.9258\n",
      "Epoch 30/100\n",
      "Epoch 00029: acc did not improve\n",
      "122s - loss: 0.1883 - fbeta_pred: 0.8224 - acc: 0.9233 - val_loss: 0.1829 - val_fbeta_pred: 0.8303 - val_acc: 0.9258\n",
      "Epoch 31/100\n",
      "Epoch 00030: acc did not improve\n",
      "122s - loss: 0.1876 - fbeta_pred: 0.8219 - acc: 0.9231 - val_loss: 0.1831 - val_fbeta_pred: 0.8226 - val_acc: 0.9252\n",
      "Epoch 32/100\n",
      "Epoch 00031: acc improved from 0.92350 to 0.92354, saving model to ../Temp/weights.31-acc=0.9235-val_acc=0.925984375-val_fbeta_pred=0.8313.hdf5\n",
      "127s - loss: 0.1877 - fbeta_pred: 0.8229 - acc: 0.9235 - val_loss: 0.1827 - val_fbeta_pred: 0.8313 - val_acc: 0.9260\n",
      "Epoch 33/100\n",
      "Epoch 00032: acc improved from 0.92354 to 0.92361, saving model to ../Temp/weights.32-acc=0.9236-val_acc=0.925296875-val_fbeta_pred=0.8265.hdf5\n",
      "127s - loss: 0.1876 - fbeta_pred: 0.8230 - acc: 0.9236 - val_loss: 0.1829 - val_fbeta_pred: 0.8265 - val_acc: 0.9253\n",
      "Epoch 34/100\n",
      "Epoch 00033: acc improved from 0.92361 to 0.92407, saving model to ../Temp/weights.33-acc=0.9241-val_acc=0.924765625-val_fbeta_pred=0.8199.hdf5\n",
      "127s - loss: 0.1870 - fbeta_pred: 0.8251 - acc: 0.9241 - val_loss: 0.1836 - val_fbeta_pred: 0.8199 - val_acc: 0.9248\n",
      "Epoch 35/100\n",
      "Epoch 00034: acc did not improve\n",
      "122s - loss: 0.1872 - fbeta_pred: 0.8237 - acc: 0.9238 - val_loss: 0.1828 - val_fbeta_pred: 0.8308 - val_acc: 0.9256\n",
      "Epoch 36/100\n",
      "Epoch 00035: acc improved from 0.92407 to 0.92410, saving model to ../Temp/weights.35-acc=0.9241-val_acc=0.9258125-val_fbeta_pred=0.8307.hdf5\n",
      "127s - loss: 0.1870 - fbeta_pred: 0.8253 - acc: 0.9241 - val_loss: 0.1825 - val_fbeta_pred: 0.8307 - val_acc: 0.9258\n",
      "Epoch 37/100\n",
      "Epoch 00036: acc improved from 0.92410 to 0.92418, saving model to ../Temp/weights.36-acc=0.9242-val_acc=0.92575-val_fbeta_pred=0.8280.hdf5\n",
      "127s - loss: 0.1867 - fbeta_pred: 0.8247 - acc: 0.9242 - val_loss: 0.1828 - val_fbeta_pred: 0.8280 - val_acc: 0.9257\n",
      "Epoch 38/100\n",
      "Epoch 00037: acc did not improve\n",
      "122s - loss: 0.1867 - fbeta_pred: 0.8240 - acc: 0.9240 - val_loss: 0.1826 - val_fbeta_pred: 0.8273 - val_acc: 0.9256\n",
      "Epoch 39/100\n",
      "Epoch 00038: acc improved from 0.92418 to 0.92431, saving model to ../Temp/weights.38-acc=0.9243-val_acc=0.92575-val_fbeta_pred=0.8261.hdf5\n",
      "127s - loss: 0.1864 - fbeta_pred: 0.8254 - acc: 0.9243 - val_loss: 0.1822 - val_fbeta_pred: 0.8261 - val_acc: 0.9257\n",
      "Epoch 40/100\n",
      "Epoch 00039: acc improved from 0.92431 to 0.92431, saving model to ../Temp/weights.39-acc=0.9243-val_acc=0.925734375-val_fbeta_pred=0.8262.hdf5\n",
      "127s - loss: 0.1865 - fbeta_pred: 0.8251 - acc: 0.9243 - val_loss: 0.1824 - val_fbeta_pred: 0.8262 - val_acc: 0.9257\n",
      "Epoch 41/100\n",
      "Epoch 00040: acc did not improve\n",
      "122s - loss: 0.1862 - fbeta_pred: 0.8243 - acc: 0.9240 - val_loss: 0.1825 - val_fbeta_pred: 0.8226 - val_acc: 0.9255\n",
      "Epoch 42/100\n",
      "Epoch 00041: acc improved from 0.92431 to 0.92441, saving model to ../Temp/weights.41-acc=0.9244-val_acc=0.92615625-val_fbeta_pred=0.8319.hdf5\n",
      "127s - loss: 0.1861 - fbeta_pred: 0.8254 - acc: 0.9244 - val_loss: 0.1821 - val_fbeta_pred: 0.8319 - val_acc: 0.9262\n",
      "Epoch 43/100\n",
      "Epoch 00042: acc did not improve\n",
      "122s - loss: 0.1863 - fbeta_pred: 0.8244 - acc: 0.9240 - val_loss: 0.1818 - val_fbeta_pred: 0.8278 - val_acc: 0.9262\n",
      "Epoch 44/100\n",
      "Epoch 00043: acc did not improve\n",
      "122s - loss: 0.1857 - fbeta_pred: 0.8246 - acc: 0.9242 - val_loss: 0.1826 - val_fbeta_pred: 0.8217 - val_acc: 0.9255\n",
      "Epoch 45/100\n",
      "Epoch 00044: acc did not improve\n",
      "122s - loss: 0.1856 - fbeta_pred: 0.8251 - acc: 0.9243 - val_loss: 0.1824 - val_fbeta_pred: 0.8235 - val_acc: 0.9255\n",
      "Epoch 46/100\n",
      "Epoch 00045: acc did not improve\n",
      "122s - loss: 0.1856 - fbeta_pred: 0.8251 - acc: 0.9243 - val_loss: 0.1815 - val_fbeta_pred: 0.8272 - val_acc: 0.9262\n",
      "Epoch 47/100\n",
      "Epoch 00046: acc improved from 0.92441 to 0.92464, saving model to ../Temp/weights.46-acc=0.9246-val_acc=0.925265625-val_fbeta_pred=0.8200.hdf5\n",
      "127s - loss: 0.1853 - fbeta_pred: 0.8261 - acc: 0.9246 - val_loss: 0.1829 - val_fbeta_pred: 0.8200 - val_acc: 0.9253\n",
      "Epoch 48/100\n",
      "Epoch 00047: acc improved from 0.92464 to 0.92474, saving model to ../Temp/weights.47-acc=0.9247-val_acc=0.92625-val_fbeta_pred=0.8302.hdf5\n",
      "135s - loss: 0.1853 - fbeta_pred: 0.8259 - acc: 0.9247 - val_loss: 0.1816 - val_fbeta_pred: 0.8302 - val_acc: 0.9263\n",
      "Epoch 49/100\n",
      "Epoch 00048: acc improved from 0.92474 to 0.92486, saving model to ../Temp/weights.48-acc=0.9249-val_acc=0.926-val_fbeta_pred=0.8266.hdf5\n",
      "127s - loss: 0.1847 - fbeta_pred: 0.8269 - acc: 0.9249 - val_loss: 0.1819 - val_fbeta_pred: 0.8266 - val_acc: 0.9260\n",
      "Epoch 50/100\n",
      "Epoch 00049: acc improved from 0.92486 to 0.92488, saving model to ../Temp/weights.49-acc=0.9249-val_acc=0.92621875-val_fbeta_pred=0.8274.hdf5\n",
      "127s - loss: 0.1849 - fbeta_pred: 0.8268 - acc: 0.9249 - val_loss: 0.1813 - val_fbeta_pred: 0.8274 - val_acc: 0.9262\n",
      "Epoch 51/100\n",
      "Epoch 00050: acc improved from 0.92488 to 0.92489, saving model to ../Temp/weights.50-acc=0.9249-val_acc=0.925921875-val_fbeta_pred=0.8311.hdf5\n",
      "127s - loss: 0.1847 - fbeta_pred: 0.8266 - acc: 0.9249 - val_loss: 0.1817 - val_fbeta_pred: 0.8311 - val_acc: 0.9259\n",
      "Epoch 52/100\n",
      "Epoch 00051: acc improved from 0.92489 to 0.92507, saving model to ../Temp/weights.51-acc=0.9251-val_acc=0.92515625-val_fbeta_pred=0.8207.hdf5\n",
      "127s - loss: 0.1846 - fbeta_pred: 0.8274 - acc: 0.9251 - val_loss: 0.1833 - val_fbeta_pred: 0.8207 - val_acc: 0.9252\n",
      "Epoch 53/100\n",
      "Epoch 00052: acc improved from 0.92507 to 0.92524, saving model to ../Temp/weights.52-acc=0.9252-val_acc=0.926078125-val_fbeta_pred=0.8265.hdf5\n",
      "127s - loss: 0.1841 - fbeta_pred: 0.8275 - acc: 0.9252 - val_loss: 0.1821 - val_fbeta_pred: 0.8265 - val_acc: 0.9261\n",
      "Epoch 54/100\n",
      "Epoch 00053: acc improved from 0.92524 to 0.92529, saving model to ../Temp/weights.53-acc=0.9253-val_acc=0.9264375-val_fbeta_pred=0.8305.hdf5\n",
      "127s - loss: 0.1841 - fbeta_pred: 0.8279 - acc: 0.9253 - val_loss: 0.1810 - val_fbeta_pred: 0.8305 - val_acc: 0.9264\n",
      "Epoch 55/100\n",
      "Epoch 00054: acc did not improve\n",
      "122s - loss: 0.1839 - fbeta_pred: 0.8279 - acc: 0.9252 - val_loss: 0.1831 - val_fbeta_pred: 0.8220 - val_acc: 0.9254\n",
      "Epoch 56/100\n",
      "Epoch 00055: acc improved from 0.92529 to 0.92544, saving model to ../Temp/weights.55-acc=0.9254-val_acc=0.925890625-val_fbeta_pred=0.8245.hdf5\n",
      "127s - loss: 0.1839 - fbeta_pred: 0.8280 - acc: 0.9254 - val_loss: 0.1819 - val_fbeta_pred: 0.8245 - val_acc: 0.9259\n",
      "Epoch 57/100\n",
      "Epoch 00056: acc did not improve\n",
      "122s - loss: 0.1837 - fbeta_pred: 0.8280 - acc: 0.9254 - val_loss: 0.1811 - val_fbeta_pred: 0.8262 - val_acc: 0.9263\n",
      "Epoch 58/100\n",
      "Epoch 00057: acc did not improve\n",
      "122s - loss: 0.1839 - fbeta_pred: 0.8279 - acc: 0.9253 - val_loss: 0.1818 - val_fbeta_pred: 0.8302 - val_acc: 0.9257\n",
      "Epoch 59/100\n",
      "Epoch 00058: acc did not improve\n",
      "122s - loss: 0.1838 - fbeta_pred: 0.8268 - acc: 0.9250 - val_loss: 0.1811 - val_fbeta_pred: 0.8254 - val_acc: 0.9263\n",
      "Epoch 60/100\n",
      "Epoch 00059: acc improved from 0.92544 to 0.92589, saving model to ../Temp/weights.59-acc=0.9259-val_acc=0.926625-val_fbeta_pred=0.8322.hdf5\n",
      "127s - loss: 0.1832 - fbeta_pred: 0.8296 - acc: 0.9259 - val_loss: 0.1807 - val_fbeta_pred: 0.8322 - val_acc: 0.9266\n",
      "Epoch 61/100\n",
      "Epoch 00060: acc did not improve\n",
      "122s - loss: 0.1831 - fbeta_pred: 0.8278 - acc: 0.9254 - val_loss: 0.1810 - val_fbeta_pred: 0.8282 - val_acc: 0.9260\n",
      "Epoch 62/100\n",
      "Epoch 00061: acc did not improve\n",
      "122s - loss: 0.1827 - fbeta_pred: 0.8284 - acc: 0.9257 - val_loss: 0.1807 - val_fbeta_pred: 0.8273 - val_acc: 0.9261\n",
      "Epoch 63/100\n",
      "Epoch 00062: acc did not improve\n",
      "122s - loss: 0.1828 - fbeta_pred: 0.8285 - acc: 0.9255 - val_loss: 0.1806 - val_fbeta_pred: 0.8282 - val_acc: 0.9267\n",
      "Epoch 64/100\n",
      "Epoch 00063: acc did not improve\n",
      "122s - loss: 0.1825 - fbeta_pred: 0.8289 - acc: 0.9258 - val_loss: 0.1816 - val_fbeta_pred: 0.8299 - val_acc: 0.9259\n",
      "Epoch 65/100\n",
      "Epoch 00064: acc did not improve\n",
      "122s - loss: 0.1822 - fbeta_pred: 0.8292 - acc: 0.9259 - val_loss: 0.1814 - val_fbeta_pred: 0.8252 - val_acc: 0.9261\n",
      "Epoch 66/100\n",
      "Epoch 00065: acc did not improve\n",
      "122s - loss: 0.1824 - fbeta_pred: 0.8293 - acc: 0.9258 - val_loss: 0.1803 - val_fbeta_pred: 0.8276 - val_acc: 0.9267\n",
      "Epoch 67/100\n",
      "Epoch 00066: acc improved from 0.92589 to 0.92622, saving model to ../Temp/weights.66-acc=0.9262-val_acc=0.9264375-val_fbeta_pred=0.8317.hdf5\n",
      "127s - loss: 0.1821 - fbeta_pred: 0.8302 - acc: 0.9262 - val_loss: 0.1803 - val_fbeta_pred: 0.8317 - val_acc: 0.9264\n",
      "Epoch 68/100\n",
      "Epoch 00067: acc did not improve\n",
      "122s - loss: 0.1820 - fbeta_pred: 0.8294 - acc: 0.9259 - val_loss: 0.1804 - val_fbeta_pred: 0.8297 - val_acc: 0.9262\n",
      "Epoch 69/100\n",
      "Epoch 00068: acc improved from 0.92622 to 0.92661, saving model to ../Temp/weights.68-acc=0.9266-val_acc=0.926328125-val_fbeta_pred=0.8318.hdf5\n",
      "127s - loss: 0.1817 - fbeta_pred: 0.8313 - acc: 0.9266 - val_loss: 0.1809 - val_fbeta_pred: 0.8318 - val_acc: 0.9263\n",
      "Epoch 70/100\n",
      "Epoch 00069: acc did not improve\n",
      "122s - loss: 0.1819 - fbeta_pred: 0.8297 - acc: 0.9261 - val_loss: 0.1801 - val_fbeta_pred: 0.8286 - val_acc: 0.9267\n",
      "Epoch 71/100\n",
      "Epoch 00070: acc did not improve\n",
      "122s - loss: 0.1816 - fbeta_pred: 0.8300 - acc: 0.9261 - val_loss: 0.1806 - val_fbeta_pred: 0.8319 - val_acc: 0.9264\n",
      "Epoch 72/100\n",
      "Epoch 00071: acc did not improve\n",
      "122s - loss: 0.1813 - fbeta_pred: 0.8299 - acc: 0.9262 - val_loss: 0.1801 - val_fbeta_pred: 0.8318 - val_acc: 0.9267\n",
      "Epoch 73/100\n",
      "Epoch 00072: acc did not improve\n",
      "122s - loss: 0.1812 - fbeta_pred: 0.8314 - acc: 0.9265 - val_loss: 0.1801 - val_fbeta_pred: 0.8257 - val_acc: 0.9266\n",
      "Epoch 74/100\n",
      "Epoch 00073: acc did not improve\n",
      "122s - loss: 0.1812 - fbeta_pred: 0.8305 - acc: 0.9263 - val_loss: 0.1804 - val_fbeta_pred: 0.8256 - val_acc: 0.9268\n",
      "Epoch 75/100\n",
      "Epoch 00074: acc did not improve\n",
      "122s - loss: 0.1809 - fbeta_pred: 0.8303 - acc: 0.9264 - val_loss: 0.1799 - val_fbeta_pred: 0.8298 - val_acc: 0.9267\n",
      "Epoch 76/100\n",
      "Epoch 00075: acc did not improve\n",
      "122s - loss: 0.1812 - fbeta_pred: 0.8308 - acc: 0.9265 - val_loss: 0.1800 - val_fbeta_pred: 0.8299 - val_acc: 0.9263\n",
      "Epoch 77/100\n",
      "Epoch 00076: acc did not improve\n",
      "122s - loss: 0.1805 - fbeta_pred: 0.8308 - acc: 0.9265 - val_loss: 0.1798 - val_fbeta_pred: 0.8288 - val_acc: 0.9267\n",
      "Epoch 78/100\n",
      "Epoch 00077: acc improved from 0.92661 to 0.92693, saving model to ../Temp/weights.77-acc=0.9269-val_acc=0.926328125-val_fbeta_pred=0.8255.hdf5\n",
      "127s - loss: 0.1805 - fbeta_pred: 0.8324 - acc: 0.9269 - val_loss: 0.1805 - val_fbeta_pred: 0.8255 - val_acc: 0.9263\n",
      "Epoch 79/100\n",
      "Epoch 00078: acc did not improve\n",
      "122s - loss: 0.1802 - fbeta_pred: 0.8307 - acc: 0.9266 - val_loss: 0.1801 - val_fbeta_pred: 0.8302 - val_acc: 0.9262\n",
      "Epoch 80/100\n",
      "Epoch 00079: acc did not improve\n",
      "122s - loss: 0.1798 - fbeta_pred: 0.8319 - acc: 0.9269 - val_loss: 0.1795 - val_fbeta_pred: 0.8277 - val_acc: 0.9268\n",
      "Epoch 81/100\n",
      "Epoch 00080: acc did not improve\n",
      "122s - loss: 0.1797 - fbeta_pred: 0.8317 - acc: 0.9269 - val_loss: 0.1807 - val_fbeta_pred: 0.8268 - val_acc: 0.9262\n",
      "Epoch 82/100\n",
      "Epoch 00081: acc did not improve\n",
      "122s - loss: 0.1798 - fbeta_pred: 0.8318 - acc: 0.9268 - val_loss: 0.1795 - val_fbeta_pred: 0.8304 - val_acc: 0.9272\n",
      "Epoch 83/100\n",
      "Epoch 00082: acc improved from 0.92693 to 0.92698, saving model to ../Temp/weights.82-acc=0.9270-val_acc=0.92675-val_fbeta_pred=0.8283.hdf5\n",
      "127s - loss: 0.1797 - fbeta_pred: 0.8318 - acc: 0.9270 - val_loss: 0.1798 - val_fbeta_pred: 0.8283 - val_acc: 0.9267\n",
      "Epoch 84/100\n",
      "Epoch 00083: acc improved from 0.92698 to 0.92718, saving model to ../Temp/weights.83-acc=0.9272-val_acc=0.926921875-val_fbeta_pred=0.8279.hdf5\n",
      "127s - loss: 0.1797 - fbeta_pred: 0.8325 - acc: 0.9272 - val_loss: 0.1798 - val_fbeta_pred: 0.8279 - val_acc: 0.9269\n",
      "Epoch 85/100\n",
      "Epoch 00084: acc improved from 0.92718 to 0.92727, saving model to ../Temp/weights.84-acc=0.9273-val_acc=0.927109375-val_fbeta_pred=0.8304.hdf5\n",
      "127s - loss: 0.1795 - fbeta_pred: 0.8327 - acc: 0.9273 - val_loss: 0.1792 - val_fbeta_pred: 0.8304 - val_acc: 0.9271\n",
      "Epoch 86/100\n",
      "Epoch 00085: acc did not improve\n",
      "122s - loss: 0.1791 - fbeta_pred: 0.8325 - acc: 0.9272 - val_loss: 0.1794 - val_fbeta_pred: 0.8334 - val_acc: 0.9270\n",
      "Epoch 87/100\n",
      "Epoch 00086: acc improved from 0.92727 to 0.92741, saving model to ../Temp/weights.86-acc=0.9274-val_acc=0.926890625-val_fbeta_pred=0.8272.hdf5\n",
      "127s - loss: 0.1790 - fbeta_pred: 0.8329 - acc: 0.9274 - val_loss: 0.1794 - val_fbeta_pred: 0.8272 - val_acc: 0.9269\n",
      "Epoch 88/100\n",
      "Epoch 00087: acc did not improve\n",
      "122s - loss: 0.1787 - fbeta_pred: 0.8331 - acc: 0.9273 - val_loss: 0.1790 - val_fbeta_pred: 0.8309 - val_acc: 0.9272\n",
      "Epoch 89/100\n",
      "Epoch 00088: acc did not improve\n",
      "122s - loss: 0.1788 - fbeta_pred: 0.8330 - acc: 0.9274 - val_loss: 0.1791 - val_fbeta_pred: 0.8319 - val_acc: 0.9273\n",
      "Epoch 90/100\n",
      "Epoch 00089: acc did not improve\n",
      "122s - loss: 0.1788 - fbeta_pred: 0.8327 - acc: 0.9273 - val_loss: 0.1798 - val_fbeta_pred: 0.8301 - val_acc: 0.9267\n",
      "Epoch 91/100\n",
      "Epoch 00090: acc improved from 0.92741 to 0.92765, saving model to ../Temp/weights.90-acc=0.9276-val_acc=0.927109375-val_fbeta_pred=0.8274.hdf5\n",
      "127s - loss: 0.1786 - fbeta_pred: 0.8336 - acc: 0.9276 - val_loss: 0.1791 - val_fbeta_pred: 0.8274 - val_acc: 0.9271\n",
      "Epoch 92/100\n",
      "Epoch 00091: acc did not improve\n",
      "122s - loss: 0.1785 - fbeta_pred: 0.8334 - acc: 0.9275 - val_loss: 0.1793 - val_fbeta_pred: 0.8254 - val_acc: 0.9268\n",
      "Epoch 93/100\n",
      "Epoch 00092: acc improved from 0.92765 to 0.92777, saving model to ../Temp/weights.92-acc=0.9278-val_acc=0.927078125-val_fbeta_pred=0.8323.hdf5\n",
      "127s - loss: 0.1779 - fbeta_pred: 0.8339 - acc: 0.9278 - val_loss: 0.1791 - val_fbeta_pred: 0.8323 - val_acc: 0.9271\n",
      "Epoch 94/100\n",
      "Epoch 00093: acc did not improve\n",
      "122s - loss: 0.1779 - fbeta_pred: 0.8337 - acc: 0.9277 - val_loss: 0.1789 - val_fbeta_pred: 0.8270 - val_acc: 0.9267\n",
      "Epoch 95/100\n",
      "Epoch 00094: acc did not improve\n",
      "122s - loss: 0.1778 - fbeta_pred: 0.8339 - acc: 0.9277 - val_loss: 0.1799 - val_fbeta_pred: 0.8258 - val_acc: 0.9269\n",
      "Epoch 96/100\n",
      "Epoch 00095: acc improved from 0.92777 to 0.92809, saving model to ../Temp/weights.95-acc=0.9281-val_acc=0.926953125-val_fbeta_pred=0.8303.hdf5\n",
      "127s - loss: 0.1775 - fbeta_pred: 0.8349 - acc: 0.9281 - val_loss: 0.1792 - val_fbeta_pred: 0.8303 - val_acc: 0.9270\n",
      "Epoch 97/100\n",
      "Epoch 00096: acc improved from 0.92809 to 0.92810, saving model to ../Temp/weights.96-acc=0.9281-val_acc=0.926609375-val_fbeta_pred=0.8240.hdf5\n",
      "127s - loss: 0.1771 - fbeta_pred: 0.8348 - acc: 0.9281 - val_loss: 0.1799 - val_fbeta_pred: 0.8240 - val_acc: 0.9266\n",
      "Epoch 98/100\n",
      "Epoch 00097: acc improved from 0.92810 to 0.92820, saving model to ../Temp/weights.97-acc=0.9282-val_acc=0.926484375-val_fbeta_pred=0.8247.hdf5\n",
      "127s - loss: 0.1771 - fbeta_pred: 0.8352 - acc: 0.9282 - val_loss: 0.1800 - val_fbeta_pred: 0.8247 - val_acc: 0.9265\n",
      "Epoch 99/100\n",
      "Epoch 00098: acc did not improve\n",
      "122s - loss: 0.1771 - fbeta_pred: 0.8348 - acc: 0.9281 - val_loss: 0.1787 - val_fbeta_pred: 0.8304 - val_acc: 0.9272\n",
      "Epoch 100/100\n",
      "Epoch 00099: acc improved from 0.92820 to 0.92836, saving model to ../Temp/weights.99-acc=0.9284-val_acc=0.927203125-val_fbeta_pred=0.8275.hdf5\n",
      "127s - loss: 0.1768 - fbeta_pred: 0.8356 - acc: 0.9284 - val_loss: 0.1789 - val_fbeta_pred: 0.8275 - val_acc: 0.9272\n",
      "2017-07-05 16:18:39.663612\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.0001)\n",
    "\n",
    "epochs     = 100\n",
    "verbose    = 2\n",
    "batch_size = 64\n",
    "\n",
    "filepath=\"../Temp/weights.{epoch:02d}-acc={\"+metric+\":.4f}-val_acc={val_\"+metric+\"}-val_fbeta_pred={val_fbeta_pred:.4f}.hdf5\"\n",
    "##checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=metric, verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "##model1 = buildModel(iSize,rSize,pp)\n",
    "tr1    = np.sum([K.count_params(p) for p in set(model10.trainable_weights)])\n",
    "tr2    = np.sum([K.count_params(p) for p in set(model10.non_trainable_weights)])\n",
    "\n",
    "#print(tr1,tr2,tr1+tr2)\n",
    "#assert ((tr1+tr2)>14000000)\n",
    "\n",
    "step = 20000\n",
    "low  = 0\n",
    "high = low+step\n",
    "\n",
    "print(datetime.datetime.now(),tr1+tr2)\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.20, \n",
    "                    callbacks=[early_stopping,reduce_lr,checkpoint],\n",
    "                    verbose=verbose)\n",
    "\n",
    "##trP = model1.predict(trX, batch_size=128)\n",
    "##fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "##fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "print(datetime.datetime.now()) #,pp,'fbeta2s=',fbeta2score,fbeta2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38390, 128, 128, 3), (38390, 16))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape, trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 4.86 s, total: 27.8 s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%time trP = model10.predict(trX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17867290067560943, 0.82775896028728346, 0.92750879134570408]\n",
      "(38390, 16)\n",
      "(38390, 16)\n",
      "fbeta_score= 0.849337750226\n",
      "fbeta_pred = 0.827171777087\n"
     ]
    }
   ],
   "source": [
    "print(model10.evaluate(trX,trY,verbose=2))\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resAll = resAll+result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True : #False :\n",
    "    save_model(model10,'../Data-Keras/Models/model-Alex-128x128x3.h5')\n",
    "    model10.save_weights('../Data-Keras/Models/model-Alex-weights-128x128x3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 96)        34944     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 22, 22, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              104861696 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                65552     \n",
      "=================================================================\n",
      "Total params: 125,455,772\n",
      "Trainable params: 125,455,766\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20 05:22:01.009723 0 --> 70 0.758419290079 [0.75741733368803943, 0.75841929007857778, 0.75785138394714635]\n",
      "2017-05-20 05:22:23.972821 1 --> 78 0.982638483662 [0.98262473453994426, 0.98263848366246676, 0.98259679666709321]\n",
      "2017-05-20 05:22:52.632376 2 --> 58 0.847226297632 [0.8469111862002846, 0.84722629763157453, 0.84682213028656683]\n",
      "2017-05-20 05:23:27.033547 3 --> 78 0.97604678248 [0.97585536488705449, 0.97604678247993626, 0.97586138532621902]\n",
      "2017-05-20 05:24:07.288213 4 --> 39 0.78729476795 [0.78664609854346335, 0.78729476795032916, 0.78707371492899492]\n",
      "2017-05-20 05:24:52.980975 5 --> 42 0.789568102568 [0.78871126051941221, 0.78956810256787635, 0.78669767415698355]\n",
      "2017-05-20 05:25:44.022237 6 --> 47 0.830831644043 [0.8305167161398419, 0.83083164404299403, 0.83015444819651052]\n",
      "2017-05-20 05:26:40.712293 7 --> 45 0.738016164169 [0.73686966073098015, 0.73801616416924898, 0.73773213859960107]\n",
      "2017-05-20 05:27:43.679293 8 --> 26 0.676190170231 [0.6690774577597115, 0.6761901702314258, 0.65439641541326066]\n",
      "2017-05-20 05:28:52.203737 9 --> 99 0.860687873635 [0.84540789671187133, 0.86068787363532673]\n",
      "2017-05-20 05:30:06.360727 10 --> 53 0.964034283738 [0.96339687009527564, 0.96403428373772715, 0.96364205060652686]\n",
      "2017-05-20 05:31:26.352144 11 --> 30 0.900537376612 [0.89285689393748568, 0.90053737661152566, 0.90053737661152566]\n",
      "2017-05-20 05:32:51.552201 12 --> 27 0.652844152686 [0.64595635259618922, 0.6528441526860862, 0.65053736636295179]\n",
      "2017-05-20 05:34:22.405562 13 --> 24 0.863599425241 [0.86179482608466784, 0.86359942524081812, 0.85725979475579062]\n",
      "2017-05-20 05:35:59.177670 14 --> 14 0.370370055203 [0.3600540358709392, 0.37037005520335736, 0.35595995253798635]\n",
      "2017-05-20 05:37:41.803909 15 --> 22 0.683823292523 [0.67335220282476826, 0.68382329252278806, 0.67567543551442677]\n",
      "2017-05-20 05:39:29.432537 16 --> 14 0.589171696773 [0.56748439106677917, 0.58917169677281178, 0.5851060891681884]\n"
     ]
    }
   ],
   "source": [
    "rr, rrx = [], []; trP = model.predict(trX, batch_size=128)\n",
    "for i in range(trP.shape[1]) :\n",
    "    xx = [];\n",
    "    trYY = trY[:,i].astype(np.float64)\n",
    "    trPY = trP[:,i]\n",
    "    for ii in range(100) :\n",
    "        trPP = (trPY>0.01*ii).astype(np.float64)\n",
    "        #x = fbeta_score(trY[:,0], np.array(trP[:,0] > 0.1*ii), beta=2, average='samples')\n",
    "        x = K.get_value(fbeta_pred(trYY,trPP))\n",
    "        xx.append(x)\n",
    "    rrr = np.array(xx).argmax();\n",
    "    rr.append(rrr)\n",
    "    rrx.append(xx[rrr])\n",
    "    print(datetime.datetime.now(),i,'-->',rrr,xx[rrr],xx[(rrr-1):(rrr+2)])\n",
    "    #print(xx);\n",
    "    #plt.plot(np.array(xx)); plt.show()\n",
    "trM = np.array(rr)/100.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191\n",
      "2017-05-20 05:46:19.287685 61191 61191\n",
      "2017-05-20 05:46:38.218814 \t 0 \t 5000 \t test_14523.jpg \t \n",
      "2017-05-20 05:46:51.023731 \t 1 \t 10000 \t test_19029.jpg \t (10000, 17)\n",
      "2017-05-20 05:46:58.884016 \t 1 \t 15000 \t test_23524.jpg \t (10000, 17)\n",
      "2017-05-20 05:47:09.507695 \t 2 \t 20000 \t test_28015.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:16.475888 \t 2 \t 25000 \t test_32520.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:26.837760 \t 3 \t 30000 \t test_37026.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:33.858034 \t 3 \t 35000 \t test_4908.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:44.019579 \t 4 \t 40000 \t test_9402.jpg \t (40000, 17)\n",
      "2017-05-20 05:47:51.298769 \t 4 \t 45000 \t file_13913.jpg \t (40000, 17)\n",
      "2017-05-20 05:48:01.555641 \t 5 \t 50000 \t file_18419.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:24.538867 \t 5 \t 55000 \t file_4564.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:40.785101 \t 6 \t 60000 \t file_892.jpg \t (60000, 17)\n",
      "2017-05-20 05:48:43.863555\n"
     ]
    }
   ],
   "source": [
    "#nameAsk = os.listdir(teDirI); print(len(nameAsk))\n",
    "nameAsk = os.listdir(teDirJPG); print(len(nameAsk))\n",
    "trOX, trOY, i, ii, size = [], [], 0, 0, len(nameAsk)\n",
    "print(datetime.datetime.now(),len(nameAsk),size)\n",
    "for nn in nameAsk[0:size] :\n",
    "    #nf = os.path.join(teDirTIF,nn);\n",
    "    nf = os.path.join(teDirJPG,nn);\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        trOX.append(nx)\n",
    "        trOY.append(nn)\n",
    "    i += 1\n",
    "    if (i%10000==0) and (i>1) :\n",
    "        if (ii==0) :\n",
    "            trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "            trP = model.predict(trOX, batch_size=512); \n",
    "        else :\n",
    "            trOX = np.array(trOX);  trOX = trOX / 255.0\n",
    "            trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "        trOX,ii = [],ii+1;\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",ii,'\\t',i,\"\\t\",nn,'\\t',(trP.shape if ii>0 else \"\"))\n",
    "\n",
    "if (len(trOX)>0) :\n",
    "    if (ii==0) :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = model.predict(trOX, batch_size=512); \n",
    "    else :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "    trOX,ii = [],ii+1;\n",
    "    \n",
    "print(datetime.datetime.now())\n",
    "\n",
    "#assert (size!=len(trOY)), \"Wrong files {} != {}\".format(size,len(trOY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191 (61191, 17) (61191,)\n"
     ]
    }
   ],
   "source": [
    "#trOX = np.array(trOX);\n",
    "trOY = np.array([os.path.splitext(x)[0] for x in trOY]);\n",
    "print(len(nameAsk),trP.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy',trOX)\n",
    "np.save('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 32, 32, 6) (61191,)\n"
     ]
    }
   ],
   "source": [
    "trOX = np.load('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy')\n",
    "trOY = np.load('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy')\n",
    "print(trOX.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.75841929007857778,\n",
       " 1: 0.98263848366246676,\n",
       " 2: 0.84722629763157453,\n",
       " 3: 0.97604678247993626,\n",
       " 4: 0.78729476795032916,\n",
       " 5: 0.78956810256787635,\n",
       " 6: 0.83083164404299403,\n",
       " 7: 0.73801616416924898,\n",
       " 8: 0.6761901702314258,\n",
       " 9: 0.86068787363532673,\n",
       " 10: 0.96403428373772715,\n",
       " 11: 0.90053737661152566,\n",
       " 12: 0.6528441526860862,\n",
       " 13: 0.86359942524081812,\n",
       " 14: 0.37037005520335736,\n",
       " 15: 0.68382329252278806,\n",
       " 16: 0.58917169677281178}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrx\n",
    "rrd=dict()\n",
    "for i in range(len(rrx)) :\n",
    "    rrd[i]=rrx[i]\n",
    "rrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Forming result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61191, 17), array([  6.56801313e-02,   7.46541142e-01,   2.32726157e-01,\n",
       "          9.55386758e-01,   1.95543230e-01,   9.11955476e-01,\n",
       "          8.89197826e-01,   2.53069662e-02,   1.54045611e-05,\n",
       "          7.43342913e-04,   6.54759035e-02,   6.17289741e-04,\n",
       "          8.51887614e-02,   2.95602629e-04,   2.64362683e-07,\n",
       "          1.03749386e-04,   2.92145728e-07], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trP = model.predict(trOX, batch_size=512); \n",
    "trP.shape, trP[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "[3, 10, 0, 9] \n",
      " ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down'] \n",
      " [2.0, 0.5, 0.5, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "trM=np.array([0.0]*len(labels)); print(trM.shape)\n",
    "wr = [labels.index(i) for i in weather_labels];\n",
    "tt=trM; trM[:]=0.5\n",
    "trM[np.array(wr)] = 2.0\n",
    "print(wr,'\\n',labels,'\\n',trM.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'clear primary'] \n",
      " ['file_20521', 'clear primary'] \n",
      " [ 2.   0.5  0.5  2.   0.5  0.5  0.5  0.5  0.5  2.   2.   0.5  0.5  0.5  0.5\n",
      "  0.5  0.5] [  1.63650557e-01   3.91220033e-01   1.36160061e-01   9.47374701e-01\n",
      "   9.09343541e-01   1.55211976e-02   3.13203782e-02   1.42206885e-02\n",
      "   8.06170846e-08   9.10553038e-01   7.85041321e-03   4.12757437e-08\n",
      "   6.71853591e-03   1.33155788e-06   7.46736941e-06   9.65268737e-06\n",
      "   7.95199711e-08]\n"
     ]
    }
   ],
   "source": [
    "#trP = model.predict(trX, batch_size=512); trP=K.get_value(trP)\n",
    "res = []\n",
    "\n",
    "for i in range(trP.shape[0]) :\n",
    "    trPP = [weather_labels[trP[i,wr].argmax()]] + [labels[ii] for ii in range(len(labels)) if (trP[i,ii]>trM[ii])];\n",
    "    pp   = ' '.join(trPP)\n",
    "    ##if (pp==\"\") : print(trY[i])\n",
    "    res.append([trOY[i],pp])\n",
    "\n",
    "res.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n",
    "#print(res[4:8],'\\n',res[-4:])\n",
    "print(res[0],'\\n',res[-1],'\\n',trM,trP[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "#print(trM.tolist())\n",
    "#np.round(trP[4:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20-05-51-18\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(res,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
