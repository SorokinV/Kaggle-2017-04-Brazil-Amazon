{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## AlexNet analog (Krizhevsky 2012)\n",
    "##\n",
    "## maximum on LB => 0.84500\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import formFH, paths_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Data/test-jpg-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, teDirJPG, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def formImExt (nf, resize=(32,32), printOK=False) :\n",
    "    nx = None\n",
    "    try : \n",
    "        ni = cv.imread(nf,-1); \n",
    "        if (ni is not None) :\n",
    "            #ni = cv.normalize\n",
    "            if not ((ni.shape[2]==3) or (ni.shape[2]==4)) and printOK : print('----- error ---- shape:',ni.shape,nf)\n",
    "            if (ni.shape[2]==3) :\n",
    "                nx = cv.resize(ni,resize)\n",
    "            if (ni.shape[2]==4) :\n",
    "                #r,g,b,n = ni[:,:,2],ni[:,:,1],ni[:,:,0],ni[:,:,3]\n",
    "                r,g,b,n = cv.resize(ni[:,:,2],resize),cv.resize(ni[:,:,1],resize),cv.resize(ni[:,:,0],resize),cv.resize(ni[:,:,3],resize)\n",
    "                dv,dw   = np.divide((r-n),(r+n+0.01)), np.divide((g-n),(g+n+0.01))\n",
    "                nx      = np.array([r,g,b,n,dv,dw]).T; \n",
    "    except BaseException as e :\n",
    "        print(nf,e); nx = None;\n",
    "    \n",
    "    if nx is None and printOK : \n",
    "        print('------ None:',nf); nx = None\n",
    "        \n",
    "    return(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-18 16:09:51.030338 40479 40479\n",
      "2017-05-18 16:12:30.271675 \t 5000 \t train_4999\n",
      "2017-05-18 16:14:32.662155 \t 10000 \t train_9999\n",
      "2017-05-18 16:16:21.170086 \t 15000 \t train_14999\n",
      "2017-05-18 16:17:57.485082 \t 20000 \t train_19999\n",
      "2017-05-18 16:19:17.573212 \t 25000 \t train_24999\n",
      "2017-05-18 16:20:26.649529 \t 30000 \t train_29999\n",
      "2017-05-18 16:21:34.931734 \t 35000 \t train_34999\n",
      "2017-05-18 16:22:38.544159 \t 40000 \t train_39999\n",
      "2017-05-18 16:22:44.600525\n",
      "40479 (40479, 64, 64, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "trX, trY, i, size = [],[], 0, len(nameList)\n",
    "print(datetime.datetime.now(),len(nameList),size)\n",
    "for nn in nameList[0:size] :\n",
    "    #nf = os.path.join(trDirTIF,nn+\".tif\");\n",
    "    nf = os.path.join(trDirJPG,nn+\".jpg\");\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        #rr=np.save(os.path.join(trWork,nn+\".npy\"),nx);\n",
    "        #trX.append(nn+\".npy\")\n",
    "        trX.append(nx)\n",
    "        trY.append(True)\n",
    "    else : \n",
    "        trY.append(False)\n",
    "    i += 1\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",i,\"\\t\",nn)\n",
    "    #print(nn.shape)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "trX = np.array(trX);\n",
    "trY = labelList[trY];\n",
    "print(len(nameList),trX.shape,trY.shape)\n",
    "#trXY=pd.DataFrame(trY); trXY['name']=trX; trXY.head()\n",
    "#trXY.to_pickle(os.path.join(trWork,\"listFiles.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "######np.save('../Data-Keras/Datas/train-model-2D-64x64x6-XX.npy',trX)\n",
    "######np.save('../Data-Keras/Datas/train-model-2D-64x64x6-YY.npy',trY)\n",
    "###np.save('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy',trX)\n",
    "###np.save('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12048, 128, 128, 3) (12048, 16)\n"
     ]
    }
   ],
   "source": [
    "###trXX = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-XX.npy')\n",
    "###trYY = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-YY.npy')\n",
    "######trXX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "######trYY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "trXX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "trYY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "trX, trY = trXX[trYY[:,3]==0], trYY[trYY[:,3]==0] # not cloudy\n",
    "trY=trY[:,[0,1,2]+range(4,17)] # --cloudy\n",
    "del trXX,trYY\n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#trX=trX/255.0\n",
    "##trX = cv.normalize(trX, trX, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "#trX=trX/65535.0\n",
    "#trX[0,:,:]\n",
    "#trX[:,:,:,5].max(),trX.min(),trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fbeta_pred(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "#\n",
    "def Kriz2012 ( model, iSize, rSize ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    model.add(Convolution2D(96,(11,11),strides=(4,4),activation='relu'))\n",
    "    model.add(Convolution2D(256,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(256,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "# cut version\n",
    "#\n",
    "#\n",
    "def Kriz2012x3x3 ( model, iSize, rSize, cv2d, dense, pp ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(axis=3,input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    if not (cv2d is None) :\n",
    "        for cv in cv2d :\n",
    "            if (cv>0) :\n",
    "                model.add(Convolution2D(cv,(2,2)))\n",
    "                #model.add(BatchNormalization(axis=3))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if not (dense is None) :\n",
    "        for de in dense :\n",
    "            if (de>0) :\n",
    "                model.add(Dense(pp[5],activation='relu'))\n",
    "                model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildModel (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    if (cv2d is None) and (dense is None) and not (params is None) : cv2d, dense = params[:-2], params[-2:]\n",
    "    model = Kriz2012x3x3(model,iSize,rSize,cv2d=cv2d,dense=dense,pp=params)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "def buildModelKriz (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    \n",
    "    model = Kriz2012(model,iSize,rSize)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#mm1=np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "#mm2=np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "#mm1,mm2,mm1+mm2\n",
    "#len(result),len(resAll)\n",
    "#trX.shape,trX.dtype,trX[0]\n",
    "#trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resAll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3) 16\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=12,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "params = [(32,64,32,0,0,256,0),(32,64,16,0,0,256,0),(32,64,32,0,0,256,0),(32,64,64,0,0,256,0),(32,64,128,0,0,256,0),(32,64,256,0,0,256,0),(32,64,512,0,0,256,0),(32,64,1024,0,0,256,0)]\n",
    "params = params+[(32,64,8,0,0,16,0),(32,64,16,0,0,256,0),(32,64,32,0,0,64,0),(32,64,64,0,0,128,0),(32,64,128,0,0,256,0),(32,64,256,0,0,512,0),(32,64,512,0,0,1024,0),(32,64,1024,0,0,2048,0)]\n",
    "params = params+[(32,64,8,0,0,16,128),(32,64,16,0,0,32,128),(32,64,32,0,0,64,128),(32,64,64,0,0,128,128),(32,64,128,0,0,256,128),(32,64,256,0,0,512,128),(32,64,512,0,0,1024,128),(32,64,1024,0,0,2048,128)]\n",
    "params = params+[(96,256,384,384,256,4096,4096),(96,256,384,384,256,4096,2048),(96,256,384,384,256,2048,4096),(96,256,384,384,256,2048,2048),\n",
    "          (96,256,384,384,0,4096,0),(96,256,384,0,256,4096,0),(96,256,0,0,256,4096,0),\n",
    "          (96,256,0,0,0,4096,0),(96,0,0,0,0,4096,0),(96,256,0,0,256,4096,0)]\n",
    "#         (96,256,384,197,256,4096,0),  bad unchausted memory ResourceExhaustedError: OOM when allocating tensor with shape[128,8,8,384]\n",
    "#         (96,128,0,0,0,4096,0),\n",
    "#\n",
    "#        [(96,256,197,0,0,4096,0), (96,256,384,384,256,4096,0)]\n",
    "#\n",
    "#       [(96,32,0,0,0,1024,0),(96,64,0,0,0,1024,0),(96,128,0,0,0,1024,0),(96,256,0,0,0,1024,0),\n",
    "#         (256,32,0,0,0,1024,0),(256,64,0,0,0,1024,0),(256,128,0,0,0,1024,0)]\n",
    "\n",
    "params = [(96,64,0,0,0,256,0),(96,64,0,0,0,512,0),(96,64,0,0,0,1024,0),(96,64,0,0,0,2048,0),(96,64,0,0,0,8192,0)]\n",
    "params = params+[(16,64,0,0,0,256,0),(32,64,0,0,0,256,0),(64,64,0,0,0,256,0),(128,64,0,0,0,256,0),(256,64,0,0,0,256,0)]\n",
    "\n",
    "params = [(32,64,16,0,0,256,0)] \n",
    "params = [(16,32,64,256,0,512,512),(8,64,256,1024,0,512,512),(8,64,256,1024,0,0,512),(8,64,256,2048,0,0,512),(8,64,256,2048,0,512,512),\n",
    "          (8,64,256,2048,0,1024,0),(8,64,256,2048,0,1024,1024)]\n",
    "##params = [(8,64,256,1024,0,512,512),(8,64,256,1024,0,512,0)]\n",
    "params = [(8,64,256,2048,0,2048,0)] # 0.87 0.87\n",
    "params = [(8,64,256,4096,0,1024,0)] # 0.8686 0.8724\n",
    "params = [(32,64,16,0,0,256,512),(8,64,256,2048,0,1024,0),(8,64,256,2048,0,512,0),(8,64,256,4096,0,256,0)] # 0.875 0.8796\n",
    "params = [(32,64,16,0,0,256,512)]\n",
    "\n",
    "#params = [(8,64,256,4096,0,256,0)]\n",
    "\n",
    "iSize, rSize, result = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], []\n",
    "print(iSize,rSize)\n",
    "epochs  = 100\n",
    "verbose = 2\n",
    "batch_size = 64 # 64 0.8633 0.8717 (68 secs/batch) # 32 0.8545 0.8653 (87 secs/batch) # 16 0.8483 0.8623 (137 secs/batch) # 32\n",
    "for pp in [] : #params :\n",
    "    filepath=\"../Data-Keras/weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    model1 = buildModel(iSize,rSize,pp)\n",
    "    tr1=np.sum([K.count_params(p) for p in set(model1.trainable_weights)])\n",
    "    tr2=np.sum([K.count_params(p) for p in set(model1.non_trainable_weights)])\n",
    "    if (tr1+tr2)>14000000 : \n",
    "        print(datetime.datetime.now(),pp,tr1+tr2,'(badly)')\n",
    "        continue;\n",
    "    print(datetime.datetime.now(),pp,tr1+tr2)\n",
    "    hist1  = model1.fit(trX,trY,epochs=epochs, batch_size=batch_size, validation_split=0.20, \n",
    "                        callbacks=[early_stopping,reduce_lr,checkpoint],\n",
    "                        verbose=verbose)\n",
    "    \n",
    "    trP = model1.predict(trX, batch_size=128)\n",
    "    fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "    fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "    #print(datetime.datetime.now(),pp,hist1.history['fbeta_pred'][-1],hist1.history['val_fbeta_pred'][-1],'fbeta2s=',fbeta2score,fbeta2pred)\n",
    "    print(datetime.datetime.now(),pp,'fbeta2s=',fbeta2score,fbeta2pred)\n",
    "    result.append([pp,hist1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) 16\n"
     ]
    }
   ],
   "source": [
    "iSize, rSize, result = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], []\n",
    "params = (32,64,128,256,0,256,512)\n",
    "print(iSize,rSize)\n",
    "metric = 'acc'\n",
    "model10 = buildModelKriz(iSize,rSize,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 06:49:32.250324 125455772\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: acc improved from -inf to 0.58337, saving model to ../Temp/weights.00-acc=0.5945.hdf5\n",
      "84s - loss: 0.1127 - fbeta_pred: 0.6631 - acc: 0.5834 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 2/100\n",
      "Epoch 00001: acc improved from 0.58337 to 0.59150, saving model to ../Temp/weights.01-acc=0.5945.hdf5\n",
      "72s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 3/100\n",
      "Epoch 00002: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 4/100\n",
      "Epoch 00003: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 5/100\n",
      "Epoch 00004: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6706 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 6/100\n",
      "Epoch 00005: acc did not improve\n",
      "63s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 7/100\n",
      "Epoch 00006: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 8/100\n",
      "Epoch 00007: acc did not improve\n",
      "63s - loss: 0.1066 - fbeta_pred: 0.6706 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 9/100\n",
      "Epoch 00008: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 10/100\n",
      "Epoch 00009: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 11/100\n",
      "Epoch 00010: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6706 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "Epoch 12/100\n",
      "Epoch 00011: acc did not improve\n",
      "62s - loss: 0.1066 - fbeta_pred: 0.6707 - acc: 0.5915 - val_loss: 0.1051 - val_fbeta_pred: 0.6726 - val_acc: 0.5945\n",
      "2017-07-05 07:02:36.669922\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "epochs     = 100\n",
    "verbose    = 2\n",
    "batch_size = 128 \n",
    "\n",
    "filepath=\"../Temp/weights.{epoch:02d}-acc={val_\"+metric+\":.4f}.hdf5\"\n",
    "##checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=metric, verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "##model1 = buildModel(iSize,rSize,pp)\n",
    "tr1    = np.sum([K.count_params(p) for p in set(model10.trainable_weights)])\n",
    "tr2    = np.sum([K.count_params(p) for p in set(model10.non_trainable_weights)])\n",
    "\n",
    "#print(tr1,tr2,tr1+tr2)\n",
    "#assert ((tr1+tr2)>14000000)\n",
    "\n",
    "step = 10000\n",
    "low  = 0\n",
    "high = low+step\n",
    "\n",
    "print(datetime.datetime.now(),tr1+tr2)\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.20, \n",
    "                    callbacks=[early_stopping,reduce_lr,checkpoint],\n",
    "                    verbose=verbose)\n",
    "\n",
    "##trP = model1.predict(trX, batch_size=128)\n",
    "##fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "##fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "print(datetime.datetime.now()) #,pp,'fbeta2s=',fbeta2score,fbeta2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trP = model10.predict(trX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09179318143156262, 0.74588026341847369, 0.59553452855245681]\n",
      "(12048, 16)\n",
      "(12048, 16)\n",
      "fbeta_score= 0.572584122385\n",
      "fbeta_pred = 0.673862288804\n"
     ]
    }
   ],
   "source": [
    "print(model1.evaluate(trX,trY,verbose=2))\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resAll = resAll+result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    save_model(model10,'../Data-Keras/Models/model-Alex.h5')\n",
    "    model10.save_weights('../Data-Keras/Models/model-Alex-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20 05:22:01.009723 0 --> 70 0.758419290079 [0.75741733368803943, 0.75841929007857778, 0.75785138394714635]\n",
      "2017-05-20 05:22:23.972821 1 --> 78 0.982638483662 [0.98262473453994426, 0.98263848366246676, 0.98259679666709321]\n",
      "2017-05-20 05:22:52.632376 2 --> 58 0.847226297632 [0.8469111862002846, 0.84722629763157453, 0.84682213028656683]\n",
      "2017-05-20 05:23:27.033547 3 --> 78 0.97604678248 [0.97585536488705449, 0.97604678247993626, 0.97586138532621902]\n",
      "2017-05-20 05:24:07.288213 4 --> 39 0.78729476795 [0.78664609854346335, 0.78729476795032916, 0.78707371492899492]\n",
      "2017-05-20 05:24:52.980975 5 --> 42 0.789568102568 [0.78871126051941221, 0.78956810256787635, 0.78669767415698355]\n",
      "2017-05-20 05:25:44.022237 6 --> 47 0.830831644043 [0.8305167161398419, 0.83083164404299403, 0.83015444819651052]\n",
      "2017-05-20 05:26:40.712293 7 --> 45 0.738016164169 [0.73686966073098015, 0.73801616416924898, 0.73773213859960107]\n",
      "2017-05-20 05:27:43.679293 8 --> 26 0.676190170231 [0.6690774577597115, 0.6761901702314258, 0.65439641541326066]\n",
      "2017-05-20 05:28:52.203737 9 --> 99 0.860687873635 [0.84540789671187133, 0.86068787363532673]\n",
      "2017-05-20 05:30:06.360727 10 --> 53 0.964034283738 [0.96339687009527564, 0.96403428373772715, 0.96364205060652686]\n",
      "2017-05-20 05:31:26.352144 11 --> 30 0.900537376612 [0.89285689393748568, 0.90053737661152566, 0.90053737661152566]\n",
      "2017-05-20 05:32:51.552201 12 --> 27 0.652844152686 [0.64595635259618922, 0.6528441526860862, 0.65053736636295179]\n",
      "2017-05-20 05:34:22.405562 13 --> 24 0.863599425241 [0.86179482608466784, 0.86359942524081812, 0.85725979475579062]\n",
      "2017-05-20 05:35:59.177670 14 --> 14 0.370370055203 [0.3600540358709392, 0.37037005520335736, 0.35595995253798635]\n",
      "2017-05-20 05:37:41.803909 15 --> 22 0.683823292523 [0.67335220282476826, 0.68382329252278806, 0.67567543551442677]\n",
      "2017-05-20 05:39:29.432537 16 --> 14 0.589171696773 [0.56748439106677917, 0.58917169677281178, 0.5851060891681884]\n"
     ]
    }
   ],
   "source": [
    "rr, rrx = [], []; trP = model.predict(trX, batch_size=128)\n",
    "for i in range(trP.shape[1]) :\n",
    "    xx = [];\n",
    "    trYY = trY[:,i].astype(np.float64)\n",
    "    trPY = trP[:,i]\n",
    "    for ii in range(100) :\n",
    "        trPP = (trPY>0.01*ii).astype(np.float64)\n",
    "        #x = fbeta_score(trY[:,0], np.array(trP[:,0] > 0.1*ii), beta=2, average='samples')\n",
    "        x = K.get_value(fbeta_pred(trYY,trPP))\n",
    "        xx.append(x)\n",
    "    rrr = np.array(xx).argmax();\n",
    "    rr.append(rrr)\n",
    "    rrx.append(xx[rrr])\n",
    "    print(datetime.datetime.now(),i,'-->',rrr,xx[rrr],xx[(rrr-1):(rrr+2)])\n",
    "    #print(xx);\n",
    "    #plt.plot(np.array(xx)); plt.show()\n",
    "trM = np.array(rr)/100.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191\n",
      "2017-05-20 05:46:19.287685 61191 61191\n",
      "2017-05-20 05:46:38.218814 \t 0 \t 5000 \t test_14523.jpg \t \n",
      "2017-05-20 05:46:51.023731 \t 1 \t 10000 \t test_19029.jpg \t (10000, 17)\n",
      "2017-05-20 05:46:58.884016 \t 1 \t 15000 \t test_23524.jpg \t (10000, 17)\n",
      "2017-05-20 05:47:09.507695 \t 2 \t 20000 \t test_28015.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:16.475888 \t 2 \t 25000 \t test_32520.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:26.837760 \t 3 \t 30000 \t test_37026.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:33.858034 \t 3 \t 35000 \t test_4908.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:44.019579 \t 4 \t 40000 \t test_9402.jpg \t (40000, 17)\n",
      "2017-05-20 05:47:51.298769 \t 4 \t 45000 \t file_13913.jpg \t (40000, 17)\n",
      "2017-05-20 05:48:01.555641 \t 5 \t 50000 \t file_18419.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:24.538867 \t 5 \t 55000 \t file_4564.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:40.785101 \t 6 \t 60000 \t file_892.jpg \t (60000, 17)\n",
      "2017-05-20 05:48:43.863555\n"
     ]
    }
   ],
   "source": [
    "#nameAsk = os.listdir(teDirI); print(len(nameAsk))\n",
    "nameAsk = os.listdir(teDirJPG); print(len(nameAsk))\n",
    "trOX, trOY, i, ii, size = [], [], 0, 0, len(nameAsk)\n",
    "print(datetime.datetime.now(),len(nameAsk),size)\n",
    "for nn in nameAsk[0:size] :\n",
    "    #nf = os.path.join(teDirTIF,nn);\n",
    "    nf = os.path.join(teDirJPG,nn);\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        trOX.append(nx)\n",
    "        trOY.append(nn)\n",
    "    i += 1\n",
    "    if (i%10000==0) and (i>1) :\n",
    "        if (ii==0) :\n",
    "            trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "            trP = model.predict(trOX, batch_size=512); \n",
    "        else :\n",
    "            trOX = np.array(trOX);  trOX = trOX / 255.0\n",
    "            trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "        trOX,ii = [],ii+1;\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",ii,'\\t',i,\"\\t\",nn,'\\t',(trP.shape if ii>0 else \"\"))\n",
    "\n",
    "if (len(trOX)>0) :\n",
    "    if (ii==0) :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = model.predict(trOX, batch_size=512); \n",
    "    else :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "    trOX,ii = [],ii+1;\n",
    "    \n",
    "print(datetime.datetime.now())\n",
    "\n",
    "#assert (size!=len(trOY)), \"Wrong files {} != {}\".format(size,len(trOY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191 (61191, 17) (61191,)\n"
     ]
    }
   ],
   "source": [
    "#trOX = np.array(trOX);\n",
    "trOY = np.array([os.path.splitext(x)[0] for x in trOY]);\n",
    "print(len(nameAsk),trP.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy',trOX)\n",
    "np.save('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 32, 32, 6) (61191,)\n"
     ]
    }
   ],
   "source": [
    "trOX = np.load('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy')\n",
    "trOY = np.load('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy')\n",
    "print(trOX.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.75841929007857778,\n",
       " 1: 0.98263848366246676,\n",
       " 2: 0.84722629763157453,\n",
       " 3: 0.97604678247993626,\n",
       " 4: 0.78729476795032916,\n",
       " 5: 0.78956810256787635,\n",
       " 6: 0.83083164404299403,\n",
       " 7: 0.73801616416924898,\n",
       " 8: 0.6761901702314258,\n",
       " 9: 0.86068787363532673,\n",
       " 10: 0.96403428373772715,\n",
       " 11: 0.90053737661152566,\n",
       " 12: 0.6528441526860862,\n",
       " 13: 0.86359942524081812,\n",
       " 14: 0.37037005520335736,\n",
       " 15: 0.68382329252278806,\n",
       " 16: 0.58917169677281178}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrx\n",
    "rrd=dict()\n",
    "for i in range(len(rrx)) :\n",
    "    rrd[i]=rrx[i]\n",
    "rrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Forming result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61191, 17), array([  6.56801313e-02,   7.46541142e-01,   2.32726157e-01,\n",
       "          9.55386758e-01,   1.95543230e-01,   9.11955476e-01,\n",
       "          8.89197826e-01,   2.53069662e-02,   1.54045611e-05,\n",
       "          7.43342913e-04,   6.54759035e-02,   6.17289741e-04,\n",
       "          8.51887614e-02,   2.95602629e-04,   2.64362683e-07,\n",
       "          1.03749386e-04,   2.92145728e-07], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trP = model.predict(trOX, batch_size=512); \n",
    "trP.shape, trP[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "[3, 10, 0, 9] \n",
      " ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down'] \n",
      " [2.0, 0.5, 0.5, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "trM=np.array([0.0]*len(labels)); print(trM.shape)\n",
    "wr = [labels.index(i) for i in weather_labels];\n",
    "tt=trM; trM[:]=0.5\n",
    "trM[np.array(wr)] = 2.0\n",
    "print(wr,'\\n',labels,'\\n',trM.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'clear primary'] \n",
      " ['file_20521', 'clear primary'] \n",
      " [ 2.   0.5  0.5  2.   0.5  0.5  0.5  0.5  0.5  2.   2.   0.5  0.5  0.5  0.5\n",
      "  0.5  0.5] [  1.63650557e-01   3.91220033e-01   1.36160061e-01   9.47374701e-01\n",
      "   9.09343541e-01   1.55211976e-02   3.13203782e-02   1.42206885e-02\n",
      "   8.06170846e-08   9.10553038e-01   7.85041321e-03   4.12757437e-08\n",
      "   6.71853591e-03   1.33155788e-06   7.46736941e-06   9.65268737e-06\n",
      "   7.95199711e-08]\n"
     ]
    }
   ],
   "source": [
    "#trP = model.predict(trX, batch_size=512); trP=K.get_value(trP)\n",
    "res = []\n",
    "\n",
    "for i in range(trP.shape[0]) :\n",
    "    trPP = [weather_labels[trP[i,wr].argmax()]] + [labels[ii] for ii in range(len(labels)) if (trP[i,ii]>trM[ii])];\n",
    "    pp   = ' '.join(trPP)\n",
    "    ##if (pp==\"\") : print(trY[i])\n",
    "    res.append([trOY[i],pp])\n",
    "\n",
    "res.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n",
    "#print(res[4:8],'\\n',res[-4:])\n",
    "print(res[0],'\\n',res[-1],'\\n',trM,trP[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "#print(trM.tolist())\n",
    "#np.round(trP[4:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20-05-51-18\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(res,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
