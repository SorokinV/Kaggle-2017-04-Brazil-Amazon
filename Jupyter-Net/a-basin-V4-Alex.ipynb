{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## AlexNet analog (Krizhevsky 2012)\n",
    "##\n",
    "## 2017-05-20\n",
    "## maximum on LB => 0.84500\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import formFH, paths_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Data/test-jpg-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, teDirJPG, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##np.save('../Data-Keras/Datas/train-model-2D-224x224x3-XX-short.npy',trX)\n",
    "##np.save('../Data-Keras/Datas/train-model-2D-224x224x3-YY-short.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    ###trXX = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-XX.npy')\n",
    "    ###trYY = np.load('../Data-Keras/Datas/train-model-2D-64x64x6-YY.npy')\n",
    "    ######trXX  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-XX.npy')\n",
    "    ######trYY  = np.load('../Data-Keras/Datas/train-model-2D-64x64x3-YY.npy')\n",
    "    ##trXX  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-XX.npy')\n",
    "    ##trYY  = np.load('../Data-Keras/Datas/train-model-2D-128x128x3-YY.npy')\n",
    "    trXX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX.npy')\n",
    "    trYY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY.npy')\n",
    "    trX, trY = trXX[trYY[:,3]==0], trYY[trYY[:,3]==0] # not cloudy\n",
    "    trY=trY[:,[0,1,2]+range(4,17)] # --cloudy\n",
    "    del trXX,trYY\n",
    "    print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12048, 224, 224, 3) (12048, 16)\n"
     ]
    }
   ],
   "source": [
    "trX  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-XX-short.npy')\n",
    "trY  = np.load('../Data-Keras/Datas/train-model-2D-224x224x3-YY-short.npy')\n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#trX=trX/255.0\n",
    "##trX = cv.normalize(trX, trX, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "#trX=trX/65535.0\n",
    "#trX[0,:,:]\n",
    "#trX[:,:,:,5].max(),trX.min(),trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fbeta_pred(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "#\n",
    "def Kriz2012 ( model, iSize, rSize ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    model.add(Convolution2D(96,(11,11),strides=(4,4),activation='relu'))\n",
    "    model.add(Convolution2D(256,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(256,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)\n",
    "\n",
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "#\n",
    "def Kriz2012X ( model, iSize, rSize ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    model.add(Convolution2D(96,(11,11),strides=(4,4),activation='relu'))\n",
    "    model.add(Convolution2D(256,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    #model.add(Convolution2D(256,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(128,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    #model.add(Dense(4096,activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "# cut version\n",
    "#\n",
    "#\n",
    "def Kriz2012x3x3 ( model, iSize, rSize, cv2d, dense, pp ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(axis=3,input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    if not (cv2d is None) :\n",
    "        for cv in cv2d :\n",
    "            if (cv>0) :\n",
    "                model.add(Convolution2D(cv,(2,2)))\n",
    "                #model.add(BatchNormalization(axis=3))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if not (dense is None) :\n",
    "        for de in dense :\n",
    "            if (de>0) :\n",
    "                model.add(Dense(pp[5],activation='relu'))\n",
    "                model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildModel (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    if (cv2d is None) and (dense is None) and not (params is None) : cv2d, dense = params[:-2], params[-2:]\n",
    "    model = Kriz2012x3x3(model,iSize,rSize,cv2d=cv2d,dense=dense,pp=params)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "def buildModelKriz (iSize,rSize,params=None,cv2d=None,dense=None) :\n",
    "    model = Sequential()\n",
    "    \n",
    "    model = Kriz2012X(model,iSize,rSize)\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error',  #'binary_crossentropy',\n",
    "                  optimizer=\"adam\", #sgd, #\"adam\", #'rmsprop',\n",
    "                  metrics=[fbeta_pred,'acc']) #['binary_accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "    #              optimizer='adam', #'adam', #sgd, #\"adam\", #'rmsprop',\n",
    "    #              metrics=['accuracy']) #[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#mm1=np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "#mm2=np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "#mm1,mm2,mm1+mm2\n",
    "#len(result),len(resAll)\n",
    "#trX.shape,trX.dtype,trX[0]\n",
    "#trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resAll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3) 16\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=12,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "params = [(32,64,32,0,0,256,0),(32,64,16,0,0,256,0),(32,64,32,0,0,256,0),(32,64,64,0,0,256,0),(32,64,128,0,0,256,0),(32,64,256,0,0,256,0),(32,64,512,0,0,256,0),(32,64,1024,0,0,256,0)]\n",
    "params = params+[(32,64,8,0,0,16,0),(32,64,16,0,0,256,0),(32,64,32,0,0,64,0),(32,64,64,0,0,128,0),(32,64,128,0,0,256,0),(32,64,256,0,0,512,0),(32,64,512,0,0,1024,0),(32,64,1024,0,0,2048,0)]\n",
    "params = params+[(32,64,8,0,0,16,128),(32,64,16,0,0,32,128),(32,64,32,0,0,64,128),(32,64,64,0,0,128,128),(32,64,128,0,0,256,128),(32,64,256,0,0,512,128),(32,64,512,0,0,1024,128),(32,64,1024,0,0,2048,128)]\n",
    "params = params+[(96,256,384,384,256,4096,4096),(96,256,384,384,256,4096,2048),(96,256,384,384,256,2048,4096),(96,256,384,384,256,2048,2048),\n",
    "          (96,256,384,384,0,4096,0),(96,256,384,0,256,4096,0),(96,256,0,0,256,4096,0),\n",
    "          (96,256,0,0,0,4096,0),(96,0,0,0,0,4096,0),(96,256,0,0,256,4096,0)]\n",
    "#         (96,256,384,197,256,4096,0),  bad unchausted memory ResourceExhaustedError: OOM when allocating tensor with shape[128,8,8,384]\n",
    "#         (96,128,0,0,0,4096,0),\n",
    "#\n",
    "#        [(96,256,197,0,0,4096,0), (96,256,384,384,256,4096,0)]\n",
    "#\n",
    "#       [(96,32,0,0,0,1024,0),(96,64,0,0,0,1024,0),(96,128,0,0,0,1024,0),(96,256,0,0,0,1024,0),\n",
    "#         (256,32,0,0,0,1024,0),(256,64,0,0,0,1024,0),(256,128,0,0,0,1024,0)]\n",
    "\n",
    "params = [(96,64,0,0,0,256,0),(96,64,0,0,0,512,0),(96,64,0,0,0,1024,0),(96,64,0,0,0,2048,0),(96,64,0,0,0,8192,0)]\n",
    "params = params+[(16,64,0,0,0,256,0),(32,64,0,0,0,256,0),(64,64,0,0,0,256,0),(128,64,0,0,0,256,0),(256,64,0,0,0,256,0)]\n",
    "\n",
    "params = [(32,64,16,0,0,256,0)] \n",
    "params = [(16,32,64,256,0,512,512),(8,64,256,1024,0,512,512),(8,64,256,1024,0,0,512),(8,64,256,2048,0,0,512),(8,64,256,2048,0,512,512),\n",
    "          (8,64,256,2048,0,1024,0),(8,64,256,2048,0,1024,1024)]\n",
    "##params = [(8,64,256,1024,0,512,512),(8,64,256,1024,0,512,0)]\n",
    "params = [(8,64,256,2048,0,2048,0)] # 0.87 0.87\n",
    "params = [(8,64,256,4096,0,1024,0)] # 0.8686 0.8724\n",
    "params = [(32,64,16,0,0,256,512),(8,64,256,2048,0,1024,0),(8,64,256,2048,0,512,0),(8,64,256,4096,0,256,0)] # 0.875 0.8796\n",
    "params = [(32,64,16,0,0,256,512)]\n",
    "\n",
    "#params = [(8,64,256,4096,0,256,0)]\n",
    "\n",
    "iSize, rSize, result = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], []\n",
    "print(iSize,rSize)\n",
    "epochs  = 100\n",
    "verbose = 2\n",
    "batch_size = 64 # 64 0.8633 0.8717 (68 secs/batch) # 32 0.8545 0.8653 (87 secs/batch) # 16 0.8483 0.8623 (137 secs/batch) # 32\n",
    "for pp in [] : #params :\n",
    "    filepath=\"../Data-Keras/weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    model1 = buildModel(iSize,rSize,pp)\n",
    "    tr1=np.sum([K.count_params(p) for p in set(model1.trainable_weights)])\n",
    "    tr2=np.sum([K.count_params(p) for p in set(model1.non_trainable_weights)])\n",
    "    if (tr1+tr2)>14000000 : \n",
    "        print(datetime.datetime.now(),pp,tr1+tr2,'(badly)')\n",
    "        continue;\n",
    "    print(datetime.datetime.now(),pp,tr1+tr2)\n",
    "    hist1  = model1.fit(trX,trY,epochs=epochs, batch_size=batch_size, validation_split=0.20, \n",
    "                        callbacks=[early_stopping,reduce_lr,checkpoint],\n",
    "                        verbose=verbose)\n",
    "    \n",
    "    trP = model1.predict(trX, batch_size=128)\n",
    "    fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "    fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "    #print(datetime.datetime.now(),pp,hist1.history['fbeta_pred'][-1],hist1.history['val_fbeta_pred'][-1],'fbeta2s=',fbeta2score,fbeta2pred)\n",
    "    print(datetime.datetime.now(),pp,'fbeta2s=',fbeta2score,fbeta2pred)\n",
    "    result.append([pp,hist1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3) 16\n"
     ]
    }
   ],
   "source": [
    "iSize, rSize, result = (trX.shape[1],trX.shape[2],trX.shape[3]), trY.shape[1], []\n",
    "params = (32,64,128,256,0,256,512)\n",
    "print(iSize,rSize)\n",
    "metric = 'acc'\n",
    "model10 = buildModelKriz(iSize,rSize,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-05 08:31:49.553862 66760988\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: acc improved from -inf to 0.55000, saving model to ../Temp/weights.00-acc=0.5550.hdf5\n",
      "38s - loss: 0.1371 - fbeta_pred: 0.6252 - acc: 0.5500 - val_loss: 0.1159 - val_fbeta_pred: 0.6427 - val_acc: 0.5550\n",
      "Epoch 2/100\n",
      "Epoch 00001: acc improved from 0.55000 to 0.59625, saving model to ../Temp/weights.01-acc=0.5550.hdf5\n",
      "25s - loss: 0.1047 - fbeta_pred: 0.6739 - acc: 0.5962 - val_loss: 0.1159 - val_fbeta_pred: 0.6427 - val_acc: 0.5550\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,128,22,22]\n\t [[Node: gradients_1/max_pooling2d_2/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@max_pooling2d_2/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_10/Relu, max_pooling2d_2/MaxPool, gradients_1/flatten_2/Reshape_grad/Reshape)]]\n\nCaused by op u'gradients_1/max_pooling2d_2/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-36-6bcba8d60a04>\", line 30, in <module>\n    verbose=verbose)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/models.py\", line 856, in fit\n    initial_epoch=initial_epoch)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.py\", line 1481, in fit\n    self._make_train_function()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.py\", line 1013, in _make_train_function\n    self.total_loss)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/optimizers.py\", line 381, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/optimizers.py\", line 47, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2264, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 438, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1737, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'max_pooling2d_2/MaxPool', defined at:\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 18 identical lines from previous traceback]\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-616bc7199140>\", line 5, in <module>\n    model10 = buildModelKriz(iSize,rSize,params)\n  File \"<ipython-input-30-d1a7fe3c98fd>\", line 18, in buildModelKriz\n    model = Kriz2012X(model,iSize,rSize)\n  File \"<ipython-input-28-44a5702ee636>\", line 63, in Kriz2012X\n    model.add(MaxPooling2D(pool_size=(2,2)))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/models.py\", line 466, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/topology.py\", line 585, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/layers/pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/layers/pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3245, in pool2d\n    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1821, in max_pool\n    name=name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1638, in _max_pool\n    data_format=data_format, name=name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,128,22,22]\n\t [[Node: gradients_1/max_pooling2d_2/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@max_pooling2d_2/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_10/Relu, max_pooling2d_2/MaxPool, gradients_1/flatten_2/Reshape_grad/Reshape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6bcba8d60a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     verbose=verbose)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m##trP = model1.predict(trX, batch_size=128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,128,22,22]\n\t [[Node: gradients_1/max_pooling2d_2/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@max_pooling2d_2/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_10/Relu, max_pooling2d_2/MaxPool, gradients_1/flatten_2/Reshape_grad/Reshape)]]\n\nCaused by op u'gradients_1/max_pooling2d_2/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-36-6bcba8d60a04>\", line 30, in <module>\n    verbose=verbose)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/models.py\", line 856, in fit\n    initial_epoch=initial_epoch)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.py\", line 1481, in fit\n    self._make_train_function()\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.py\", line 1013, in _make_train_function\n    self.total_loss)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/optimizers.py\", line 381, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/optimizers.py\", line 47, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2264, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 438, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1737, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'max_pooling2d_2/MaxPool', defined at:\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 18 identical lines from previous traceback]\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-616bc7199140>\", line 5, in <module>\n    model10 = buildModelKriz(iSize,rSize,params)\n  File \"<ipython-input-30-d1a7fe3c98fd>\", line 18, in buildModelKriz\n    model = Kriz2012X(model,iSize,rSize)\n  File \"<ipython-input-28-44a5702ee636>\", line 63, in Kriz2012X\n    model.add(MaxPooling2D(pool_size=(2,2)))\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/models.py\", line 466, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/topology.py\", line 585, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/layers/pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/layers/pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3245, in pool2d\n    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1821, in max_pool\n    name=name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1638, in _max_pool\n    data_format=data_format, name=name)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,128,22,22]\n\t [[Node: gradients_1/max_pooling2d_2/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@max_pooling2d_2/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_10/Relu, max_pooling2d_2/MaxPool, gradients_1/flatten_2/Reshape_grad/Reshape)]]\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10,min_delta=0.0001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "\n",
    "epochs     = 100\n",
    "verbose    = 2\n",
    "batch_size = 64\n",
    "\n",
    "filepath=\"../Temp/weights.{epoch:02d}-acc={val_\"+metric+\":.4f}.hdf5\"\n",
    "##checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=metric, verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "##model1 = buildModel(iSize,rSize,pp)\n",
    "tr1    = np.sum([K.count_params(p) for p in set(model10.trainable_weights)])\n",
    "tr2    = np.sum([K.count_params(p) for p in set(model10.non_trainable_weights)])\n",
    "\n",
    "#print(tr1,tr2,tr1+tr2)\n",
    "#assert ((tr1+tr2)>14000000)\n",
    "\n",
    "step = 1000\n",
    "low  = 0\n",
    "high = low+step\n",
    "\n",
    "print(datetime.datetime.now(),tr1+tr2)\n",
    "#hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "hist1  = model10.fit(trX[low:high],trY[low:high],\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.20, \n",
    "                    callbacks=[early_stopping,reduce_lr,checkpoint],\n",
    "                    verbose=verbose)\n",
    "\n",
    "##trP = model1.predict(trX, batch_size=128)\n",
    "##fbeta2score=fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples')\n",
    "##fbeta2pred =K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64)))\n",
    "print(datetime.datetime.now()) #,pp,'fbeta2s=',fbeta2score,fbeta2pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12048, 224, 224, 3), (12048, 16))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape, trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trP = model10.predict(trX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10595638280212484, 0.67353584527336108, 0.59553452855245681]\n",
      "(12048, 16)\n",
      "(12048, 16)\n",
      "fbeta_score= 0.572584122385\n",
      "fbeta_pred = 0.673862288804\n"
     ]
    }
   ],
   "source": [
    "print(model10.evaluate(trX,trY,verbose=2))\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resAll = resAll+result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True : #False :\n",
    "    save_model(model10,'../Data-Keras/Models/model-Alex-128x128x3.h5')\n",
    "    model10.save_weights('../Data-Keras/Models/model-Alex-weights-128x128x3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 256)       614656    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 46, 46, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 44, 44, 128)       442496    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              63439872  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 66,760,988\n",
      "Trainable params: 66,760,982\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20 05:22:01.009723 0 --> 70 0.758419290079 [0.75741733368803943, 0.75841929007857778, 0.75785138394714635]\n",
      "2017-05-20 05:22:23.972821 1 --> 78 0.982638483662 [0.98262473453994426, 0.98263848366246676, 0.98259679666709321]\n",
      "2017-05-20 05:22:52.632376 2 --> 58 0.847226297632 [0.8469111862002846, 0.84722629763157453, 0.84682213028656683]\n",
      "2017-05-20 05:23:27.033547 3 --> 78 0.97604678248 [0.97585536488705449, 0.97604678247993626, 0.97586138532621902]\n",
      "2017-05-20 05:24:07.288213 4 --> 39 0.78729476795 [0.78664609854346335, 0.78729476795032916, 0.78707371492899492]\n",
      "2017-05-20 05:24:52.980975 5 --> 42 0.789568102568 [0.78871126051941221, 0.78956810256787635, 0.78669767415698355]\n",
      "2017-05-20 05:25:44.022237 6 --> 47 0.830831644043 [0.8305167161398419, 0.83083164404299403, 0.83015444819651052]\n",
      "2017-05-20 05:26:40.712293 7 --> 45 0.738016164169 [0.73686966073098015, 0.73801616416924898, 0.73773213859960107]\n",
      "2017-05-20 05:27:43.679293 8 --> 26 0.676190170231 [0.6690774577597115, 0.6761901702314258, 0.65439641541326066]\n",
      "2017-05-20 05:28:52.203737 9 --> 99 0.860687873635 [0.84540789671187133, 0.86068787363532673]\n",
      "2017-05-20 05:30:06.360727 10 --> 53 0.964034283738 [0.96339687009527564, 0.96403428373772715, 0.96364205060652686]\n",
      "2017-05-20 05:31:26.352144 11 --> 30 0.900537376612 [0.89285689393748568, 0.90053737661152566, 0.90053737661152566]\n",
      "2017-05-20 05:32:51.552201 12 --> 27 0.652844152686 [0.64595635259618922, 0.6528441526860862, 0.65053736636295179]\n",
      "2017-05-20 05:34:22.405562 13 --> 24 0.863599425241 [0.86179482608466784, 0.86359942524081812, 0.85725979475579062]\n",
      "2017-05-20 05:35:59.177670 14 --> 14 0.370370055203 [0.3600540358709392, 0.37037005520335736, 0.35595995253798635]\n",
      "2017-05-20 05:37:41.803909 15 --> 22 0.683823292523 [0.67335220282476826, 0.68382329252278806, 0.67567543551442677]\n",
      "2017-05-20 05:39:29.432537 16 --> 14 0.589171696773 [0.56748439106677917, 0.58917169677281178, 0.5851060891681884]\n"
     ]
    }
   ],
   "source": [
    "rr, rrx = [], []; trP = model.predict(trX, batch_size=128)\n",
    "for i in range(trP.shape[1]) :\n",
    "    xx = [];\n",
    "    trYY = trY[:,i].astype(np.float64)\n",
    "    trPY = trP[:,i]\n",
    "    for ii in range(100) :\n",
    "        trPP = (trPY>0.01*ii).astype(np.float64)\n",
    "        #x = fbeta_score(trY[:,0], np.array(trP[:,0] > 0.1*ii), beta=2, average='samples')\n",
    "        x = K.get_value(fbeta_pred(trYY,trPP))\n",
    "        xx.append(x)\n",
    "    rrr = np.array(xx).argmax();\n",
    "    rr.append(rrr)\n",
    "    rrx.append(xx[rrr])\n",
    "    print(datetime.datetime.now(),i,'-->',rrr,xx[rrr],xx[(rrr-1):(rrr+2)])\n",
    "    #print(xx);\n",
    "    #plt.plot(np.array(xx)); plt.show()\n",
    "trM = np.array(rr)/100.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191\n",
      "2017-05-20 05:46:19.287685 61191 61191\n",
      "2017-05-20 05:46:38.218814 \t 0 \t 5000 \t test_14523.jpg \t \n",
      "2017-05-20 05:46:51.023731 \t 1 \t 10000 \t test_19029.jpg \t (10000, 17)\n",
      "2017-05-20 05:46:58.884016 \t 1 \t 15000 \t test_23524.jpg \t (10000, 17)\n",
      "2017-05-20 05:47:09.507695 \t 2 \t 20000 \t test_28015.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:16.475888 \t 2 \t 25000 \t test_32520.jpg \t (20000, 17)\n",
      "2017-05-20 05:47:26.837760 \t 3 \t 30000 \t test_37026.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:33.858034 \t 3 \t 35000 \t test_4908.jpg \t (30000, 17)\n",
      "2017-05-20 05:47:44.019579 \t 4 \t 40000 \t test_9402.jpg \t (40000, 17)\n",
      "2017-05-20 05:47:51.298769 \t 4 \t 45000 \t file_13913.jpg \t (40000, 17)\n",
      "2017-05-20 05:48:01.555641 \t 5 \t 50000 \t file_18419.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:24.538867 \t 5 \t 55000 \t file_4564.jpg \t (50000, 17)\n",
      "2017-05-20 05:48:40.785101 \t 6 \t 60000 \t file_892.jpg \t (60000, 17)\n",
      "2017-05-20 05:48:43.863555\n"
     ]
    }
   ],
   "source": [
    "#nameAsk = os.listdir(teDirI); print(len(nameAsk))\n",
    "nameAsk = os.listdir(teDirJPG); print(len(nameAsk))\n",
    "trOX, trOY, i, ii, size = [], [], 0, 0, len(nameAsk)\n",
    "print(datetime.datetime.now(),len(nameAsk),size)\n",
    "for nn in nameAsk[0:size] :\n",
    "    #nf = os.path.join(teDirTIF,nn);\n",
    "    nf = os.path.join(teDirJPG,nn);\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        trOX.append(nx)\n",
    "        trOY.append(nn)\n",
    "    i += 1\n",
    "    if (i%10000==0) and (i>1) :\n",
    "        if (ii==0) :\n",
    "            trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "            trP = model.predict(trOX, batch_size=512); \n",
    "        else :\n",
    "            trOX = np.array(trOX);  trOX = trOX / 255.0\n",
    "            trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "        trOX,ii = [],ii+1;\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",ii,'\\t',i,\"\\t\",nn,'\\t',(trP.shape if ii>0 else \"\"))\n",
    "\n",
    "if (len(trOX)>0) :\n",
    "    if (ii==0) :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = model.predict(trOX, batch_size=512); \n",
    "    else :\n",
    "        trOX = np.array(trOX); trOX = trOX / 255.0\n",
    "        trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "    trOX,ii = [],ii+1;\n",
    "    \n",
    "print(datetime.datetime.now())\n",
    "\n",
    "#assert (size!=len(trOY)), \"Wrong files {} != {}\".format(size,len(trOY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191 (61191, 17) (61191,)\n"
     ]
    }
   ],
   "source": [
    "#trOX = np.array(trOX);\n",
    "trOY = np.array([os.path.splitext(x)[0] for x in trOY]);\n",
    "print(len(nameAsk),trP.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy',trOX)\n",
    "np.save('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 32, 32, 6) (61191,)\n"
     ]
    }
   ],
   "source": [
    "trOX = np.load('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy')\n",
    "trOY = np.load('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy')\n",
    "print(trOX.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.75841929007857778,\n",
       " 1: 0.98263848366246676,\n",
       " 2: 0.84722629763157453,\n",
       " 3: 0.97604678247993626,\n",
       " 4: 0.78729476795032916,\n",
       " 5: 0.78956810256787635,\n",
       " 6: 0.83083164404299403,\n",
       " 7: 0.73801616416924898,\n",
       " 8: 0.6761901702314258,\n",
       " 9: 0.86068787363532673,\n",
       " 10: 0.96403428373772715,\n",
       " 11: 0.90053737661152566,\n",
       " 12: 0.6528441526860862,\n",
       " 13: 0.86359942524081812,\n",
       " 14: 0.37037005520335736,\n",
       " 15: 0.68382329252278806,\n",
       " 16: 0.58917169677281178}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrx\n",
    "rrd=dict()\n",
    "for i in range(len(rrx)) :\n",
    "    rrd[i]=rrx[i]\n",
    "rrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Forming result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61191, 17), array([  6.56801313e-02,   7.46541142e-01,   2.32726157e-01,\n",
       "          9.55386758e-01,   1.95543230e-01,   9.11955476e-01,\n",
       "          8.89197826e-01,   2.53069662e-02,   1.54045611e-05,\n",
       "          7.43342913e-04,   6.54759035e-02,   6.17289741e-04,\n",
       "          8.51887614e-02,   2.95602629e-04,   2.64362683e-07,\n",
       "          1.03749386e-04,   2.92145728e-07], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trP = model.predict(trOX, batch_size=512); \n",
    "trP.shape, trP[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "[3, 10, 0, 9] \n",
      " ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down'] \n",
      " [2.0, 0.5, 0.5, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "trM=np.array([0.0]*len(labels)); print(trM.shape)\n",
    "wr = [labels.index(i) for i in weather_labels];\n",
    "tt=trM; trM[:]=0.5\n",
    "trM[np.array(wr)] = 2.0\n",
    "print(wr,'\\n',labels,'\\n',trM.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'clear primary'] \n",
      " ['file_20521', 'clear primary'] \n",
      " [ 2.   0.5  0.5  2.   0.5  0.5  0.5  0.5  0.5  2.   2.   0.5  0.5  0.5  0.5\n",
      "  0.5  0.5] [  1.63650557e-01   3.91220033e-01   1.36160061e-01   9.47374701e-01\n",
      "   9.09343541e-01   1.55211976e-02   3.13203782e-02   1.42206885e-02\n",
      "   8.06170846e-08   9.10553038e-01   7.85041321e-03   4.12757437e-08\n",
      "   6.71853591e-03   1.33155788e-06   7.46736941e-06   9.65268737e-06\n",
      "   7.95199711e-08]\n"
     ]
    }
   ],
   "source": [
    "#trP = model.predict(trX, batch_size=512); trP=K.get_value(trP)\n",
    "res = []\n",
    "\n",
    "for i in range(trP.shape[0]) :\n",
    "    trPP = [weather_labels[trP[i,wr].argmax()]] + [labels[ii] for ii in range(len(labels)) if (trP[i,ii]>trM[ii])];\n",
    "    pp   = ' '.join(trPP)\n",
    "    ##if (pp==\"\") : print(trY[i])\n",
    "    res.append([trOY[i],pp])\n",
    "\n",
    "res.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n",
    "#print(res[4:8],'\\n',res[-4:])\n",
    "print(res[0],'\\n',res[-1],'\\n',trM,trP[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "#print(trM.tolist())\n",
    "#np.round(trP[4:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-20-05-51-18\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(res,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
