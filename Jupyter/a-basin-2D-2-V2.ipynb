{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys,os,datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__);\n",
    "print(pd.__version__);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Python')\n",
    "from helper import formFH, paths_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential,save_model,load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/train-tif-v2',\n",
       " '../Data/test-tif-v2',\n",
       " '../Work/Train',\n",
       " '../Work/Test')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trLabels,trDirTIF,trDirJPG,teDirTIF,teDirJPG = paths_input()\n",
    "trDirI = trDirTIF\n",
    "teDirI = teDirTIF\n",
    "trWork, teWork = '../Work/Train', '../Work/Test'\n",
    "trDirI,teDirI, trWork, teWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(trLabels)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    #labels_df[label].astype(np.int8)\n",
    "# Display head\n",
    "#labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation' ]\n",
    "rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\n",
    "#rare_labels              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = label_list; #weather_labels;\n",
    "nameList =labels_df[labels_df[labels].sum(axis=1)>0].image_name.tolist(); len(nameList)\n",
    "labelList=labels_df[labels_df[labels].sum(axis=1)>0][labels].as_matrix();\n",
    "labelList[:6,:]\n",
    "#labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def formImExt (nf, resize=(32,32), printOK=False) :\n",
    "    nx = None\n",
    "    try : \n",
    "        ni = cv.imread(nf,-1); \n",
    "        if (ni is not None) :\n",
    "            if not ((ni.shape[2]==3) or (ni.shape[2]==4)) and printOK : print('----- error ---- shape:',ni.shape,nf)\n",
    "            if (ni.shape[2]==3) :\n",
    "                nx = cv.resize(ni,resize)\n",
    "            if (ni.shape[2]==4) :\n",
    "                #r,g,b,n = ni[:,:,2],ni[:,:,1],ni[:,:,0],ni[:,:,3]\n",
    "                r,g,b,n = cv.resize(ni[:,:,2],resize),cv.resize(ni[:,:,1],resize),cv.resize(ni[:,:,0],resize),cv.resize(ni[:,:,3],resize)\n",
    "                dv,dw   = np.divide((r-n),(r+n+0.01)), np.divide((g-n),(g+n+0.01))\n",
    "                nx      = np.array([r,g,b,n,dv,dw]).T; \n",
    "    except BaseException as e :\n",
    "        print(nf,e); nx = None;\n",
    "    \n",
    "    if nx is None and printOK : \n",
    "        print('------ None:',nf); nx = None\n",
    "        \n",
    "    return(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-17 01:13:07.494771 40479 40479\n",
      "2017-05-17 01:16:37.692809 \t 5000 \t train_4999\n",
      "2017-05-17 01:19:26.533243 \t 10000 \t train_9999\n",
      "2017-05-17 01:22:03.474690 \t 15000 \t train_14999\n",
      "2017-05-17 01:24:39.649915 \t 20000 \t train_19999\n",
      "2017-05-17 01:27:09.540339 \t 25000 \t train_24999\n",
      "2017-05-17 01:29:38.237389 \t 30000 \t train_29999\n",
      "2017-05-17 01:32:05.531116 \t 35000 \t train_34999\n",
      "2017-05-17 01:34:34.413286 \t 40000 \t train_39999\n",
      "2017-05-17 01:34:47.681317\n",
      "40479 (40479, 64, 64, 6) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "trX, trY, i, size = [],[], 0, len(nameList)\n",
    "print(datetime.datetime.now(),len(nameList),size)\n",
    "for nn in nameList[0:size] :\n",
    "    nf = os.path.join(trDirTIF,nn+\".tif\");\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        #rr=np.save(os.path.join(trWork,nn+\".npy\"),nx);\n",
    "        #trX.append(nn+\".npy\")\n",
    "        trX.append(nx)\n",
    "        trY.append(True)\n",
    "    else : \n",
    "        trY.append(False)\n",
    "    i += 1\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",i,\"\\t\",nn)\n",
    "    #print(nn.shape)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "trX = np.array(trX);\n",
    "trY = labelList[trY];\n",
    "print(len(nameList),trX.shape,trY.shape)\n",
    "#trXY=pd.DataFrame(trY); trXY['name']=trX; trXY.head()\n",
    "#trXY.to_pickle(os.path.join(trWork,\"listFiles.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('../Data-Keras/train-model-2D-64x64-v2-XX.npy',trX)\n",
    "np.save('../Data-Keras/train-model-2D-64x64-v2-YY.npy',trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del(trOX); del(trOY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 6) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "trX = np.load('../Data-Keras/train-model-2D-64x64-v2-XX.npy')\n",
    "trY = np.load('../Data-Keras/train-model-2D-64x64-v2-YY.npy')\n",
    "print(trX.shape,trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def fbeta_pred(y_true, y_pred, beta=2.0, OK1=0.2, eps=0.000001, printOK=False):\n",
    "    beta2 = beta*beta\n",
    "    yy_true = K.round(y_true)\n",
    "    #yy_pred = K.round(y_pred+(0.5-OK1))\n",
    "    yy_pred = K.round(y_pred)\n",
    "    tp, tp_fp, fn = K.sum((yy_pred*yy_true)), K.sum(yy_true), K.sum((K.abs(yy_pred*(yy_true-1.0))))\n",
    "    precision, recall = tp/(tp_fp+eps), tp/(tp+fn+eps) \n",
    "    fbeta = (1+beta2)*(precision*recall)/(beta2*precision+recall+eps)\n",
    "    ##if fbeta>1.0 : fbeta = 1.0;\n",
    "    if printOK :\n",
    "        print('ten true ',K.get_value(yy_true))\n",
    "        #print('ten pred ',y_pred)\n",
    "        print('ten roun ',K.get_value(yy_pred))\n",
    "        print(' pre=',K.get_value(precision),' recall=',K.get_value(recall),' tp=',\n",
    "              K.get_value(tp),' fn=',K.get_value(fn),' tp+fp=',K.get_value(tp_fp))\n",
    "    return(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "#\n",
    "def Kriz2012 ( model, iSize, rSize ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    model.add(Convolution2D(96,(11,11),strides=(4,4),activation='relu'))\n",
    "    model.add(Convolution2D(256,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(256,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# model Krizevsky 2012\n",
    "#\n",
    "#    input(224x224)\n",
    "#    c2d(96,(11,11),strides=(4,4))\n",
    "#    c2d(256,(5,5))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(384,(3,3))\n",
    "#    c2d(256,(3,3))\n",
    "#    maxp(2,2)\n",
    "#    flaten()\n",
    "#    dense(4096)\n",
    "#    dense(4096)\n",
    "#    dense(output(1000))\n",
    "#\n",
    "# cut version\n",
    "#\n",
    "#\n",
    "def Kriz2012c ( model, iSize, rSize ) :\n",
    "    i1,i2,i3 = iSize\n",
    "    model.add(BatchNormalization(input_shape=(i1,i2,i3)))\n",
    "    \n",
    "    model.add(Convolution2D(96,(11,11),strides=(4,4),activation='relu'))\n",
    "    model.add(Convolution2D(256,(5,5),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(384,(3,3),activation='relu'))\n",
    "    model.add(Convolution2D(256,(3,3),activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    ##model.add(Dense(2048,activation='relu'))\n",
    "    ##model.add(Dropout(0.25))\n",
    "    #model.add(Dense(4096,activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(rSize,activation='sigmoid'))\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# try model Krizevsky 2012\n",
    "#\n",
    "#iSize = (trX.shape[1],trX.shape[2],trX.shape[3])\n",
    "iSize = (64,64,6)\n",
    "#rSize = trY.shape[1]\n",
    "rSize = 17\n",
    "model = Sequential()\n",
    "model = Kriz2012c(model,iSize,rSize)\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', #sgd, #\"adam\", #'rmsprop',\n",
    "              metrics=[fbeta_pred]) #['accuracy',fbeta_pred]) #['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# badly don't work: fail customs metric # model=load_model('../Data-Keras/basin02-loop-all.h5') ## verify load from v1 version\n",
    "#model.load_weights('../Data-Keras/train-model-020-1D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 64, 64, 6)         24        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 96)        69792     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 256)       614656    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 256)         884992    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 8,050,121\n",
      "Trainable params: 8,050,109\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        #shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        #rotation_range=10,\n",
    "        #samplewise_center=True,\n",
    "        ##featurewise_center=True,\n",
    "        ##featurewise_std_normalization=True,\n",
    "        ##samplewise_std_normalization=True,\n",
    "        ##zca_whitening=True,\n",
    "        #vertical_flip=True,\n",
    "        #horizontal_flip=True\n",
    "        )\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(\n",
    "        #samplewise_center=True,\n",
    "        ##featurewise_center=True,\n",
    "        ##featurewise_std_normalization=True,\n",
    "        #samplewise_std_normalization=True,\n",
    "        ##zca_whitening=True,\n",
    "        rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow(xTrain[0:10000],yTrain[0:10000],\n",
    "        #target_size=(h,w),\n",
    "        #color_mode='grayscale',\n",
    "        batch_size=32,)\n",
    "        #save_to_dir='../Keras/Temp',\n",
    "        #shuffle=False,\n",
    "        #class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow(xTest[0:1000],yTest[0:1000],\n",
    "        #target_size=(h,w),\n",
    "        #color_mode='grayscale',\n",
    "        batch_size=32,)\n",
    "        #save_to_dir='../Keras/Temp',\n",
    "        #shuffle=False,\n",
    "        #class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.begin : 2017-05-17 01:43:12.199873\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/100\n",
      "77s - loss: 5.6902 - fbeta_pred: 0.6457 - val_loss: 5.4766 - val_fbeta_pred: 0.7209\n",
      "Epoch 2/100\n",
      "33s - loss: 5.2851 - fbeta_pred: 0.7625 - val_loss: 5.2076 - val_fbeta_pred: 0.7948\n",
      "Epoch 3/100\n",
      "33s - loss: 5.1658 - fbeta_pred: 0.7773 - val_loss: 5.1337 - val_fbeta_pred: 0.8053\n",
      "Epoch 4/100\n",
      "33s - loss: 5.0314 - fbeta_pred: 0.7957 - val_loss: 5.0433 - val_fbeta_pred: 0.8053\n",
      "Epoch 5/100\n",
      "33s - loss: 4.9689 - fbeta_pred: 0.8064 - val_loss: 4.9210 - val_fbeta_pred: 0.8231\n",
      "Epoch 6/100\n",
      "33s - loss: 4.9093 - fbeta_pred: 0.8106 - val_loss: 4.8984 - val_fbeta_pred: 0.8213\n",
      "Epoch 7/100\n",
      "33s - loss: 4.8698 - fbeta_pred: 0.8154 - val_loss: 4.9380 - val_fbeta_pred: 0.8276\n",
      "Epoch 8/100\n",
      "33s - loss: 4.8304 - fbeta_pred: 0.8168 - val_loss: 4.8110 - val_fbeta_pred: 0.8268\n",
      "Epoch 9/100\n",
      "33s - loss: 4.7907 - fbeta_pred: 0.8230 - val_loss: 4.7901 - val_fbeta_pred: 0.8439\n",
      "Epoch 10/100\n",
      "33s - loss: 4.7497 - fbeta_pred: 0.8318 - val_loss: 4.7889 - val_fbeta_pred: 0.8389\n",
      "Epoch 11/100\n",
      "33s - loss: 4.7166 - fbeta_pred: 0.8354 - val_loss: 4.7615 - val_fbeta_pred: 0.8352\n",
      "Epoch 12/100\n",
      "33s - loss: 4.6951 - fbeta_pred: 0.8371 - val_loss: 4.7308 - val_fbeta_pred: 0.8402\n",
      "Epoch 13/100\n",
      "33s - loss: 4.6780 - fbeta_pred: 0.8391 - val_loss: 4.7220 - val_fbeta_pred: 0.8414\n",
      "Epoch 14/100\n",
      "33s - loss: 4.6492 - fbeta_pred: 0.8411 - val_loss: 4.7321 - val_fbeta_pred: 0.8440\n",
      "Epoch 15/100\n",
      "33s - loss: 4.6397 - fbeta_pred: 0.8410 - val_loss: 4.7322 - val_fbeta_pred: 0.8387\n",
      "Epoch 16/100\n",
      "33s - loss: 4.6171 - fbeta_pred: 0.8452 - val_loss: 4.7217 - val_fbeta_pred: 0.8473\n",
      "Epoch 17/100\n",
      "33s - loss: 4.5988 - fbeta_pred: 0.8448 - val_loss: 4.7407 - val_fbeta_pred: 0.8397\n",
      "Epoch 18/100\n",
      "33s - loss: 4.5902 - fbeta_pred: 0.8461 - val_loss: 4.7081 - val_fbeta_pred: 0.8399\n",
      "Epoch 19/100\n",
      "33s - loss: 4.5598 - fbeta_pred: 0.8495 - val_loss: 4.7174 - val_fbeta_pred: 0.8359\n",
      "Epoch 20/100\n",
      "33s - loss: 4.5329 - fbeta_pred: 0.8497 - val_loss: 4.6907 - val_fbeta_pred: 0.8489\n",
      "Epoch 21/100\n",
      "33s - loss: 4.5198 - fbeta_pred: 0.8481 - val_loss: 4.7321 - val_fbeta_pred: 0.8451\n",
      "Epoch 22/100\n",
      "33s - loss: 4.5051 - fbeta_pred: 0.8503 - val_loss: 4.7325 - val_fbeta_pred: 0.8353\n",
      "Epoch 23/100\n",
      "33s - loss: 4.5044 - fbeta_pred: 0.8503 - val_loss: 4.7424 - val_fbeta_pred: 0.8408\n",
      "Epoch 24/100\n",
      "33s - loss: 4.4760 - fbeta_pred: 0.8528 - val_loss: 4.7543 - val_fbeta_pred: 0.8395\n",
      "Epoch 25/100\n",
      "33s - loss: 4.4419 - fbeta_pred: 0.8562 - val_loss: 4.7696 - val_fbeta_pred: 0.8363\n",
      "Epoch 26/100\n",
      "33s - loss: 4.4280 - fbeta_pred: 0.8573 - val_loss: 4.8180 - val_fbeta_pred: 0.8361\n",
      "Epoch 27/100\n",
      "33s - loss: 4.4350 - fbeta_pred: 0.8555 - val_loss: 4.8152 - val_fbeta_pred: 0.8372\n",
      "Epoch 28/100\n",
      "33s - loss: 4.3926 - fbeta_pred: 0.8552 - val_loss: 4.7916 - val_fbeta_pred: 0.8376\n",
      "Epoch 29/100\n",
      "33s - loss: 4.3660 - fbeta_pred: 0.8592 - val_loss: 4.8629 - val_fbeta_pred: 0.8236\n",
      "Epoch 30/100\n",
      "33s - loss: 4.3455 - fbeta_pred: 0.8618 - val_loss: 4.8487 - val_fbeta_pred: 0.8248\n",
      "Epoch 31/100\n",
      "33s - loss: 4.3139 - fbeta_pred: 0.8645 - val_loss: 4.8976 - val_fbeta_pred: 0.8368\n",
      "Epoch 32/100\n",
      "33s - loss: 4.2986 - fbeta_pred: 0.8664 - val_loss: 4.8543 - val_fbeta_pred: 0.8246\n",
      "Epoch 33/100\n",
      "33s - loss: 4.2902 - fbeta_pred: 0.8661 - val_loss: 4.8908 - val_fbeta_pred: 0.8196\n",
      "Epoch 34/100\n",
      "33s - loss: 4.2496 - fbeta_pred: 0.8711 - val_loss: 4.9244 - val_fbeta_pred: 0.8244\n",
      "Epoch 35/100\n",
      "33s - loss: 4.2530 - fbeta_pred: 0.8691 - val_loss: 4.9340 - val_fbeta_pred: 0.8240\n",
      "Epoch 36/100\n",
      "33s - loss: 4.2168 - fbeta_pred: 0.8743 - val_loss: 5.0212 - val_fbeta_pred: 0.8329\n",
      "time.end   : 2017-05-17 02:04:02.305324\n"
     ]
    }
   ],
   "source": [
    "print('time.begin :',datetime.datetime.now())\n",
    "#hist_old=hist.history\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "hist = model.fit(trX,trY,\n",
    "         epochs=100, #10,\n",
    "         batch_size=256,\n",
    "         validation_split=0.20,\n",
    "         callbacks=[early_stopping],\n",
    "         #class_weight=rrd,\n",
    "         verbose=2\n",
    "         )\n",
    "        #samples_per_epoch=200)\n",
    "        #validation_data=validation_generator,\n",
    "        #initial_epoch=start,\n",
    "        #nb_val_samples=2048\n",
    "         #)\n",
    "print('time.end   :',datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_model(model,'../Data-Keras/train-model-2D-2-v2-all.h5')\n",
    "model.save_weights('../Data-Keras/train-model-2D-2-v2-weights.h5')  # save weights after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3339444657595294, 0.71995355617081491, 0.87297436628756564]\n",
      "(40479, 17)\n",
      "(40479, 17)\n",
      "fbeta_score= 0.900652762317\n",
      "fbeta_pred = 0.872814040159\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(trX,trY,verbose=2))\n",
    "trP = model.predict(trX, batch_size=128)\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2616619400457534, 0.88562342545511386]\n",
      "(40479, 17)\n",
      "(40479, 17)\n",
      "fbeta_score= 0.908520702902\n",
      "fbeta_pred = 0.885392335893\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(trX,trY,verbose=2))\n",
    "trP = model.predict(trX, batch_size=512)\n",
    "print(trY.shape)\n",
    "print(trP.shape)\n",
    "print('fbeta_score=',fbeta_score(trY, np.array(trP) > 0.2, beta=2, average='samples'))\n",
    "print('fbeta_pred =',K.get_value(fbeta_pred(trY.astype(np.float64),trP.astype(np.float64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#hist_old=hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-15 07:45:16.245791 0 --> 67 0.703723037192 [0.70136893207458639, 0.70372303719187324, 0.70255697093345204]\n",
      "2017-05-15 07:48:05.845385 1 --> 74 0.980069323901 [0.97993962183479821, 0.98006932390084267, 0.97997932676465371]\n",
      "2017-05-15 07:51:03.555375 2 --> 60 0.830832805721 [0.83066919227432678, 0.83083280572116081, 0.83012642884749333]\n",
      "2017-05-15 07:54:07.692849 3 --> 73 0.95596621068 [0.95530247952573877, 0.9559662106804423, 0.95587193006934856]\n",
      "2017-05-15 07:57:17.654396 4 --> 37 0.771627389839 [0.77128836874582085, 0.77162738983933221, 0.77157084802598352]\n",
      "2017-05-15 08:00:35.571387 5 --> 28 0.612647945213 [0.6089740900094327, 0.61264794521337496, 0.60631829415658134]\n",
      "2017-05-15 08:04:02.404595 6 --> 40 0.711618933993 [0.70809511238058165, 0.71161893399277543, 0.71149522396880938]\n",
      "2017-05-15 08:07:36.162990 7 --> 38 0.549023191429 [0.54805400909065172, 0.54902319142904643, 0.54874345592600848]\n",
      "2017-05-15 08:11:16.278601 8 --> 20 0.24951985087 [0.24604540154654581, 0.24951985087034834, 0.23326541244809568]\n",
      "2017-05-15 08:15:03.688871 9 --> 75 0.807659543767 [0.80664200796933339, 0.80765954376652815, 0.80544293900478359]\n",
      "2017-05-15 08:18:54.332631 10 --> 39 0.89400227749 [0.89367143664096893, 0.89400227748987626, 0.89355103407464842]\n",
      "2017-05-15 08:22:48.890322 11 --> 23 0.353260549829 [0.33163233223165617, 0.35326054982895766, 0.33333301543238353]\n",
      "2017-05-15 08:26:51.878065 12 --> 19 0.305239533004 [0.30279133950534243, 0.30523953300436946, 0.30437165965154667]\n",
      "2017-05-15 08:31:04.785543 13 --> 36 0.794424858804 [0.79381420688000048, 0.79442485880374014, 0.79151920410799548]\n",
      "2017-05-15 08:35:25.473228 14 --> 8 0.154155279206 [0.14412979899974701, 0.15415527920611241, 0.1355929670214423]\n",
      "2017-05-15 08:39:54.478940 15 --> 30 0.266322764441 [0.25244274544714956, 0.26632276444121183, 0.26433665157607383]\n",
      "2017-05-15 08:44:30.492999 16 --> 5 0.0826443251838 [0.054200397691350675, 0.082644325183804948, 0.045454421901120562]\n"
     ]
    }
   ],
   "source": [
    "rr, rrx = [], []; trP = model.predict(trX, batch_size=512)\n",
    "for i in range(trP.shape[1]) :\n",
    "    xx = [];\n",
    "    trYY = trY[:,i].astype(np.float64)\n",
    "    trPY = trP[:,i]\n",
    "    for ii in range(100) :\n",
    "        trPP = (trPY>0.01*ii).astype(np.float64)\n",
    "        #x = fbeta_score(trY[:,0], np.array(trP[:,0] > 0.1*ii), beta=2, average='samples')\n",
    "        x = K.get_value(fbeta_pred(trYY,trPP))\n",
    "        xx.append(x)\n",
    "    rrr = np.array(xx).argmax();\n",
    "    rr.append(rrr)\n",
    "    rrx.append(xx[rrr])\n",
    "    print(datetime.datetime.now(),i,'-->',rrr,xx[rrr],xx[(rrr-1):(rrr+2)])\n",
    "    #print(xx);\n",
    "    #plt.plot(np.array(xx)); plt.show()\n",
    "trM = np.array(rr)/100.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_model(model,  '../Data-Keras/train-model-2D-2-v2-loop-all.h5')\n",
    "model.save_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5')  # save weights after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('../Data-Keras/train-model-2D-2-v2-loop-weights.h5') ## verify load weights from v1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1664d7f42525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Forming output dataset for predicting --> trOX, trOY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trX' is not defined"
     ]
    }
   ],
   "source": [
    "# Forming output dataset for predicting --> trOX, trOY\n",
    "del(trX)\n",
    "del(trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191\n",
      "2017-05-17 03:09:48.246618 61191 61191\n",
      "2017-05-17 03:11:58.205335 \t 0 \t 5000 \t test_15649.tif \t \n",
      "2017-05-17 03:14:10.807284 \t 1 \t 10000 \t test_32423.tif \t (10000, 17)\n",
      "2017-05-17 03:16:13.438699 \t 1 \t 15000 \t test_36264.tif \t (10000, 17)\n",
      "2017-05-17 03:18:21.598552 \t 2 \t 20000 \t test_10894.tif \t (20000, 17)\n",
      "2017-05-17 03:20:28.583399 \t 2 \t 25000 \t file_9502.tif \t (20000, 17)\n",
      "2017-05-17 03:22:35.660930 \t 3 \t 30000 \t file_14128.tif \t (30000, 17)\n",
      "2017-05-17 03:24:39.034604 \t 3 \t 35000 \t file_17389.tif \t (30000, 17)\n",
      "2017-05-17 03:26:47.299834 \t 4 \t 40000 \t test_19356.tif \t (40000, 17)\n",
      "2017-05-17 03:28:49.710308 \t 4 \t 45000 \t test_10134.tif \t (40000, 17)\n",
      "2017-05-17 03:30:57.184685 \t 5 \t 50000 \t test_24243.tif \t (50000, 17)\n",
      "2017-05-17 03:33:03.187887 \t 5 \t 55000 \t test_7049.tif \t (50000, 17)\n",
      "2017-05-17 03:35:12.862152 \t 6 \t 60000 \t file_10482.tif \t (60000, 17)\n",
      "2017-05-17 03:35:42.990272\n"
     ]
    }
   ],
   "source": [
    "nameAsk = os.listdir(teDirI); print(len(nameAsk))\n",
    "trOX, trOY, i, ii, size = [], [], 0, 0, len(nameAsk)\n",
    "print(datetime.datetime.now(),len(nameAsk),size)\n",
    "for nn in nameAsk[0:size] :\n",
    "    nf = os.path.join(teDirTIF,nn);\n",
    "    nx = formImExt(nf,resize=(64,64))\n",
    "    if (nx is not None) :\n",
    "        trOX.append(nx)\n",
    "        trOY.append(nn)\n",
    "    i += 1\n",
    "    if (i%10000==0) and (i>1) :\n",
    "        if (ii==0) :\n",
    "            trOX = np.array(trOX);\n",
    "            trP = model.predict(trOX, batch_size=512); \n",
    "        else :\n",
    "            trOX = np.array(trOX);\n",
    "            trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "        trOX,ii = [],ii+1;\n",
    "    if (i%5000==0) : print(datetime.datetime.now(),\"\\t\",ii,'\\t',i,\"\\t\",nn,'\\t',(trP.shape if ii>0 else \"\"))\n",
    "\n",
    "if (len(trOX)>0) :\n",
    "    if (ii==0) :\n",
    "        trOX = np.array(trOX);\n",
    "        trP = model.predict(trOX, batch_size=512); \n",
    "    else :\n",
    "        trOX = np.array(trOX);\n",
    "        trP = np.vstack([trP,model.predict(trOX, batch_size=512)]); \n",
    "    trOX,ii = [],ii+1;\n",
    "    \n",
    "print(datetime.datetime.now())\n",
    "\n",
    "#assert (size!=len(trOY)), \"Wrong files {} != {}\".format(size,len(trOY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61191 (61191, 17) (61191,)\n"
     ]
    }
   ],
   "source": [
    "#trOX = np.array(trOX);\n",
    "trOY = np.array([os.path.splitext(x)[0] for x in trOY]);\n",
    "print(len(nameAsk),trP.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy',trOX)\n",
    "np.save('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy',trOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 32, 32, 6) (61191,)\n"
     ]
    }
   ],
   "source": [
    "trOX = np.load('../Data-Keras/test-basin-2D-64x64-OX-tif-v2.npy')\n",
    "trOY = np.load('../Data-Keras/test-basin-2D-64x64-OY-tif-v2.npy')\n",
    "print(trOX.shape,trOY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rrx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-0c48c95e3f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrrx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrrd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrrx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrrx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrrd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rrx' is not defined"
     ]
    }
   ],
   "source": [
    "rrx\n",
    "rrd=dict()\n",
    "for i in range(len(rrx)) :\n",
    "    rrd[i]=rrx[i]\n",
    "rrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Forming result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61191, 17), array([  2.31444892e-02,   9.79294121e-01,   2.86209971e-01,\n",
       "          9.69578385e-01,   3.21317136e-01,   3.53857726e-02,\n",
       "          1.92450643e-01,   1.09134607e-01,   5.12446323e-03,\n",
       "          7.43655721e-04,   2.26537101e-02,   7.24586775e-04,\n",
       "          1.53525993e-02,   2.39399401e-03,   2.09098756e-02,\n",
       "          2.87257116e-02,   1.37278186e-02], dtype=float32))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trP = model.predict(trOX, batch_size=512); \n",
    "trP.shape, trP[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "[3, 10, 0, 9] \n",
      " ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down'] \n",
      " [2.0, 0.5, 0.5, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "trM=np.array([0.0]*len(labels)); print(trM.shape)\n",
    "wr = [labels.index(i) for i in weather_labels];\n",
    "tt=trM; trM[:]=0.5\n",
    "trM[np.array(wr)] = 2.0\n",
    "print(wr,'\\n',labels,'\\n',trM.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'clear primary'] \n",
      " ['file_20521', 'clear primary agriculture habitation road'] \n",
      " [ 2.   0.5  0.5  2.   0.5  0.5  0.5  0.5  0.5  2.   2.   0.5  0.5  0.5  0.5\n",
      "  0.5  0.5] [  1.94645324e-03   9.97888982e-01   8.46054684e-03   9.90010440e-01\n",
      "   1.23228263e-02   2.39327317e-03   8.05634167e-03   4.15086700e-03\n",
      "   1.36539020e-04   9.33622869e-05   7.56200310e-03   1.45730678e-06\n",
      "   3.36432975e-04   4.43703175e-06   1.29225282e-02   6.47825329e-03\n",
      "   4.82078525e-04]\n"
     ]
    }
   ],
   "source": [
    "#trP = model.predict(trX, batch_size=512); trP=K.get_value(trP)\n",
    "res = []\n",
    "\n",
    "for i in range(trP.shape[0]) :\n",
    "    trPP = [weather_labels[trP[i,wr].argmax()]] + [labels[ii] for ii in range(len(labels)) if (trP[i,ii]>trM[ii])];\n",
    "    pp   = ' '.join(trPP)\n",
    "    ##if (pp==\"\") : print(trY[i])\n",
    "    res.append([trOY[i],pp])\n",
    "\n",
    "res.sort(cmp=lambda x,y: cmp(int(x[0].partition('_')[2]),int(y[0].partition('_')[2])) if (x[0].partition('_')[0]==y[0].partition('_')[0]) else cmp(y[0].partition('_')[0],x[0].partition('_')[0]))\n",
    "#print(res[4:8],'\\n',res[-4:])\n",
    "print(res[0],'\\n',res[-1],'\\n',trM,trP[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "#print(trM.tolist())\n",
    "#np.round(trP[4:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-17-03-38-07\n"
     ]
    }
   ],
   "source": [
    "rrr=pd.DataFrame(res,columns=['image_name','tags']); rrr.head(); \n",
    "suffixDT = (datetime.datetime.now()).strftime('%Y-%m-%d-%H-%M-%S'); print(suffixDT)\n",
    "rrr.to_csv('../Result/vss'+suffixDT+'.csv',index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
